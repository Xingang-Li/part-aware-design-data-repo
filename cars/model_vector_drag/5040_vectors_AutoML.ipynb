{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./5040_vectors_drags.csv | Columns = 5043 / 5043 | Rows = 439 -> 439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_5032</th>\n",
       "      <th>dim_5033</th>\n",
       "      <th>dim_5034</th>\n",
       "      <th>dim_5035</th>\n",
       "      <th>dim_5036</th>\n",
       "      <th>dim_5037</th>\n",
       "      <th>dim_5038</th>\n",
       "      <th>dim_5039</th>\n",
       "      <th>dim_5040</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5041 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "61     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "354    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "358    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "275    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "18     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_5032  dim_5033  dim_5034  dim_5035  dim_5036  dim_5037  \\\n",
       "61   ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "354  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "358  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "275  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "18   ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "     dim_5038  dim_5039  dim_5040   drag  \n",
       "61        0.0       0.0       0.0  0.375  \n",
       "354       0.0       0.0       0.0  0.374  \n",
       "358       0.0       0.0       0.0  0.435  \n",
       "275       0.0       0.0       0.0  0.437  \n",
       "18        0.0       0.0       0.0  0.367  \n",
       "\n",
       "[5 rows x 5041 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = './5040_vectors_drags.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-5040\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Saving ./agModels-5040/learner.pkl\n",
      "Saving ./agModels-5040/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-5040/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 5040\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    251778.86 MB\n",
      "\tTrain Data (Original)  Memory Usage: 14.15 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 2064 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\t2.7s = Fit runtime\n",
      "\t\t\t2064 features in original data used to generate 2064 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t2064 features in original data used to generate 2064 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t2064 features in original data used to generate 2064 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t\t\t0.3s = Fit runtime\n",
      "\t\t\t2064 features in original data used to generate 2064 features in processed data.\n",
      "\tUseless Original Features (Count: 2976): ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_6', 'dim_7', 'dim_8', 'dim_9', 'dim_10', 'dim_11', 'dim_12', 'dim_13', 'dim_14', 'dim_15', 'dim_16', 'dim_17', 'dim_18', 'dim_19', 'dim_20', 'dim_21', 'dim_22', 'dim_23', 'dim_24', 'dim_25', 'dim_26', 'dim_27', 'dim_28', 'dim_29', 'dim_30', 'dim_31', 'dim_32', 'dim_33', 'dim_34', 'dim_35', 'dim_36', 'dim_37', 'dim_38', 'dim_39', 'dim_40', 'dim_41', 'dim_42', 'dim_43', 'dim_44', 'dim_45', 'dim_46', 'dim_47', 'dim_48', 'dim_49', 'dim_50', 'dim_51', 'dim_52', 'dim_53', 'dim_54', 'dim_55', 'dim_56', 'dim_57', 'dim_58', 'dim_59', 'dim_60', 'dim_61', 'dim_62', 'dim_63', 'dim_64', 'dim_65', 'dim_67', 'dim_68', 'dim_69', 'dim_70', 'dim_71', 'dim_72', 'dim_73', 'dim_74', 'dim_75', 'dim_76', 'dim_77', 'dim_80', 'dim_81', 'dim_82', 'dim_83', 'dim_84', 'dim_85', 'dim_86', 'dim_87', 'dim_89', 'dim_90', 'dim_92', 'dim_93', 'dim_94', 'dim_95', 'dim_96', 'dim_97', 'dim_98', 'dim_99', 'dim_101', 'dim_102', 'dim_105', 'dim_106', 'dim_107', 'dim_108', 'dim_109', 'dim_110', 'dim_111', 'dim_113', 'dim_116', 'dim_117', 'dim_118', 'dim_119', 'dim_120', 'dim_121', 'dim_122', 'dim_123', 'dim_125', 'dim_128', 'dim_129', 'dim_130', 'dim_131', 'dim_132', 'dim_133', 'dim_134', 'dim_135', 'dim_140', 'dim_141', 'dim_142', 'dim_143', 'dim_144', 'dim_145', 'dim_146', 'dim_147', 'dim_152', 'dim_153', 'dim_154', 'dim_155', 'dim_156', 'dim_157', 'dim_158', 'dim_159', 'dim_162', 'dim_164', 'dim_165', 'dim_166', 'dim_167', 'dim_168', 'dim_169', 'dim_170', 'dim_171', 'dim_174', 'dim_175', 'dim_176', 'dim_177', 'dim_178', 'dim_179', 'dim_180', 'dim_181', 'dim_182', 'dim_183', 'dim_185', 'dim_186', 'dim_187', 'dim_188', 'dim_189', 'dim_190', 'dim_191', 'dim_192', 'dim_193', 'dim_194', 'dim_195', 'dim_197', 'dim_198', 'dim_199', 'dim_200', 'dim_201', 'dim_202', 'dim_203', 'dim_204', 'dim_205', 'dim_206', 'dim_207', 'dim_209', 'dim_210', 'dim_211', 'dim_212', 'dim_213', 'dim_214', 'dim_215', 'dim_216', 'dim_217', 'dim_218', 'dim_219', 'dim_221', 'dim_222', 'dim_223', 'dim_224', 'dim_225', 'dim_226', 'dim_227', 'dim_228', 'dim_229', 'dim_230', 'dim_231', 'dim_233', 'dim_234', 'dim_235', 'dim_236', 'dim_237', 'dim_238', 'dim_239', 'dim_240', 'dim_241', 'dim_242', 'dim_243', 'dim_245', 'dim_246', 'dim_247', 'dim_248', 'dim_249', 'dim_250', 'dim_251', 'dim_252', 'dim_253', 'dim_254', 'dim_255', 'dim_257', 'dim_258', 'dim_259', 'dim_260', 'dim_261', 'dim_262', 'dim_263', 'dim_264', 'dim_265', 'dim_266', 'dim_267', 'dim_269', 'dim_270', 'dim_271', 'dim_273', 'dim_274', 'dim_275', 'dim_276', 'dim_277', 'dim_278', 'dim_279', 'dim_281', 'dim_282', 'dim_283', 'dim_284', 'dim_285', 'dim_286', 'dim_287', 'dim_288', 'dim_289', 'dim_290', 'dim_291', 'dim_292', 'dim_293', 'dim_295', 'dim_296', 'dim_297', 'dim_298', 'dim_299', 'dim_300', 'dim_301', 'dim_302', 'dim_303', 'dim_304', 'dim_308', 'dim_309', 'dim_310', 'dim_311', 'dim_312', 'dim_313', 'dim_314', 'dim_315', 'dim_319', 'dim_320', 'dim_321', 'dim_322', 'dim_323', 'dim_324', 'dim_325', 'dim_326', 'dim_327', 'dim_328', 'dim_329', 'dim_330', 'dim_331', 'dim_332', 'dim_333', 'dim_334', 'dim_335', 'dim_336', 'dim_337', 'dim_338', 'dim_339', 'dim_340', 'dim_341', 'dim_342', 'dim_343', 'dim_344', 'dim_345', 'dim_346', 'dim_347', 'dim_348', 'dim_349', 'dim_350', 'dim_351', 'dim_352', 'dim_353', 'dim_354', 'dim_355', 'dim_356', 'dim_357', 'dim_358', 'dim_359', 'dim_360', 'dim_361', 'dim_362', 'dim_363', 'dim_364', 'dim_365', 'dim_366', 'dim_367', 'dim_368', 'dim_369', 'dim_370', 'dim_371', 'dim_372', 'dim_373', 'dim_374', 'dim_375', 'dim_376', 'dim_377', 'dim_378', 'dim_379', 'dim_380', 'dim_381', 'dim_382', 'dim_383', 'dim_384', 'dim_385', 'dim_386', 'dim_387', 'dim_388', 'dim_389', 'dim_390', 'dim_391', 'dim_392', 'dim_393', 'dim_394', 'dim_395', 'dim_396', 'dim_397', 'dim_398', 'dim_399', 'dim_400', 'dim_401', 'dim_402', 'dim_403', 'dim_404', 'dim_405', 'dim_406', 'dim_407', 'dim_408', 'dim_409', 'dim_410', 'dim_411', 'dim_412', 'dim_413', 'dim_414', 'dim_415', 'dim_416', 'dim_417', 'dim_418', 'dim_419', 'dim_420', 'dim_421', 'dim_422', 'dim_423', 'dim_424', 'dim_425', 'dim_426', 'dim_427', 'dim_428', 'dim_429', 'dim_430', 'dim_431', 'dim_432', 'dim_433', 'dim_434', 'dim_435', 'dim_436', 'dim_437', 'dim_438', 'dim_439', 'dim_440', 'dim_441', 'dim_442', 'dim_443', 'dim_444', 'dim_445', 'dim_446', 'dim_447', 'dim_448', 'dim_449', 'dim_451', 'dim_452', 'dim_453', 'dim_454', 'dim_455', 'dim_456', 'dim_457', 'dim_458', 'dim_459', 'dim_460', 'dim_464', 'dim_465', 'dim_466', 'dim_467', 'dim_468', 'dim_469', 'dim_470', 'dim_471', 'dim_472', 'dim_479', 'dim_480', 'dim_481', 'dim_482', 'dim_483', 'dim_490', 'dim_491', 'dim_492', 'dim_493', 'dim_494', 'dim_502', 'dim_503', 'dim_504', 'dim_505', 'dim_506', 'dim_513', 'dim_514', 'dim_515', 'dim_516', 'dim_517', 'dim_518', 'dim_525', 'dim_526', 'dim_527', 'dim_528', 'dim_529', 'dim_537', 'dim_538', 'dim_539', 'dim_540', 'dim_541', 'dim_549', 'dim_550', 'dim_551', 'dim_552', 'dim_553', 'dim_562', 'dim_563', 'dim_564', 'dim_565', 'dim_574', 'dim_575', 'dim_576', 'dim_577', 'dim_578', 'dim_586', 'dim_587', 'dim_588', 'dim_589', 'dim_590', 'dim_591', 'dim_598', 'dim_599', 'dim_600', 'dim_601', 'dim_602', 'dim_603', 'dim_610', 'dim_611', 'dim_612', 'dim_613', 'dim_614', 'dim_615', 'dim_622', 'dim_623', 'dim_624', 'dim_625', 'dim_626', 'dim_627', 'dim_634', 'dim_635', 'dim_636', 'dim_637', 'dim_638', 'dim_639', 'dim_646', 'dim_647', 'dim_648', 'dim_649', 'dim_650', 'dim_651', 'dim_658', 'dim_659', 'dim_660', 'dim_661', 'dim_662', 'dim_663', 'dim_670', 'dim_671', 'dim_672', 'dim_673', 'dim_674', 'dim_675', 'dim_682', 'dim_683', 'dim_684', 'dim_685', 'dim_686', 'dim_687', 'dim_694', 'dim_695', 'dim_696', 'dim_697', 'dim_698', 'dim_699', 'dim_705', 'dim_706', 'dim_707', 'dim_708', 'dim_709', 'dim_710', 'dim_717', 'dim_718', 'dim_719', 'dim_720', 'dim_721', 'dim_722', 'dim_729', 'dim_730', 'dim_731', 'dim_732', 'dim_733', 'dim_734', 'dim_741', 'dim_742', 'dim_743', 'dim_744', 'dim_745', 'dim_753', 'dim_754', 'dim_755', 'dim_756', 'dim_757', 'dim_764', 'dim_765', 'dim_766', 'dim_767', 'dim_768', 'dim_769', 'dim_776', 'dim_777', 'dim_778', 'dim_779', 'dim_780', 'dim_781', 'dim_782', 'dim_788', 'dim_789', 'dim_790', 'dim_791', 'dim_792', 'dim_793', 'dim_794', 'dim_795', 'dim_800', 'dim_801', 'dim_802', 'dim_803', 'dim_804', 'dim_805', 'dim_806', 'dim_807', 'dim_808', 'dim_811', 'dim_812', 'dim_813', 'dim_814', 'dim_815', 'dim_816', 'dim_817', 'dim_818', 'dim_819', 'dim_820', 'dim_821', 'dim_822', 'dim_823', 'dim_824', 'dim_825', 'dim_826', 'dim_827', 'dim_828', 'dim_829', 'dim_830', 'dim_831', 'dim_832', 'dim_833', 'dim_834', 'dim_835', 'dim_836', 'dim_837', 'dim_838', 'dim_839', 'dim_840', 'dim_841', 'dim_842', 'dim_843', 'dim_844', 'dim_845', 'dim_846', 'dim_847', 'dim_848', 'dim_849', 'dim_850', 'dim_851', 'dim_852', 'dim_853', 'dim_854', 'dim_855', 'dim_856', 'dim_857', 'dim_858', 'dim_859', 'dim_860', 'dim_861', 'dim_862', 'dim_863', 'dim_864', 'dim_865', 'dim_866', 'dim_867', 'dim_868', 'dim_871', 'dim_872', 'dim_873', 'dim_874', 'dim_875', 'dim_876', 'dim_877', 'dim_878', 'dim_879', 'dim_880', 'dim_884', 'dim_886', 'dim_887', 'dim_888', 'dim_889', 'dim_890', 'dim_899', 'dim_900', 'dim_901', 'dim_902', 'dim_911', 'dim_912', 'dim_913', 'dim_914', 'dim_923', 'dim_924', 'dim_925', 'dim_931', 'dim_935', 'dim_936', 'dim_943', 'dim_947', 'dim_948', 'dim_955', 'dim_959', 'dim_960', 'dim_967', 'dim_972', 'dim_973', 'dim_979', 'dim_983', 'dim_984', 'dim_985', 'dim_991', 'dim_995', 'dim_996', 'dim_997', 'dim_998', 'dim_1003', 'dim_1007', 'dim_1008', 'dim_1009', 'dim_1010', 'dim_1015', 'dim_1019', 'dim_1020', 'dim_1021', 'dim_1022', 'dim_1027', 'dim_1031', 'dim_1032', 'dim_1033', 'dim_1034', 'dim_1038', 'dim_1039', 'dim_1043', 'dim_1044', 'dim_1045', 'dim_1046', 'dim_1050', 'dim_1051', 'dim_1055', 'dim_1056', 'dim_1057', 'dim_1058', 'dim_1062', 'dim_1063', 'dim_1067', 'dim_1068', 'dim_1069', 'dim_1070', 'dim_1074', 'dim_1079', 'dim_1080', 'dim_1081', 'dim_1082', 'dim_1086', 'dim_1091', 'dim_1092', 'dim_1093', 'dim_1094', 'dim_1098', 'dim_1103', 'dim_1104', 'dim_1105', 'dim_1106', 'dim_1110', 'dim_1115', 'dim_1116', 'dim_1117', 'dim_1118', 'dim_1122', 'dim_1127', 'dim_1128', 'dim_1129', 'dim_1130', 'dim_1134', 'dim_1139', 'dim_1140', 'dim_1141', 'dim_1142', 'dim_1146', 'dim_1150', 'dim_1151', 'dim_1152', 'dim_1153', 'dim_1162', 'dim_1163', 'dim_1164', 'dim_1173', 'dim_1174', 'dim_1175', 'dim_1176', 'dim_1182', 'dim_1185', 'dim_1186', 'dim_1187', 'dim_1188', 'dim_1194', 'dim_1197', 'dim_1198', 'dim_1199', 'dim_1200', 'dim_1201', 'dim_1202', 'dim_1209', 'dim_1210', 'dim_1211', 'dim_1212', 'dim_1213', 'dim_1214', 'dim_1220', 'dim_1221', 'dim_1222', 'dim_1223', 'dim_1224', 'dim_1225', 'dim_1226', 'dim_1227', 'dim_1232', 'dim_1233', 'dim_1234', 'dim_1235', 'dim_1236', 'dim_1237', 'dim_1238', 'dim_1239', 'dim_1240', 'dim_1243', 'dim_1244', 'dim_1245', 'dim_1246', 'dim_1247', 'dim_1248', 'dim_1249', 'dim_1250', 'dim_1251', 'dim_1252', 'dim_1253', 'dim_1254', 'dim_1255', 'dim_1256', 'dim_1257', 'dim_1258', 'dim_1259', 'dim_1260', 'dim_1261', 'dim_1262', 'dim_1263', 'dim_1264', 'dim_1265', 'dim_1266', 'dim_1267', 'dim_1268', 'dim_1269', 'dim_1270', 'dim_1271', 'dim_1272', 'dim_1273', 'dim_1274', 'dim_1275', 'dim_1276', 'dim_1277', 'dim_1278', 'dim_1279', 'dim_1280', 'dim_1281', 'dim_1282', 'dim_1283', 'dim_1284', 'dim_1285', 'dim_1286', 'dim_1287', 'dim_1288', 'dim_1291', 'dim_1292', 'dim_1293', 'dim_1294', 'dim_1295', 'dim_1296', 'dim_1297', 'dim_1298', 'dim_1299', 'dim_1300', 'dim_1305', 'dim_1306', 'dim_1307', 'dim_1308', 'dim_1309', 'dim_1310', 'dim_1319', 'dim_1320', 'dim_1321', 'dim_1322', 'dim_1331', 'dim_1332', 'dim_1333', 'dim_1334', 'dim_1344', 'dim_1345', 'dim_1346', 'dim_1351', 'dim_1356', 'dim_1357', 'dim_1358', 'dim_1362', 'dim_1363', 'dim_1368', 'dim_1369', 'dim_1370', 'dim_1374', 'dim_1375', 'dim_1380', 'dim_1381', 'dim_1382', 'dim_1385', 'dim_1386', 'dim_1387', 'dim_1392', 'dim_1393', 'dim_1394', 'dim_1398', 'dim_1399', 'dim_1404', 'dim_1405', 'dim_1406', 'dim_1410', 'dim_1411', 'dim_1416', 'dim_1417', 'dim_1418', 'dim_1422', 'dim_1423', 'dim_1428', 'dim_1429', 'dim_1430', 'dim_1434', 'dim_1435', 'dim_1436', 'dim_1440', 'dim_1441', 'dim_1442', 'dim_1446', 'dim_1447', 'dim_1448', 'dim_1452', 'dim_1453', 'dim_1454', 'dim_1458', 'dim_1459', 'dim_1460', 'dim_1464', 'dim_1465', 'dim_1466', 'dim_1470', 'dim_1471', 'dim_1472', 'dim_1476', 'dim_1477', 'dim_1478', 'dim_1482', 'dim_1483', 'dim_1484', 'dim_1488', 'dim_1489', 'dim_1490', 'dim_1494', 'dim_1495', 'dim_1496', 'dim_1500', 'dim_1501', 'dim_1502', 'dim_1506', 'dim_1507', 'dim_1512', 'dim_1513', 'dim_1514', 'dim_1518', 'dim_1519', 'dim_1524', 'dim_1525', 'dim_1526', 'dim_1530', 'dim_1531', 'dim_1535', 'dim_1536', 'dim_1537', 'dim_1538', 'dim_1542', 'dim_1543', 'dim_1547', 'dim_1548', 'dim_1549', 'dim_1550', 'dim_1553', 'dim_1554', 'dim_1555', 'dim_1559', 'dim_1560', 'dim_1561', 'dim_1562', 'dim_1565', 'dim_1566', 'dim_1567', 'dim_1570', 'dim_1571', 'dim_1572', 'dim_1573', 'dim_1574', 'dim_1578', 'dim_1582', 'dim_1583', 'dim_1584', 'dim_1585', 'dim_1586', 'dim_1589', 'dim_1590', 'dim_1593', 'dim_1594', 'dim_1595', 'dim_1596', 'dim_1597', 'dim_1598', 'dim_1601', 'dim_1602', 'dim_1605', 'dim_1606', 'dim_1607', 'dim_1608', 'dim_1609', 'dim_1610', 'dim_1614', 'dim_1617', 'dim_1618', 'dim_1619', 'dim_1620', 'dim_1621', 'dim_1622', 'dim_1629', 'dim_1630', 'dim_1631', 'dim_1632', 'dim_1633', 'dim_1634', 'dim_1640', 'dim_1641', 'dim_1642', 'dim_1643', 'dim_1644', 'dim_1645', 'dim_1646', 'dim_1652', 'dim_1653', 'dim_1654', 'dim_1655', 'dim_1656', 'dim_1657', 'dim_1658', 'dim_1659', 'dim_1662', 'dim_1663', 'dim_1664', 'dim_1665', 'dim_1666', 'dim_1667', 'dim_1668', 'dim_1669', 'dim_1670', 'dim_1671', 'dim_1672', 'dim_1673', 'dim_1674', 'dim_1675', 'dim_1676', 'dim_1677', 'dim_1678', 'dim_1679', 'dim_1680', 'dim_1681', 'dim_1682', 'dim_1683', 'dim_1684', 'dim_1685', 'dim_1686', 'dim_1687', 'dim_1688', 'dim_1689', 'dim_1690', 'dim_1691', 'dim_1692', 'dim_1693', 'dim_1694', 'dim_1695', 'dim_1696', 'dim_1697', 'dim_1698', 'dim_1699', 'dim_1700', 'dim_1701', 'dim_1702', 'dim_1703', 'dim_1704', 'dim_1705', 'dim_1706', 'dim_1707', 'dim_1708', 'dim_1711', 'dim_1712', 'dim_1713', 'dim_1714', 'dim_1715', 'dim_1716', 'dim_1717', 'dim_1718', 'dim_1719', 'dim_1727', 'dim_1728', 'dim_1729', 'dim_1730', 'dim_1739', 'dim_1740', 'dim_1741', 'dim_1742', 'dim_1751', 'dim_1752', 'dim_1753', 'dim_1754', 'dim_1759', 'dim_1764', 'dim_1765', 'dim_1766', 'dim_1771', 'dim_1776', 'dim_1777', 'dim_1778', 'dim_1782', 'dim_1783', 'dim_1788', 'dim_1789', 'dim_1790', 'dim_1794', 'dim_1795', 'dim_1801', 'dim_1802', 'dim_1806', 'dim_1807', 'dim_1813', 'dim_1814', 'dim_1818', 'dim_1819', 'dim_1824', 'dim_1825', 'dim_1826', 'dim_1830', 'dim_1831', 'dim_1836', 'dim_1837', 'dim_1838', 'dim_1842', 'dim_1843', 'dim_1848', 'dim_1849', 'dim_1850', 'dim_1854', 'dim_1855', 'dim_1860', 'dim_1861', 'dim_1862', 'dim_1866', 'dim_1867', 'dim_1868', 'dim_1872', 'dim_1873', 'dim_1874', 'dim_1878', 'dim_1879', 'dim_1880', 'dim_1884', 'dim_1885', 'dim_1886', 'dim_1890', 'dim_1891', 'dim_1892', 'dim_1896', 'dim_1897', 'dim_1898', 'dim_1902', 'dim_1903', 'dim_1904', 'dim_1908', 'dim_1909', 'dim_1910', 'dim_1914', 'dim_1915', 'dim_1916', 'dim_1920', 'dim_1921', 'dim_1922', 'dim_1926', 'dim_1927', 'dim_1932', 'dim_1933', 'dim_1934', 'dim_1938', 'dim_1939', 'dim_1944', 'dim_1945', 'dim_1946', 'dim_1950', 'dim_1951', 'dim_1955', 'dim_1956', 'dim_1957', 'dim_1958', 'dim_1962', 'dim_1963', 'dim_1967', 'dim_1968', 'dim_1969', 'dim_1970', 'dim_1974', 'dim_1975', 'dim_1979', 'dim_1980', 'dim_1981', 'dim_1982', 'dim_1986', 'dim_1987', 'dim_1991', 'dim_1992', 'dim_1993', 'dim_1994', 'dim_1998', 'dim_2002', 'dim_2003', 'dim_2004', 'dim_2005', 'dim_2006', 'dim_2010', 'dim_2013', 'dim_2014', 'dim_2015', 'dim_2016', 'dim_2017', 'dim_2018', 'dim_2022', 'dim_2025', 'dim_2026', 'dim_2027', 'dim_2028', 'dim_2029', 'dim_2030', 'dim_2034', 'dim_2037', 'dim_2038', 'dim_2039', 'dim_2040', 'dim_2041', 'dim_2042', 'dim_2046', 'dim_2049', 'dim_2050', 'dim_2051', 'dim_2052', 'dim_2053', 'dim_2054', 'dim_2060', 'dim_2061', 'dim_2062', 'dim_2063', 'dim_2064', 'dim_2065', 'dim_2066', 'dim_2072', 'dim_2073', 'dim_2074', 'dim_2075', 'dim_2076', 'dim_2077', 'dim_2078', 'dim_2079', 'dim_2083', 'dim_2084', 'dim_2085', 'dim_2086', 'dim_2087', 'dim_2088', 'dim_2089', 'dim_2090', 'dim_2091', 'dim_2092', 'dim_2093', 'dim_2094', 'dim_2095', 'dim_2096', 'dim_2097', 'dim_2098', 'dim_2099', 'dim_2100', 'dim_2101', 'dim_2102', 'dim_2103', 'dim_2104', 'dim_2106', 'dim_2107', 'dim_2108', 'dim_2109', 'dim_2110', 'dim_2111', 'dim_2112', 'dim_2113', 'dim_2114', 'dim_2115', 'dim_2116', 'dim_2118', 'dim_2119', 'dim_2120', 'dim_2121', 'dim_2122', 'dim_2123', 'dim_2124', 'dim_2125', 'dim_2126', 'dim_2127', 'dim_2131', 'dim_2132', 'dim_2133', 'dim_2134', 'dim_2135', 'dim_2136', 'dim_2137', 'dim_2138', 'dim_2139', 'dim_2145', 'dim_2146', 'dim_2147', 'dim_2148', 'dim_2149', 'dim_2150', 'dim_2159', 'dim_2160', 'dim_2161', 'dim_2162', 'dim_2171', 'dim_2172', 'dim_2173', 'dim_2174', 'dim_2178', 'dim_2179', 'dim_2184', 'dim_2185', 'dim_2186', 'dim_2191', 'dim_2196', 'dim_2197', 'dim_2198', 'dim_2203', 'dim_2208', 'dim_2209', 'dim_2210', 'dim_2215', 'dim_2221', 'dim_2222', 'dim_2227', 'dim_2233', 'dim_2234', 'dim_2238', 'dim_2239', 'dim_2244', 'dim_2245', 'dim_2246', 'dim_2250', 'dim_2251', 'dim_2256', 'dim_2257', 'dim_2258', 'dim_2262', 'dim_2263', 'dim_2268', 'dim_2269', 'dim_2270', 'dim_2274', 'dim_2275', 'dim_2280', 'dim_2281', 'dim_2282', 'dim_2286', 'dim_2287', 'dim_2292', 'dim_2293', 'dim_2294', 'dim_2298', 'dim_2299', 'dim_2300', 'dim_2304', 'dim_2305', 'dim_2306', 'dim_2310', 'dim_2311', 'dim_2312', 'dim_2317', 'dim_2318', 'dim_2322', 'dim_2323', 'dim_2324', 'dim_2328', 'dim_2329', 'dim_2330', 'dim_2334', 'dim_2335', 'dim_2336', 'dim_2340', 'dim_2341', 'dim_2342', 'dim_2346', 'dim_2347', 'dim_2352', 'dim_2353', 'dim_2354', 'dim_2358', 'dim_2359', 'dim_2364', 'dim_2365', 'dim_2366', 'dim_2370', 'dim_2371', 'dim_2375', 'dim_2376', 'dim_2377', 'dim_2378', 'dim_2382', 'dim_2383', 'dim_2387', 'dim_2388', 'dim_2389', 'dim_2390', 'dim_2393', 'dim_2394', 'dim_2395', 'dim_2399', 'dim_2400', 'dim_2401', 'dim_2402', 'dim_2405', 'dim_2406', 'dim_2407', 'dim_2411', 'dim_2412', 'dim_2413', 'dim_2414', 'dim_2418', 'dim_2422', 'dim_2423', 'dim_2424', 'dim_2425', 'dim_2426', 'dim_2429', 'dim_2430', 'dim_2434', 'dim_2435', 'dim_2436', 'dim_2437', 'dim_2438', 'dim_2441', 'dim_2442', 'dim_2445', 'dim_2446', 'dim_2447', 'dim_2448', 'dim_2449', 'dim_2450', 'dim_2454', 'dim_2457', 'dim_2458', 'dim_2459', 'dim_2460', 'dim_2461', 'dim_2462', 'dim_2466', 'dim_2469', 'dim_2470', 'dim_2471', 'dim_2472', 'dim_2473', 'dim_2474', 'dim_2480', 'dim_2481', 'dim_2482', 'dim_2483', 'dim_2484', 'dim_2485', 'dim_2486', 'dim_2492', 'dim_2493', 'dim_2494', 'dim_2495', 'dim_2496', 'dim_2497', 'dim_2498', 'dim_2499', 'dim_2503', 'dim_2504', 'dim_2505', 'dim_2506', 'dim_2507', 'dim_2508', 'dim_2509', 'dim_2510', 'dim_2511', 'dim_2512', 'dim_2513', 'dim_2514', 'dim_2515', 'dim_2516', 'dim_2517', 'dim_2518', 'dim_2519', 'dim_2520', 'dim_2521', 'dim_2522', 'dim_2523', 'dim_2524', 'dim_2526', 'dim_2527', 'dim_2528', 'dim_2529', 'dim_2530', 'dim_2531', 'dim_2532', 'dim_2533', 'dim_2534', 'dim_2535', 'dim_2536', 'dim_2538', 'dim_2539', 'dim_2540', 'dim_2541', 'dim_2542', 'dim_2543', 'dim_2544', 'dim_2545', 'dim_2546', 'dim_2548', 'dim_2551', 'dim_2552', 'dim_2553', 'dim_2554', 'dim_2555', 'dim_2556', 'dim_2557', 'dim_2558', 'dim_2559', 'dim_2567', 'dim_2568', 'dim_2569', 'dim_2570', 'dim_2579', 'dim_2580', 'dim_2581', 'dim_2582', 'dim_2591', 'dim_2592', 'dim_2593', 'dim_2594', 'dim_2598', 'dim_2599', 'dim_2604', 'dim_2605', 'dim_2606', 'dim_2611', 'dim_2616', 'dim_2617', 'dim_2618', 'dim_2623', 'dim_2628', 'dim_2629', 'dim_2630', 'dim_2635', 'dim_2641', 'dim_2642', 'dim_2647', 'dim_2653', 'dim_2654', 'dim_2658', 'dim_2659', 'dim_2664', 'dim_2665', 'dim_2666', 'dim_2670', 'dim_2671', 'dim_2676', 'dim_2677', 'dim_2678', 'dim_2682', 'dim_2683', 'dim_2688', 'dim_2689', 'dim_2690', 'dim_2694', 'dim_2695', 'dim_2700', 'dim_2701', 'dim_2702', 'dim_2706', 'dim_2707', 'dim_2712', 'dim_2713', 'dim_2714', 'dim_2718', 'dim_2719', 'dim_2720', 'dim_2725', 'dim_2726', 'dim_2730', 'dim_2731', 'dim_2732', 'dim_2736', 'dim_2737', 'dim_2738', 'dim_2742', 'dim_2743', 'dim_2744', 'dim_2748', 'dim_2749', 'dim_2750', 'dim_2754', 'dim_2755', 'dim_2756', 'dim_2760', 'dim_2761', 'dim_2762', 'dim_2766', 'dim_2767', 'dim_2772', 'dim_2773', 'dim_2774', 'dim_2778', 'dim_2779', 'dim_2784', 'dim_2785', 'dim_2786', 'dim_2790', 'dim_2791', 'dim_2795', 'dim_2796', 'dim_2797', 'dim_2798', 'dim_2802', 'dim_2803', 'dim_2807', 'dim_2808', 'dim_2809', 'dim_2810', 'dim_2813', 'dim_2814', 'dim_2815', 'dim_2819', 'dim_2820', 'dim_2821', 'dim_2822', 'dim_2826', 'dim_2827', 'dim_2831', 'dim_2832', 'dim_2833', 'dim_2834', 'dim_2838', 'dim_2842', 'dim_2843', 'dim_2844', 'dim_2845', 'dim_2846', 'dim_2849', 'dim_2850', 'dim_2854', 'dim_2855', 'dim_2856', 'dim_2857', 'dim_2858', 'dim_2861', 'dim_2862', 'dim_2865', 'dim_2866', 'dim_2867', 'dim_2868', 'dim_2869', 'dim_2870', 'dim_2874', 'dim_2877', 'dim_2878', 'dim_2879', 'dim_2880', 'dim_2881', 'dim_2882', 'dim_2886', 'dim_2889', 'dim_2890', 'dim_2891', 'dim_2892', 'dim_2893', 'dim_2894', 'dim_2900', 'dim_2901', 'dim_2902', 'dim_2903', 'dim_2904', 'dim_2905', 'dim_2906', 'dim_2912', 'dim_2913', 'dim_2914', 'dim_2915', 'dim_2916', 'dim_2917', 'dim_2918', 'dim_2919', 'dim_2923', 'dim_2924', 'dim_2925', 'dim_2926', 'dim_2927', 'dim_2928', 'dim_2929', 'dim_2930', 'dim_2931', 'dim_2932', 'dim_2933', 'dim_2934', 'dim_2935', 'dim_2936', 'dim_2937', 'dim_2938', 'dim_2939', 'dim_2940', 'dim_2941', 'dim_2942', 'dim_2943', 'dim_2944', 'dim_2945', 'dim_2946', 'dim_2947', 'dim_2948', 'dim_2949', 'dim_2950', 'dim_2951', 'dim_2952', 'dim_2953', 'dim_2954', 'dim_2955', 'dim_2956', 'dim_2957', 'dim_2958', 'dim_2959', 'dim_2960', 'dim_2961', 'dim_2962', 'dim_2963', 'dim_2964', 'dim_2965', 'dim_2966', 'dim_2967', 'dim_2968', 'dim_2971', 'dim_2972', 'dim_2973', 'dim_2974', 'dim_2975', 'dim_2976', 'dim_2977', 'dim_2978', 'dim_2979', 'dim_2985', 'dim_2987', 'dim_2988', 'dim_2989', 'dim_2990', 'dim_2999', 'dim_3000', 'dim_3001', 'dim_3002', 'dim_3011', 'dim_3012', 'dim_3013', 'dim_3014', 'dim_3019', 'dim_3024', 'dim_3025', 'dim_3026', 'dim_3031', 'dim_3036', 'dim_3037', 'dim_3038', 'dim_3043', 'dim_3048', 'dim_3049', 'dim_3050', 'dim_3054', 'dim_3055', 'dim_3061', 'dim_3062', 'dim_3066', 'dim_3067', 'dim_3073', 'dim_3074', 'dim_3078', 'dim_3079', 'dim_3085', 'dim_3086', 'dim_3090', 'dim_3091', 'dim_3096', 'dim_3097', 'dim_3098', 'dim_3102', 'dim_3103', 'dim_3108', 'dim_3109', 'dim_3110', 'dim_3114', 'dim_3115', 'dim_3116', 'dim_3120', 'dim_3121', 'dim_3122', 'dim_3126', 'dim_3127', 'dim_3128', 'dim_3132', 'dim_3133', 'dim_3134', 'dim_3138', 'dim_3139', 'dim_3140', 'dim_3144', 'dim_3145', 'dim_3146', 'dim_3150', 'dim_3151', 'dim_3152', 'dim_3156', 'dim_3157', 'dim_3158', 'dim_3162', 'dim_3163', 'dim_3164', 'dim_3168', 'dim_3169', 'dim_3170', 'dim_3174', 'dim_3175', 'dim_3176', 'dim_3180', 'dim_3181', 'dim_3182', 'dim_3186', 'dim_3187', 'dim_3192', 'dim_3193', 'dim_3194', 'dim_3198', 'dim_3199', 'dim_3204', 'dim_3205', 'dim_3206', 'dim_3210', 'dim_3211', 'dim_3215', 'dim_3216', 'dim_3217', 'dim_3218', 'dim_3222', 'dim_3223', 'dim_3227', 'dim_3228', 'dim_3229', 'dim_3230', 'dim_3234', 'dim_3235', 'dim_3239', 'dim_3240', 'dim_3241', 'dim_3242', 'dim_3246', 'dim_3247', 'dim_3250', 'dim_3251', 'dim_3252', 'dim_3253', 'dim_3254', 'dim_3258', 'dim_3262', 'dim_3263', 'dim_3264', 'dim_3265', 'dim_3266', 'dim_3270', 'dim_3273', 'dim_3274', 'dim_3275', 'dim_3276', 'dim_3277', 'dim_3278', 'dim_3282', 'dim_3285', 'dim_3286', 'dim_3287', 'dim_3288', 'dim_3289', 'dim_3290', 'dim_3294', 'dim_3297', 'dim_3298', 'dim_3299', 'dim_3300', 'dim_3301', 'dim_3302', 'dim_3306', 'dim_3309', 'dim_3310', 'dim_3311', 'dim_3312', 'dim_3313', 'dim_3314', 'dim_3320', 'dim_3321', 'dim_3322', 'dim_3323', 'dim_3324', 'dim_3325', 'dim_3326', 'dim_3332', 'dim_3333', 'dim_3334', 'dim_3335', 'dim_3336', 'dim_3337', 'dim_3338', 'dim_3339', 'dim_3343', 'dim_3344', 'dim_3345', 'dim_3346', 'dim_3347', 'dim_3348', 'dim_3349', 'dim_3350', 'dim_3351', 'dim_3352', 'dim_3353', 'dim_3354', 'dim_3355', 'dim_3356', 'dim_3357', 'dim_3358', 'dim_3359', 'dim_3360', 'dim_3361', 'dim_3362', 'dim_3363', 'dim_3364', 'dim_3365', 'dim_3366', 'dim_3367', 'dim_3368', 'dim_3369', 'dim_3370', 'dim_3371', 'dim_3372', 'dim_3373', 'dim_3374', 'dim_3375', 'dim_3376', 'dim_3377', 'dim_3378', 'dim_3379', 'dim_3380', 'dim_3381', 'dim_3382', 'dim_3383', 'dim_3384', 'dim_3385', 'dim_3386', 'dim_3387', 'dim_3388', 'dim_3391', 'dim_3392', 'dim_3393', 'dim_3394', 'dim_3395', 'dim_3396', 'dim_3397', 'dim_3398', 'dim_3399', 'dim_3400', 'dim_3405', 'dim_3406', 'dim_3407', 'dim_3408', 'dim_3409', 'dim_3410', 'dim_3419', 'dim_3420', 'dim_3421', 'dim_3422', 'dim_3431', 'dim_3432', 'dim_3433', 'dim_3434', 'dim_3444', 'dim_3445', 'dim_3446', 'dim_3451', 'dim_3456', 'dim_3457', 'dim_3458', 'dim_3462', 'dim_3463', 'dim_3468', 'dim_3469', 'dim_3470', 'dim_3474', 'dim_3475', 'dim_3480', 'dim_3481', 'dim_3482', 'dim_3486', 'dim_3487', 'dim_3492', 'dim_3493', 'dim_3494', 'dim_3497', 'dim_3498', 'dim_3499', 'dim_3504', 'dim_3505', 'dim_3506', 'dim_3510', 'dim_3511', 'dim_3512', 'dim_3516', 'dim_3517', 'dim_3518', 'dim_3522', 'dim_3523', 'dim_3524', 'dim_3528', 'dim_3529', 'dim_3530', 'dim_3534', 'dim_3535', 'dim_3536', 'dim_3541', 'dim_3542', 'dim_3546', 'dim_3547', 'dim_3548', 'dim_3552', 'dim_3553', 'dim_3554', 'dim_3558', 'dim_3559', 'dim_3560', 'dim_3564', 'dim_3565', 'dim_3566', 'dim_3570', 'dim_3571', 'dim_3572', 'dim_3576', 'dim_3577', 'dim_3578', 'dim_3582', 'dim_3583', 'dim_3584', 'dim_3588', 'dim_3589', 'dim_3590', 'dim_3594', 'dim_3595', 'dim_3596', 'dim_3600', 'dim_3601', 'dim_3602', 'dim_3606', 'dim_3607', 'dim_3612', 'dim_3613', 'dim_3614', 'dim_3618', 'dim_3619', 'dim_3624', 'dim_3625', 'dim_3626', 'dim_3630', 'dim_3631', 'dim_3635', 'dim_3636', 'dim_3637', 'dim_3638', 'dim_3642', 'dim_3643', 'dim_3647', 'dim_3648', 'dim_3649', 'dim_3650', 'dim_3653', 'dim_3654', 'dim_3655', 'dim_3659', 'dim_3660', 'dim_3661', 'dim_3662', 'dim_3665', 'dim_3666', 'dim_3667', 'dim_3670', 'dim_3671', 'dim_3672', 'dim_3673', 'dim_3674', 'dim_3678', 'dim_3682', 'dim_3683', 'dim_3684', 'dim_3685', 'dim_3686', 'dim_3689', 'dim_3690', 'dim_3693', 'dim_3694', 'dim_3695', 'dim_3696', 'dim_3697', 'dim_3698', 'dim_3701', 'dim_3702', 'dim_3705', 'dim_3706', 'dim_3707', 'dim_3708', 'dim_3709', 'dim_3710', 'dim_3714', 'dim_3717', 'dim_3718', 'dim_3719', 'dim_3720', 'dim_3721', 'dim_3722', 'dim_3729', 'dim_3730', 'dim_3731', 'dim_3732', 'dim_3733', 'dim_3734', 'dim_3740', 'dim_3741', 'dim_3742', 'dim_3743', 'dim_3744', 'dim_3745', 'dim_3746', 'dim_3752', 'dim_3753', 'dim_3754', 'dim_3755', 'dim_3756', 'dim_3757', 'dim_3758', 'dim_3759', 'dim_3762', 'dim_3763', 'dim_3764', 'dim_3765', 'dim_3766', 'dim_3767', 'dim_3768', 'dim_3769', 'dim_3770', 'dim_3771', 'dim_3772', 'dim_3773', 'dim_3774', 'dim_3775', 'dim_3776', 'dim_3777', 'dim_3778', 'dim_3779', 'dim_3780', 'dim_3781', 'dim_3782', 'dim_3783', 'dim_3784', 'dim_3785', 'dim_3786', 'dim_3787', 'dim_3788', 'dim_3789', 'dim_3790', 'dim_3791', 'dim_3792', 'dim_3793', 'dim_3794', 'dim_3795', 'dim_3796', 'dim_3797', 'dim_3798', 'dim_3799', 'dim_3800', 'dim_3801', 'dim_3802', 'dim_3803', 'dim_3804', 'dim_3805', 'dim_3806', 'dim_3807', 'dim_3808', 'dim_3811', 'dim_3812', 'dim_3813', 'dim_3814', 'dim_3815', 'dim_3816', 'dim_3817', 'dim_3818', 'dim_3819', 'dim_3820', 'dim_3824', 'dim_3826', 'dim_3827', 'dim_3828', 'dim_3829', 'dim_3830', 'dim_3839', 'dim_3840', 'dim_3841', 'dim_3842', 'dim_3851', 'dim_3852', 'dim_3853', 'dim_3854', 'dim_3863', 'dim_3864', 'dim_3865', 'dim_3875', 'dim_3876', 'dim_3883', 'dim_3887', 'dim_3888', 'dim_3895', 'dim_3899', 'dim_3900', 'dim_3907', 'dim_3911', 'dim_3912', 'dim_3913', 'dim_3919', 'dim_3923', 'dim_3924', 'dim_3925', 'dim_3931', 'dim_3935', 'dim_3936', 'dim_3937', 'dim_3943', 'dim_3947', 'dim_3948', 'dim_3949', 'dim_3950', 'dim_3955', 'dim_3959', 'dim_3960', 'dim_3961', 'dim_3962', 'dim_3967', 'dim_3971', 'dim_3972', 'dim_3973', 'dim_3974', 'dim_3979', 'dim_3983', 'dim_3984', 'dim_3985', 'dim_3986', 'dim_3990', 'dim_3991', 'dim_3995', 'dim_3996', 'dim_3997', 'dim_3998', 'dim_4002', 'dim_4003', 'dim_4007', 'dim_4008', 'dim_4009', 'dim_4010', 'dim_4014', 'dim_4019', 'dim_4020', 'dim_4021', 'dim_4022', 'dim_4026', 'dim_4031', 'dim_4032', 'dim_4033', 'dim_4034', 'dim_4038', 'dim_4043', 'dim_4044', 'dim_4045', 'dim_4046', 'dim_4050', 'dim_4055', 'dim_4056', 'dim_4057', 'dim_4058', 'dim_4062', 'dim_4067', 'dim_4068', 'dim_4069', 'dim_4070', 'dim_4074', 'dim_4079', 'dim_4080', 'dim_4081', 'dim_4082', 'dim_4086', 'dim_4090', 'dim_4091', 'dim_4092', 'dim_4093', 'dim_4102', 'dim_4103', 'dim_4104', 'dim_4113', 'dim_4114', 'dim_4115', 'dim_4116', 'dim_4125', 'dim_4126', 'dim_4127', 'dim_4128', 'dim_4137', 'dim_4138', 'dim_4139', 'dim_4140', 'dim_4141', 'dim_4142', 'dim_4149', 'dim_4150', 'dim_4151', 'dim_4152', 'dim_4153', 'dim_4154', 'dim_4160', 'dim_4161', 'dim_4162', 'dim_4163', 'dim_4164', 'dim_4165', 'dim_4166', 'dim_4167', 'dim_4172', 'dim_4173', 'dim_4174', 'dim_4175', 'dim_4176', 'dim_4177', 'dim_4178', 'dim_4179', 'dim_4180', 'dim_4183', 'dim_4184', 'dim_4185', 'dim_4186', 'dim_4187', 'dim_4188', 'dim_4189', 'dim_4190', 'dim_4191', 'dim_4192', 'dim_4193', 'dim_4194', 'dim_4195', 'dim_4196', 'dim_4197', 'dim_4198', 'dim_4199', 'dim_4200', 'dim_4201', 'dim_4202', 'dim_4203', 'dim_4204', 'dim_4205', 'dim_4206', 'dim_4207', 'dim_4208', 'dim_4209', 'dim_4210', 'dim_4211', 'dim_4212', 'dim_4213', 'dim_4214', 'dim_4215', 'dim_4216', 'dim_4217', 'dim_4218', 'dim_4219', 'dim_4220', 'dim_4221', 'dim_4222', 'dim_4223', 'dim_4224', 'dim_4225', 'dim_4226', 'dim_4227', 'dim_4228', 'dim_4229', 'dim_4231', 'dim_4232', 'dim_4233', 'dim_4234', 'dim_4235', 'dim_4236', 'dim_4237', 'dim_4238', 'dim_4239', 'dim_4240', 'dim_4244', 'dim_4246', 'dim_4247', 'dim_4248', 'dim_4249', 'dim_4250', 'dim_4251', 'dim_4252', 'dim_4259', 'dim_4260', 'dim_4261', 'dim_4262', 'dim_4263', 'dim_4270', 'dim_4271', 'dim_4272', 'dim_4273', 'dim_4274', 'dim_4282', 'dim_4283', 'dim_4284', 'dim_4285', 'dim_4286', 'dim_4294', 'dim_4295', 'dim_4296', 'dim_4297', 'dim_4298', 'dim_4305', 'dim_4306', 'dim_4307', 'dim_4308', 'dim_4309', 'dim_4317', 'dim_4318', 'dim_4319', 'dim_4320', 'dim_4321', 'dim_4329', 'dim_4330', 'dim_4331', 'dim_4332', 'dim_4333', 'dim_4342', 'dim_4343', 'dim_4344', 'dim_4345', 'dim_4354', 'dim_4355', 'dim_4356', 'dim_4357', 'dim_4366', 'dim_4367', 'dim_4368', 'dim_4369', 'dim_4370', 'dim_4371', 'dim_4378', 'dim_4379', 'dim_4380', 'dim_4381', 'dim_4382', 'dim_4383', 'dim_4390', 'dim_4391', 'dim_4392', 'dim_4393', 'dim_4394', 'dim_4395', 'dim_4402', 'dim_4403', 'dim_4404', 'dim_4405', 'dim_4406', 'dim_4407', 'dim_4414', 'dim_4415', 'dim_4416', 'dim_4417', 'dim_4418', 'dim_4419', 'dim_4426', 'dim_4427', 'dim_4428', 'dim_4429', 'dim_4430', 'dim_4431', 'dim_4438', 'dim_4439', 'dim_4440', 'dim_4441', 'dim_4442', 'dim_4443', 'dim_4450', 'dim_4451', 'dim_4452', 'dim_4453', 'dim_4454', 'dim_4455', 'dim_4462', 'dim_4463', 'dim_4464', 'dim_4465', 'dim_4466', 'dim_4467', 'dim_4474', 'dim_4475', 'dim_4476', 'dim_4477', 'dim_4478', 'dim_4479', 'dim_4485', 'dim_4486', 'dim_4487', 'dim_4488', 'dim_4489', 'dim_4490', 'dim_4497', 'dim_4498', 'dim_4499', 'dim_4500', 'dim_4501', 'dim_4502', 'dim_4509', 'dim_4510', 'dim_4511', 'dim_4512', 'dim_4513', 'dim_4514', 'dim_4521', 'dim_4522', 'dim_4523', 'dim_4524', 'dim_4525', 'dim_4533', 'dim_4534', 'dim_4535', 'dim_4536', 'dim_4537', 'dim_4544', 'dim_4545', 'dim_4546', 'dim_4547', 'dim_4548', 'dim_4549', 'dim_4550', 'dim_4556', 'dim_4557', 'dim_4558', 'dim_4559', 'dim_4560', 'dim_4561', 'dim_4562', 'dim_4568', 'dim_4569', 'dim_4570', 'dim_4571', 'dim_4572', 'dim_4573', 'dim_4574', 'dim_4575', 'dim_4580', 'dim_4581', 'dim_4582', 'dim_4583', 'dim_4584', 'dim_4585', 'dim_4586', 'dim_4587', 'dim_4588', 'dim_4591', 'dim_4592', 'dim_4593', 'dim_4594', 'dim_4595', 'dim_4596', 'dim_4597', 'dim_4598', 'dim_4599', 'dim_4600', 'dim_4601', 'dim_4602', 'dim_4603', 'dim_4604', 'dim_4605', 'dim_4606', 'dim_4607', 'dim_4608', 'dim_4609', 'dim_4610', 'dim_4611', 'dim_4612', 'dim_4613', 'dim_4614', 'dim_4615', 'dim_4616', 'dim_4617', 'dim_4618', 'dim_4619', 'dim_4620', 'dim_4621', 'dim_4622', 'dim_4623', 'dim_4624', 'dim_4625', 'dim_4626', 'dim_4627', 'dim_4628', 'dim_4629', 'dim_4630', 'dim_4631', 'dim_4632', 'dim_4633', 'dim_4634', 'dim_4635', 'dim_4636', 'dim_4637', 'dim_4638', 'dim_4639', 'dim_4640', 'dim_4641', 'dim_4642', 'dim_4643', 'dim_4644', 'dim_4645', 'dim_4646', 'dim_4647', 'dim_4648', 'dim_4649', 'dim_4650', 'dim_4651', 'dim_4652', 'dim_4653', 'dim_4654', 'dim_4655', 'dim_4656', 'dim_4657', 'dim_4658', 'dim_4659', 'dim_4660', 'dim_4661', 'dim_4662', 'dim_4663', 'dim_4664', 'dim_4665', 'dim_4666', 'dim_4667', 'dim_4668', 'dim_4669', 'dim_4670', 'dim_4671', 'dim_4672', 'dim_4673', 'dim_4674', 'dim_4675', 'dim_4676', 'dim_4677', 'dim_4678', 'dim_4679', 'dim_4680', 'dim_4681', 'dim_4682', 'dim_4683', 'dim_4684', 'dim_4685', 'dim_4687', 'dim_4688', 'dim_4689', 'dim_4690', 'dim_4691', 'dim_4692', 'dim_4693', 'dim_4694', 'dim_4695', 'dim_4696', 'dim_4700', 'dim_4701', 'dim_4702', 'dim_4703', 'dim_4704', 'dim_4705', 'dim_4706', 'dim_4707', 'dim_4709', 'dim_4710', 'dim_4712', 'dim_4713', 'dim_4714', 'dim_4715', 'dim_4716', 'dim_4717', 'dim_4718', 'dim_4719', 'dim_4725', 'dim_4726', 'dim_4727', 'dim_4728', 'dim_4729', 'dim_4730', 'dim_4731', 'dim_4733', 'dim_4736', 'dim_4737', 'dim_4738', 'dim_4739', 'dim_4740', 'dim_4741', 'dim_4742', 'dim_4743', 'dim_4744', 'dim_4745', 'dim_4748', 'dim_4749', 'dim_4750', 'dim_4751', 'dim_4752', 'dim_4753', 'dim_4754', 'dim_4755', 'dim_4756', 'dim_4760', 'dim_4761', 'dim_4762', 'dim_4763', 'dim_4764', 'dim_4765', 'dim_4766', 'dim_4767', 'dim_4772', 'dim_4773', 'dim_4774', 'dim_4775', 'dim_4776', 'dim_4777', 'dim_4778', 'dim_4779', 'dim_4782', 'dim_4784', 'dim_4785', 'dim_4786', 'dim_4787', 'dim_4788', 'dim_4789', 'dim_4790', 'dim_4791', 'dim_4794', 'dim_4795', 'dim_4796', 'dim_4797', 'dim_4798', 'dim_4799', 'dim_4800', 'dim_4801', 'dim_4802', 'dim_4803', 'dim_4805', 'dim_4806', 'dim_4807', 'dim_4808', 'dim_4809', 'dim_4810', 'dim_4811', 'dim_4812', 'dim_4813', 'dim_4814', 'dim_4815', 'dim_4817', 'dim_4818', 'dim_4819', 'dim_4820', 'dim_4821', 'dim_4822', 'dim_4823', 'dim_4824', 'dim_4825', 'dim_4826', 'dim_4827', 'dim_4829', 'dim_4830', 'dim_4831', 'dim_4832', 'dim_4833', 'dim_4834', 'dim_4835', 'dim_4836', 'dim_4837', 'dim_4838', 'dim_4839', 'dim_4841', 'dim_4842', 'dim_4843', 'dim_4844', 'dim_4845', 'dim_4846', 'dim_4847', 'dim_4848', 'dim_4849', 'dim_4850', 'dim_4851', 'dim_4853', 'dim_4854', 'dim_4855', 'dim_4856', 'dim_4857', 'dim_4858', 'dim_4859', 'dim_4860', 'dim_4861', 'dim_4862', 'dim_4863', 'dim_4865', 'dim_4866', 'dim_4867', 'dim_4868', 'dim_4869', 'dim_4870', 'dim_4871', 'dim_4872', 'dim_4873', 'dim_4874', 'dim_4875', 'dim_4877', 'dim_4878', 'dim_4879', 'dim_4880', 'dim_4881', 'dim_4882', 'dim_4883', 'dim_4884', 'dim_4885', 'dim_4886', 'dim_4887', 'dim_4889', 'dim_4890', 'dim_4891', 'dim_4892', 'dim_4893', 'dim_4894', 'dim_4895', 'dim_4896', 'dim_4897', 'dim_4898', 'dim_4899', 'dim_4901', 'dim_4902', 'dim_4903', 'dim_4904', 'dim_4905', 'dim_4906', 'dim_4907', 'dim_4908', 'dim_4909', 'dim_4910', 'dim_4911', 'dim_4913', 'dim_4914', 'dim_4915', 'dim_4916', 'dim_4917', 'dim_4918', 'dim_4919', 'dim_4920', 'dim_4921', 'dim_4922', 'dim_4923', 'dim_4924', 'dim_4925', 'dim_4926', 'dim_4927', 'dim_4928', 'dim_4929', 'dim_4930', 'dim_4931', 'dim_4932', 'dim_4933', 'dim_4934', 'dim_4935', 'dim_4936', 'dim_4938', 'dim_4939', 'dim_4940', 'dim_4941', 'dim_4942', 'dim_4943', 'dim_4944', 'dim_4945', 'dim_4946', 'dim_4947', 'dim_4948', 'dim_4952', 'dim_4953', 'dim_4954', 'dim_4955', 'dim_4956', 'dim_4957', 'dim_4958', 'dim_4959', 'dim_4960', 'dim_4964', 'dim_4965', 'dim_4966', 'dim_4967', 'dim_4968', 'dim_4969', 'dim_4970', 'dim_4971', 'dim_4972', 'dim_4975', 'dim_4976', 'dim_4977', 'dim_4978', 'dim_4979', 'dim_4980', 'dim_4981', 'dim_4982', 'dim_4983', 'dim_4984', 'dim_4985', 'dim_4986', 'dim_4987', 'dim_4988', 'dim_4989', 'dim_4990', 'dim_4991', 'dim_4992', 'dim_4993', 'dim_4994', 'dim_4995', 'dim_4996', 'dim_4997', 'dim_4998', 'dim_4999', 'dim_5000', 'dim_5001', 'dim_5002', 'dim_5003', 'dim_5004', 'dim_5005', 'dim_5006', 'dim_5007', 'dim_5008', 'dim_5009', 'dim_5010', 'dim_5011', 'dim_5012', 'dim_5013', 'dim_5014', 'dim_5015', 'dim_5016', 'dim_5017', 'dim_5018', 'dim_5019', 'dim_5020', 'dim_5021', 'dim_5022', 'dim_5023', 'dim_5024', 'dim_5025', 'dim_5026', 'dim_5027', 'dim_5028', 'dim_5029', 'dim_5030', 'dim_5031', 'dim_5032', 'dim_5033', 'dim_5034', 'dim_5035', 'dim_5036', 'dim_5037', 'dim_5038', 'dim_5039', 'dim_5040']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('int8', 'int') : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n",
      "\t8.2s = Fit runtime\n",
      "\t2064 features in original data used to generate 2064 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.72 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 8.59s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-5040/learner.pkl\n",
      "Saving ./agModels-5040/utils/data/X.pkl\n",
      "Saving ./agModels-5040/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 2064 of 2064 features.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 2064 of 2064 features.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0486\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.52s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0486\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.56s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 2064 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0483\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.63s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0475\t = Validation score   (-root_mean_squared_error)\n",
      "\t1544.38s\t = Training   runtime\n",
      "\t3.25s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 2064 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0484\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.13s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0458\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.37s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0488\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.39s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.0464\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.18s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 2064 features.\n",
      "\tDropped 0 of 2064 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2064 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0479\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.09s\t = Training   runtime\n",
      "\t0.37s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 6\n",
      "Ensemble indices: [5, 7, 8, 5, 7, 5]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.         0.5\n",
      " 0.         0.33333333 0.16666667]\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.0451\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.5s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0473\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.74s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0473\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.63s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 2073 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.18s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0476\t = Validation score   (-root_mean_squared_error)\n",
      "\t71.19s\t = Training   runtime\n",
      "\t2.33s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 2073 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.45s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0457\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.46s\t = Training   runtime\n",
      "\t0.8s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.0489\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.36s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0458\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.11s\t = Training   runtime\n",
      "\t0.78s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.0491\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.28s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 21\n",
      "Ensemble indices: [5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.         0.52380952\n",
      " 0.         0.47619048 0.        ]\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.0449\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.94s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0468\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.66s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 2073 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.0469\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.23s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t90.85s\t = Training   runtime\n",
      "\t2.16s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 2073 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0473\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.0464\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.91s\t = Training   runtime\n",
      "\t0.45s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0478\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.67s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.0462\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.47s\t = Training   runtime\n",
      "\t0.43s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0469\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.51s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 10\n",
      "Ensemble indices: [7, 5, 8, 5, 8, 7, 5, 7, 8, 5]\n",
      "Ensemble weights: \n",
      "[0.  0.  0.  0.  0.  0.4 0.  0.3 0.3]\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.0451\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.44s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.0468\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.26s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0461\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.5s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 2073 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.0472\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.41s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0475\t = Validation score   (-root_mean_squared_error)\n",
      "\t961.92s\t = Training   runtime\n",
      "\t2.0s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 2073 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0473\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.0s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.0474\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.51s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.0476\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.59s\t = Training   runtime\n",
      "\t0.41s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.0469\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.25s\t = Training   runtime\n",
      "\t0.69s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 2073 features.\n",
      "\tDropped 0 of 2073 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 2073 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.0483\t = Validation score   (-root_mean_squared_error)\n",
      "\t48.99s\t = Training   runtime\n",
      "\t0.63s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 15\n",
      "Ensemble indices: [1, 5, 1, 7, 1, 1, 5, 1, 1, 5, 7, 1, 1, 5, 1]\n",
      "Ensemble weights: \n",
      "[0.         0.6        0.         0.         0.         0.26666667\n",
      " 0.         0.13333333 0.        ]\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-5040/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0457\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 3131.4s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Loading: ./agModels-5040/models/trainer.pkl\n",
      "Saving ./agModels-5040/models/trainer.pkl\n",
      "Saving ./agModels-5040/learner.pkl\n",
      "Saving ./agModels-5040/predictor.pkl\n",
      "Saving ./agModels-5040/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-5040/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-5040/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-5040'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_5031</th>\n",
       "      <th>dim_5032</th>\n",
       "      <th>dim_5033</th>\n",
       "      <th>dim_5034</th>\n",
       "      <th>dim_5035</th>\n",
       "      <th>dim_5036</th>\n",
       "      <th>dim_5037</th>\n",
       "      <th>dim_5038</th>\n",
       "      <th>dim_5039</th>\n",
       "      <th>dim_5040</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 5040 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "46     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "101    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "175    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "9      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "136    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_5031  dim_5032  dim_5033  dim_5034  dim_5035  dim_5036  \\\n",
       "46   ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "101  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "175  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9    ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "136  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "     dim_5037  dim_5038  dim_5039  dim_5040  \n",
       "46        0.0       0.0       0.0       0.0  \n",
       "101       0.0       0.0       0.0       0.0  \n",
       "175       0.0       0.0       0.0       0.0  \n",
       "9         0.0       0.0       0.0       0.0  \n",
       "136       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 5040 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-5040/predictor.pkl\n",
      "Loading: ./agModels-5040/learner.pkl\n",
      "Loading: ./agModels-5040/models/trainer.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L3/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.0433683735142141\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.0433683735142141,\n",
      "    \"mean_squared_error\": -0.0018808158212683867,\n",
      "    \"mean_absolute_error\": -0.031108732914382764,\n",
      "    \"r2\": 0.36039966288989234,\n",
      "    \"pearsonr\": 0.6034750660626828,\n",
      "    \"median_absolute_error\": -0.022203582286834722\n",
      "}\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'LightGBMXT_BAG_L1': -0.046267265258455564, 'LightGBM_BAG_L1': -0.04626726606707347, 'RandomForestMSE_BAG_L1': -0.04546359992112085, 'CatBoost_BAG_L1': -0.045164715611786706, 'ExtraTreesMSE_BAG_L1': -0.04535276153315227, 'NeuralNetFastAI_BAG_L1': -0.04724620394445908, 'XGBoost_BAG_L1': -0.04568240516380143, 'NeuralNetTorch_BAG_L1': -0.044929122246535357, 'LightGBMLarge_BAG_L1': -0.04559373389168442, 'WeightedEnsemble_L2': -0.04490251437474157, 'LightGBMXT_BAG_L2': -0.045234763409136854, 'LightGBM_BAG_L2': -0.044171972935409906, 'RandomForestMSE_BAG_L2': -0.04454270351405777, 'CatBoost_BAG_L2': -0.04482989062586722, 'ExtraTreesMSE_BAG_L2': -0.04441577068354805, 'NeuralNetFastAI_BAG_L2': -0.04389978746986761, 'XGBoost_BAG_L2': -0.045146320254408887, 'NeuralNetTorch_BAG_L2': -0.043982823337702495, 'LightGBMLarge_BAG_L2': -0.044336658133211214, 'WeightedEnsemble_L3': -0.0433683735142141, 'LightGBMXT_BAG_L3': -0.044973554709822984, 'LightGBM_BAG_L3': -0.044287699447753, 'RandomForestMSE_BAG_L3': -0.04469849530667515, 'CatBoost_BAG_L3': -0.0444874084432088, 'ExtraTreesMSE_BAG_L3': -0.04439296723645596, 'NeuralNetFastAI_BAG_L3': -0.04996219237534041, 'XGBoost_BAG_L3': -0.04549337325726509, 'NeuralNetTorch_BAG_L3': -0.04462831803711916, 'LightGBMLarge_BAG_L3': -0.045377565558747654, 'WeightedEnsemble_L4': -0.04512853543065548, 'LightGBMXT_BAG_L4': -0.04524113764740925, 'LightGBM_BAG_L4': -0.04567352178207308, 'RandomForestMSE_BAG_L4': -0.04507166935133479, 'CatBoost_BAG_L4': -0.04517353111179415, 'ExtraTreesMSE_BAG_L4': -0.04498126342369765, 'NeuralNetFastAI_BAG_L4': -0.04536922727159635, 'XGBoost_BAG_L4': -0.04581530527019634, 'NeuralNetTorch_BAG_L4': -0.0449873536751512, 'LightGBMLarge_BAG_L4': -0.045275689948099246, 'WeightedEnsemble_L5': -0.04463385480880448}\n"
     ]
    }
   ],
   "source": [
    "%%capture log_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%config Application.log_level = 'DEBUG'\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "with open('./output_5040.log', 'w') as f:\n",
    "    f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n",
      "AutoGluon identified the following types of features:\n",
      "('int', ['bool']) : 2064 | ['dim_66', 'dim_78', 'dim_79', 'dim_88', 'dim_91', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.38428235054016113\n",
      "0.38510990142822266\n",
      "0.41238659620285034\n",
      "0.41574937105178833\n",
      "0.38083726167678833\n",
      "0.3761400878429413\n",
      "0.4510166645050049\n",
      "0.37348002195358276\n",
      "0.34719768166542053\n",
      "0.3539859652519226\n",
      "0.36666029691696167\n",
      "0.5103806257247925\n",
      "0.47386929392814636\n",
      "0.3804554343223572\n",
      "0.4229687750339508\n",
      "0.46802085638046265\n",
      "0.3172735273838043\n",
      "0.3970341384410858\n",
      "0.5034539699554443\n",
      "0.3798315227031708\n",
      "0.4454766511917114\n",
      "0.4646073579788208\n",
      "0.35539907217025757\n",
      "0.44095420837402344\n",
      "0.40899431705474854\n",
      "0.44017019867897034\n",
      "0.37270230054855347\n",
      "0.4135913848876953\n",
      "0.3447558283805847\n",
      "0.3345256447792053\n",
      "0.4236149787902832\n",
      "0.4310152530670166\n",
      "0.48415011167526245\n",
      "0.4504208266735077\n",
      "0.3726995885372162\n",
      "0.3862597942352295\n",
      "0.3888712525367737\n",
      "0.4850280284881592\n",
      "0.35839107632637024\n",
      "0.34196847677230835\n",
      "0.5384864211082458\n",
      "0.3745603561401367\n",
      "0.3381596803665161\n",
      "0.31841379404067993\n",
      "0.36638137698173523\n",
      "0.39419782161712646\n",
      "0.4161071181297302\n",
      "0.41637122631073\n",
      "0.3464541435241699\n",
      "0.3911505341529846\n",
      "0.40686994791030884\n",
      "0.37365007400512695\n",
      "0.3751179575920105\n",
      "0.35753312706947327\n",
      "0.42857784032821655\n",
      "0.37232115864753723\n",
      "0.4303678572177887\n",
      "0.351596862077713\n",
      "0.35591453313827515\n",
      "0.378522127866745\n",
      "0.35320815443992615\n",
      "0.36126843094825745\n",
      "0.45139405131340027\n",
      "0.3752706050872803\n",
      "0.3772088289260864\n",
      "0.382923424243927\n",
      "0.38268226385116577\n",
      "0.33891552686691284\n",
      "0.4265260398387909\n",
      "0.3741741180419922\n",
      "0.3989340364933014\n",
      "0.4094482660293579\n",
      "0.38620615005493164\n",
      "0.37933701276779175\n",
      "0.3903810679912567\n",
      "0.40420615673065186\n",
      "0.4853036403656006\n",
      "0.4150152802467346\n",
      "0.38366520404815674\n",
      "0.43794798851013184\n",
      "0.4126034080982208\n",
      "0.4989582896232605\n",
      "0.35474827885627747\n",
      "0.3467341661453247\n",
      "0.3641979396343231\n",
      "0.4269469976425171\n",
      "0.3679448962211609\n",
      "0.4423174262046814\n",
      "0.4022321105003357\n",
      "0.4110012650489807\n",
      "0.362364262342453\n",
      "0.34316486120224\n",
      "0.4371126592159271\n",
      "0.36674824357032776\n",
      "0.4215015769004822\n",
      "0.3550947606563568\n",
      "0.39502429962158203\n",
      "0.3662507236003876\n",
      "0.5431328415870667\n",
      "0.34959012269973755\n",
      "0.4313974976539612\n",
      "0.41185879707336426\n",
      "0.3734452426433563\n",
      "0.4065059721469879\n",
      "0.42771029472351074\n",
      "0.3302536606788635\n",
      "0.3429524600505829\n",
      "0.42788165807724\n",
      "0.4032883942127228\n",
      "0.506432056427002\n",
      "0.3271806240081787\n",
      "0.42539381980895996\n",
      "0.3684297800064087\n",
      "0.398812472820282\n",
      "0.44340208172798157\n",
      "0.3939206004142761\n",
      "0.3490472137928009\n",
      "0.34543657302856445\n",
      "0.5428359508514404\n",
      "0.3656103312969208\n",
      "0.39754194021224976\n",
      "0.4069554805755615\n",
      "0.37754300236701965\n",
      "0.4381069540977478\n",
      "0.4585554003715515\n",
      "0.3618035614490509\n",
      "0.4344123601913452\n",
      "0.466869056224823\n",
      "0.3714911937713623\n",
      "0.3632938861846924\n",
      "0.35801446437835693\n",
      "0.4650294780731201\n",
      "0.3518911302089691\n",
      "0.38774120807647705\n",
      "0.4601820707321167\n",
      "0.42311733961105347\n",
      "0.40517711639404297\n",
      "0.4531187117099762\n",
      "0.3767741918563843\n",
      "0.37030237913131714\n",
      "0.43040382862091064\n",
      "0.4268414080142975\n",
      "0.39945465326309204\n",
      "0.3539500832557678\n",
      "0.40040215849876404\n",
      "0.370631605386734\n",
      "0.4085173010826111\n",
      "0.40908336639404297\n",
      "0.45749610662460327\n",
      "0.3504951596260071\n",
      "0.443223237991333\n",
      "0.45525333285331726\n",
      "0.49086910486221313\n",
      "0.4685910940170288\n",
      "0.38087591528892517\n",
      "0.36226314306259155\n",
      "0.3963214159011841\n",
      "0.4288335144519806\n",
      "0.3968108892440796\n",
      "0.3741605877876282\n",
      "0.48158177733421326\n",
      "0.3555375039577484\n",
      "0.4413239657878876\n",
      "0.41993406414985657\n",
      "0.36460286378860474\n",
      "0.363128125667572\n",
      "0.4059561491012573\n",
      "0.42539307475090027\n",
      "0.3324563801288605\n",
      "0.43891414999961853\n",
      "0.36631423234939575\n",
      "0.39572271704673767\n",
      "0.4045986831188202\n",
      "0.39444291591644287\n",
      "0.37294602394104004\n",
      "0.4491388499736786\n",
      "0.42422208189964294\n",
      "0.3783304989337921\n",
      "0.4393378496170044\n",
      "0.414342999458313\n",
      "0.38944172859191895\n",
      "0.3384140133857727\n",
      "0.4145752787590027\n",
      "0.3714837431907654\n",
      "0.37675875425338745\n",
      "0.35839515924453735\n",
      "0.44305098056793213\n",
      "0.34607455134391785\n",
      "0.4449949562549591\n",
      "0.3513631820678711\n",
      "0.48255330324172974\n",
      "0.3638564348220825\n",
      "0.36814257502555847\n",
      "0.5618268847465515\n",
      "0.469123512506485\n",
      "0.42409077286720276\n",
      "0.416664719581604\n",
      "0.4459645748138428\n",
      "0.3510112464427948\n",
      "0.4306707978248596\n",
      "0.4059951901435852\n",
      "0.42074185609817505\n",
      "0.357977032661438\n",
      "0.3449235260486603\n",
      "0.4226648807525635\n",
      "0.3438604474067688\n",
      "0.4073081314563751\n",
      "0.3951733112335205\n",
      "0.41176295280456543\n",
      "0.39715293049812317\n",
      "0.4927365779876709\n",
      "0.377950519323349\n",
      "0.33870425820350647\n",
      "0.42102286219596863\n",
      "0.37411022186279297\n",
      "0.37651872634887695\n",
      "0.37350696325302124\n",
      "0.4168257415294647\n",
      "0.4194793701171875\n",
      "0.4068481922149658\n",
      "0.3666630983352661\n",
      "0.34138616919517517\n",
      "0.47594738006591797\n",
      "0.3862273693084717\n",
      "0.44804853200912476\n",
      "0.33794230222702026\n",
      "0.3398173749446869\n",
      "0.42211002111434937\n",
      "0.378133088350296\n",
      "0.3373711407184601\n",
      "0.3874672055244446\n",
      "0.33399420976638794\n",
      "0.41340506076812744\n",
      "0.3714938461780548\n",
      "0.35921794176101685\n",
      "0.3446287512779236\n",
      "0.4913121163845062\n",
      "0.3586880564689636\n",
      "0.49216604232788086\n",
      "0.35317814350128174\n",
      "0.41040459275245667\n",
      "0.3873520791530609\n",
      "0.33643198013305664\n",
      "0.39985647797584534\n",
      "0.40651825070381165\n",
      "0.3989812731742859\n",
      "0.38237571716308594\n",
      "0.43309059739112854\n",
      "0.37613779306411743\n",
      "0.3820079565048218\n",
      "0.37654033303260803\n",
      "0.38117164373397827\n",
      "0.39285674691200256\n",
      "0.3951996862888336\n",
      "0.40056389570236206\n",
      "0.45857059955596924\n",
      "0.3574405312538147\n",
      "0.41396403312683105\n",
      "0.3645521402359009\n",
      "0.35847511887550354\n",
      "0.35606399178504944\n",
      "0.3663334548473358\n",
      "0.4646316468715668\n",
      "0.3614515960216522\n",
      "0.4386085271835327\n",
      "0.3705313503742218\n",
      "0.3694801330566406\n",
      "0.4761107563972473\n",
      "0.446767657995224\n",
      "0.3809894919395447\n",
      "0.4844071567058563\n",
      "0.4360218048095703\n",
      "0.40304577350616455\n",
      "0.3289479911327362\n",
      "0.34939369559288025\n",
      "0.42139336466789246\n",
      "0.33234894275665283\n",
      "0.34836655855178833\n",
      "0.4782646894454956\n",
      "0.37545639276504517\n",
      "0.4237014949321747\n",
      "0.3366142213344574\n",
      "0.39086538553237915\n",
      "0.3947572708129883\n",
      "0.373081773519516\n",
      "0.35090935230255127\n",
      "0.3356839418411255\n",
      "0.44997596740722656\n",
      "0.3971688747406006\n",
      "0.5088989734649658\n",
      "0.4050241708755493\n",
      "0.3709692358970642\n",
      "0.3237094283103943\n",
      "0.3601115047931671\n",
      "0.3684440851211548\n",
      "0.4289018511772156\n",
      "0.36244165897369385\n",
      "0.5694157481193542\n",
      "0.3578236699104309\n",
      "0.4415684640407562\n",
      "0.3972221612930298\n",
      "0.3461192846298218\n",
      "0.43038517236709595\n",
      "0.3530224561691284\n",
      "0.33561769127845764\n",
      "0.3964495062828064\n",
      "0.39256009459495544\n",
      "0.3712042272090912\n",
      "0.36380165815353394\n",
      "0.4645535945892334\n",
      "0.508142352104187\n",
      "0.5118312239646912\n",
      "0.42992067337036133\n",
      "0.38138189911842346\n",
      "0.4822511672973633\n",
      "0.4300345182418823\n",
      "0.41227826476097107\n",
      "0.437600314617157\n",
      "0.4065059721469879\n",
      "0.3992263376712799\n",
      "0.5404736399650574\n",
      "0.3586880564689636\n",
      "0.3457276523113251\n",
      "0.364905446767807\n",
      "0.3746330440044403\n",
      "0.45477983355522156\n",
      "0.41185009479522705\n",
      "0.4144923985004425\n",
      "0.31723058223724365\n",
      "0.38272103667259216\n",
      "0.4014222025871277\n",
      "0.3403477072715759\n",
      "0.43481916189193726\n",
      "0.4221729040145874\n",
      "0.3793095350265503\n",
      "0.44925427436828613\n",
      "0.3956294655799866\n",
      "0.4787447452545166\n",
      "0.3542766273021698\n",
      "0.3795129060745239\n",
      "0.37021955847740173\n",
      "0.3800138533115387\n",
      "0.3447107970714569\n",
      "0.4184409976005554\n",
      "0.4217398762702942\n",
      "0.49912309646606445\n",
      "0.3312735855579376\n",
      "0.40471816062927246\n",
      "0.34910473227500916\n",
      "0.3793266713619232\n",
      "0.3503849506378174\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model='WeightedEnsemble_L2')\n",
    "for item in train_data_pred:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-5040/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-5040/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3888491988182068\n",
      "0.3671557903289795\n",
      "0.3838612139225006\n",
      "0.5634114742279053\n",
      "0.3890450596809387\n",
      "0.3779953420162201\n",
      "0.4416275918483734\n",
      "0.4765593409538269\n",
      "0.40961530804634094\n",
      "0.33124840259552\n",
      "0.36169740557670593\n",
      "0.4149017333984375\n",
      "0.3770992159843445\n",
      "0.4587467908859253\n",
      "0.4225054383277893\n",
      "0.43219611048698425\n",
      "0.3998076915740967\n",
      "0.4115949273109436\n",
      "0.35782739520072937\n",
      "0.35961058735847473\n",
      "0.4190015494823456\n",
      "0.35274094343185425\n",
      "0.3436727821826935\n",
      "0.37808310985565186\n",
      "0.45776093006134033\n",
      "0.4152013659477234\n",
      "0.42506372928619385\n",
      "0.38147369027137756\n",
      "0.39333465695381165\n",
      "0.3839941620826721\n",
      "0.43997740745544434\n",
      "0.3791082799434662\n",
      "0.38363152742385864\n",
      "0.3947800397872925\n",
      "0.3794737756252289\n",
      "0.35161226987838745\n",
      "0.36844736337661743\n",
      "0.4189628064632416\n",
      "0.4119766056537628\n",
      "0.3844318985939026\n",
      "0.49013617634773254\n",
      "0.3873021602630615\n",
      "0.46062180399894714\n",
      "0.37816092371940613\n",
      "0.41994205117225647\n",
      "0.3930623233318329\n",
      "0.4287062883377075\n",
      "0.38210660219192505\n",
      "0.3690868020057678\n",
      "0.374775230884552\n",
      "0.4322760999202728\n",
      "0.36867764592170715\n",
      "0.48516973853111267\n",
      "0.43762433528900146\n",
      "0.37060821056365967\n",
      "0.3910413980484009\n",
      "0.3923742175102234\n",
      "0.3898441791534424\n",
      "0.36745119094848633\n",
      "0.4365765452384949\n",
      "0.41241347789764404\n",
      "0.4288470149040222\n",
      "0.361577570438385\n",
      "0.41018274426460266\n",
      "0.35727444291114807\n",
      "0.3468044102191925\n",
      "0.4243292808532715\n",
      "0.36297643184661865\n",
      "0.3784031569957733\n",
      "0.4286321699619293\n",
      "0.4143008589744568\n",
      "0.39346981048583984\n",
      "0.39145898818969727\n",
      "0.3953259289264679\n",
      "0.4020289182662964\n",
      "0.36180955171585083\n",
      "0.40473878383636475\n",
      "0.3962720036506653\n",
      "0.36300843954086304\n",
      "0.40151816606521606\n",
      "0.3874373435974121\n",
      "0.4360698163509369\n",
      "0.3348625600337982\n",
      "0.3660779893398285\n",
      "0.36695295572280884\n",
      "0.44021743535995483\n",
      "0.36106351017951965\n",
      "0.3522339463233948\n"
     ]
    }
   ],
   "source": [
    "test_data_pred = predictor.predict(test_data, model='WeightedEnsemble_L2')\n",
    "for item in test_data_pred:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
