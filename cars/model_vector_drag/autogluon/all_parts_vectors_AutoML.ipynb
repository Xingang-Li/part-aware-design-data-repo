{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/anaconda3/envs/surrogate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_440</th>\n",
       "      <th>dim_441</th>\n",
       "      <th>dim_442</th>\n",
       "      <th>dim_443</th>\n",
       "      <th>dim_444</th>\n",
       "      <th>dim_445</th>\n",
       "      <th>dim_446</th>\n",
       "      <th>dim_447</th>\n",
       "      <th>dim_448</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-6.639910</td>\n",
       "      <td>-2.575970</td>\n",
       "      <td>-4.333867</td>\n",
       "      <td>0.348634</td>\n",
       "      <td>-6.591602</td>\n",
       "      <td>4.137893</td>\n",
       "      <td>3.448946</td>\n",
       "      <td>9.801783</td>\n",
       "      <td>-4.944950</td>\n",
       "      <td>-1.340411</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.080956</td>\n",
       "      <td>0.063173</td>\n",
       "      <td>1.612214</td>\n",
       "      <td>1.418663</td>\n",
       "      <td>0.173674</td>\n",
       "      <td>0.923131</td>\n",
       "      <td>-0.423641</td>\n",
       "      <td>-2.278858</td>\n",
       "      <td>-0.536435</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>5.044733</td>\n",
       "      <td>2.543681</td>\n",
       "      <td>-3.247805</td>\n",
       "      <td>-5.378260</td>\n",
       "      <td>0.549456</td>\n",
       "      <td>-1.075264</td>\n",
       "      <td>6.259791</td>\n",
       "      <td>5.443143</td>\n",
       "      <td>1.828774</td>\n",
       "      <td>5.774058</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.829254</td>\n",
       "      <td>2.322891</td>\n",
       "      <td>0.782790</td>\n",
       "      <td>1.487128</td>\n",
       "      <td>-1.055578</td>\n",
       "      <td>2.655854</td>\n",
       "      <td>-0.162912</td>\n",
       "      <td>-0.385024</td>\n",
       "      <td>0.673573</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-0.939149</td>\n",
       "      <td>0.704528</td>\n",
       "      <td>0.749587</td>\n",
       "      <td>-1.643254</td>\n",
       "      <td>-3.556550</td>\n",
       "      <td>0.293420</td>\n",
       "      <td>3.039790</td>\n",
       "      <td>-3.084175</td>\n",
       "      <td>-3.810488</td>\n",
       "      <td>3.759489</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.636529</td>\n",
       "      <td>10.484594</td>\n",
       "      <td>10.753080</td>\n",
       "      <td>8.283512</td>\n",
       "      <td>1.325511</td>\n",
       "      <td>6.276447</td>\n",
       "      <td>-0.932776</td>\n",
       "      <td>11.217846</td>\n",
       "      <td>1.199296</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-1.177986</td>\n",
       "      <td>1.175732</td>\n",
       "      <td>-1.834498</td>\n",
       "      <td>1.306601</td>\n",
       "      <td>-0.493694</td>\n",
       "      <td>1.298445</td>\n",
       "      <td>2.197183</td>\n",
       "      <td>4.541283</td>\n",
       "      <td>1.859666</td>\n",
       "      <td>3.284920</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.321944</td>\n",
       "      <td>1.785326</td>\n",
       "      <td>0.453086</td>\n",
       "      <td>0.186109</td>\n",
       "      <td>1.353902</td>\n",
       "      <td>2.105992</td>\n",
       "      <td>-0.312803</td>\n",
       "      <td>-1.399713</td>\n",
       "      <td>0.909484</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.390329</td>\n",
       "      <td>-1.530953</td>\n",
       "      <td>-2.521950</td>\n",
       "      <td>-4.864147</td>\n",
       "      <td>-0.742480</td>\n",
       "      <td>0.146031</td>\n",
       "      <td>-0.156536</td>\n",
       "      <td>1.740131</td>\n",
       "      <td>-2.943921</td>\n",
       "      <td>5.280754</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.205936</td>\n",
       "      <td>-0.899805</td>\n",
       "      <td>0.860134</td>\n",
       "      <td>1.484055</td>\n",
       "      <td>-2.426541</td>\n",
       "      <td>2.012407</td>\n",
       "      <td>-0.914859</td>\n",
       "      <td>-1.245621</td>\n",
       "      <td>0.841827</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 449 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "61  -6.639910 -2.575970 -4.333867  0.348634 -6.591602  4.137893  3.448946   \n",
       "354  5.044733  2.543681 -3.247805 -5.378260  0.549456 -1.075264  6.259791   \n",
       "358 -0.939149  0.704528  0.749587 -1.643254 -3.556550  0.293420  3.039790   \n",
       "275 -1.177986  1.175732 -1.834498  1.306601 -0.493694  1.298445  2.197183   \n",
       "18   0.390329 -1.530953 -2.521950 -4.864147 -0.742480  0.146031 -0.156536   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...   dim_440    dim_441    dim_442  \\\n",
       "61   9.801783 -4.944950 -1.340411  ... -1.080956   0.063173   1.612214   \n",
       "354  5.443143  1.828774  5.774058  ... -1.829254   2.322891   0.782790   \n",
       "358 -3.084175 -3.810488  3.759489  ... -0.636529  10.484594  10.753080   \n",
       "275  4.541283  1.859666  3.284920  ... -2.321944   1.785326   0.453086   \n",
       "18   1.740131 -2.943921  5.280754  ... -2.205936  -0.899805   0.860134   \n",
       "\n",
       "      dim_443   dim_444   dim_445   dim_446    dim_447   dim_448   drag  \n",
       "61   1.418663  0.173674  0.923131 -0.423641  -2.278858 -0.536435  0.375  \n",
       "354  1.487128 -1.055578  2.655854 -0.162912  -0.385024  0.673573  0.374  \n",
       "358  8.283512  1.325511  6.276447 -0.932776  11.217846  1.199296  0.435  \n",
       "275  0.186109  1.353902  2.105992 -0.312803  -1.399713  0.909484  0.437  \n",
       "18   1.484055 -2.426541  2.012407 -0.914859  -1.245621  0.841827  0.367  \n",
       "\n",
       "[5 rows x 449 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = './all_parts_vectors_drags.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-all_parts\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Saving ./agModels-all_parts/learner.pkl\n",
      "Saving ./agModels-all_parts/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-all_parts/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 448\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    254092.27 MB\n",
      "\tTrain Data (Original)  Memory Usage: 1.26 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.2s = Fit runtime\n",
      "\t\t\t448 features in original data used to generate 448 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t448 features in original data used to generate 448 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t448 features in original data used to generate 448 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t448 features in original data used to generate 448 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t0.7s = Fit runtime\n",
      "\t448 features in original data used to generate 448 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 1.26 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.81s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-all_parts/learner.pkl\n",
      "Saving ./agModels-all_parts/utils/data/X.pkl\n",
      "Saving ./agModels-all_parts/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 448 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t-0.0612\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 448 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t-0.0608\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.06s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0536\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.35s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0537\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.09s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 448 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0554\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.62s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0552\t = Validation score   (-root_mean_squared_error)\n",
      "\t952.82s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 448 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.98s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0553\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.42s\t = Training   runtime\n",
      "\t0.82s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0547\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.59s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.0562\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.22s\t = Training   runtime\n",
      "\t2.32s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 448 features.\n",
      "\tDropped 0 of 448 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 448 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t498.86s\t = Training   runtime\n",
      "\t1.07s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 11 features.\n",
      "\tDropped 0 of 11 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 11 features.\n",
      "Ensemble size: 31\n",
      "Ensemble indices: [2, 3, 2, 3, 2, 3, 2, 7, 3, 2, 2, 3, 2, 3, 2, 3, 2, 3, 2, 3, 9, 2, 3, 2, 3, 2, 2, 7, 3, 3, 2]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.48387097 0.41935484 0.         0.\n",
      " 0.         0.06451613 0.         0.03225806 0.        ]\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.0535\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.84s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0536\t = Validation score   (-root_mean_squared_error)\n",
      "\t49.8s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.49s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 459 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0541\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.06s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t274.68s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 459 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.054\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.02s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0554\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.56s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.0544\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.08s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0536\t = Validation score   (-root_mean_squared_error)\n",
      "\t20.82s\t = Training   runtime\n",
      "\t4.62s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 459 features.\n",
      "\tDropped 0 of 459 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 459 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.0534\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.12s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 22\n",
      "Ensemble indices: [8, 7, 8, 7, 6, 7, 8, 7, 8, 7, 6, 8, 7, 8, 7, 8, 7, 6, 7, 8, 7, 8]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.         0.\n",
      " 0.13636364 0.45454545 0.40909091]\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.0528\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.54s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.0544\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.63s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0546\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.67s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 457 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.0541\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.07s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0543\t = Validation score   (-root_mean_squared_error)\n",
      "\t70.97s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 457 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0533\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.04s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.0535\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.98s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0546\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.05s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.0547\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.23s\t = Training   runtime\n",
      "\t2.28s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0539\t = Validation score   (-root_mean_squared_error)\n",
      "\t184.21s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 27\n",
      "Ensemble indices: [4, 5, 4, 5, 7, 6, 5, 4, 5, 4, 5, 4, 7, 4, 5, 6, 5, 4, 5, 4, 5, 4, 7, 5, 4, 6, 5]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.37037037 0.40740741\n",
      " 0.11111111 0.11111111 0.        ]\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.0527\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.65s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.054\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.6s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0545\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.06s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 457 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.97s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0545\t = Validation score   (-root_mean_squared_error)\n",
      "\t935.13s\t = Training   runtime\n",
      "\t0.38s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 457 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0537\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.07s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.0545\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.57s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.0549\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.99s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.0545\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.9s\t = Training   runtime\n",
      "\t2.27s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 457 features.\n",
      "\tDropped 0 of 457 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 457 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t163.96s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 18\n",
      "Ensemble indices: [4, 7, 5, 4, 4, 7, 5, 4, 7, 4, 5, 4, 7, 6, 4, 7, 5, 4]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.44444444 0.22222222\n",
      " 0.05555556 0.27777778 0.        ]\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-all_parts/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0531\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 3559.01s ... Best model: \"WeightedEnsemble_L4\"\n",
      "Loading: ./agModels-all_parts/models/trainer.pkl\n",
      "Saving ./agModels-all_parts/models/trainer.pkl\n",
      "Saving ./agModels-all_parts/learner.pkl\n",
      "Saving ./agModels-all_parts/predictor.pkl\n",
      "Saving ./agModels-all_parts/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-all_parts/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-all_parts/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-all_parts'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_439</th>\n",
       "      <th>dim_440</th>\n",
       "      <th>dim_441</th>\n",
       "      <th>dim_442</th>\n",
       "      <th>dim_443</th>\n",
       "      <th>dim_444</th>\n",
       "      <th>dim_445</th>\n",
       "      <th>dim_446</th>\n",
       "      <th>dim_447</th>\n",
       "      <th>dim_448</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3.262418</td>\n",
       "      <td>4.623484</td>\n",
       "      <td>5.207058</td>\n",
       "      <td>1.474604</td>\n",
       "      <td>5.149589</td>\n",
       "      <td>1.366774</td>\n",
       "      <td>7.350364</td>\n",
       "      <td>4.988407</td>\n",
       "      <td>-4.451728</td>\n",
       "      <td>2.715955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.493204</td>\n",
       "      <td>-1.530669</td>\n",
       "      <td>-1.038711</td>\n",
       "      <td>1.546212</td>\n",
       "      <td>0.701456</td>\n",
       "      <td>-0.417296</td>\n",
       "      <td>2.205014</td>\n",
       "      <td>-2.338213</td>\n",
       "      <td>-1.252558</td>\n",
       "      <td>-0.207984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-1.815653</td>\n",
       "      <td>0.467063</td>\n",
       "      <td>-0.713573</td>\n",
       "      <td>-2.519432</td>\n",
       "      <td>-6.833046</td>\n",
       "      <td>3.925573</td>\n",
       "      <td>3.131740</td>\n",
       "      <td>2.785505</td>\n",
       "      <td>-0.169789</td>\n",
       "      <td>3.797550</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.799442</td>\n",
       "      <td>-2.883593</td>\n",
       "      <td>1.992778</td>\n",
       "      <td>0.544198</td>\n",
       "      <td>1.757790</td>\n",
       "      <td>-0.963274</td>\n",
       "      <td>2.303173</td>\n",
       "      <td>-0.294457</td>\n",
       "      <td>-0.247084</td>\n",
       "      <td>2.795963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.128397</td>\n",
       "      <td>-0.347771</td>\n",
       "      <td>-4.491439</td>\n",
       "      <td>-0.143762</td>\n",
       "      <td>-1.139696</td>\n",
       "      <td>1.523660</td>\n",
       "      <td>4.283424</td>\n",
       "      <td>1.275272</td>\n",
       "      <td>-3.277825</td>\n",
       "      <td>-0.944104</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.005584</td>\n",
       "      <td>-2.087350</td>\n",
       "      <td>0.265765</td>\n",
       "      <td>1.710699</td>\n",
       "      <td>-0.205781</td>\n",
       "      <td>0.221282</td>\n",
       "      <td>2.097013</td>\n",
       "      <td>-2.484610</td>\n",
       "      <td>-1.032043</td>\n",
       "      <td>0.472173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.334880</td>\n",
       "      <td>-0.358754</td>\n",
       "      <td>-5.121314</td>\n",
       "      <td>-1.869275</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2.998930</td>\n",
       "      <td>-0.482418</td>\n",
       "      <td>1.283854</td>\n",
       "      <td>-1.355309</td>\n",
       "      <td>-0.988547</td>\n",
       "      <td>...</td>\n",
       "      <td>2.702447</td>\n",
       "      <td>-1.539050</td>\n",
       "      <td>-0.802389</td>\n",
       "      <td>1.228584</td>\n",
       "      <td>1.375461</td>\n",
       "      <td>-2.406342</td>\n",
       "      <td>0.712337</td>\n",
       "      <td>-1.958422</td>\n",
       "      <td>-1.374814</td>\n",
       "      <td>-1.371111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.339348</td>\n",
       "      <td>2.649365</td>\n",
       "      <td>-1.346519</td>\n",
       "      <td>0.872298</td>\n",
       "      <td>-2.672357</td>\n",
       "      <td>1.983254</td>\n",
       "      <td>2.075392</td>\n",
       "      <td>6.573480</td>\n",
       "      <td>-0.809723</td>\n",
       "      <td>-2.231186</td>\n",
       "      <td>...</td>\n",
       "      <td>4.364009</td>\n",
       "      <td>-0.522479</td>\n",
       "      <td>0.352676</td>\n",
       "      <td>0.769096</td>\n",
       "      <td>1.184941</td>\n",
       "      <td>2.701294</td>\n",
       "      <td>0.989609</td>\n",
       "      <td>-2.073087</td>\n",
       "      <td>-1.652956</td>\n",
       "      <td>-0.242727</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 448 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "46   3.262418  4.623484  5.207058  1.474604  5.149589  1.366774  7.350364   \n",
       "101 -1.815653  0.467063 -0.713573 -2.519432 -6.833046  3.925573  3.131740   \n",
       "175 -0.128397 -0.347771 -4.491439 -0.143762 -1.139696  1.523660  4.283424   \n",
       "9   -0.334880 -0.358754 -5.121314 -1.869275  0.053525  2.998930 -0.482418   \n",
       "136  0.339348  2.649365 -1.346519  0.872298 -2.672357  1.983254  2.075392   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...   dim_439   dim_440   dim_441  \\\n",
       "46   4.988407 -4.451728  2.715955  ...  0.493204 -1.530669 -1.038711   \n",
       "101  2.785505 -0.169789  3.797550  ... -1.799442 -2.883593  1.992778   \n",
       "175  1.275272 -3.277825 -0.944104  ... -0.005584 -2.087350  0.265765   \n",
       "9    1.283854 -1.355309 -0.988547  ...  2.702447 -1.539050 -0.802389   \n",
       "136  6.573480 -0.809723 -2.231186  ...  4.364009 -0.522479  0.352676   \n",
       "\n",
       "      dim_442   dim_443   dim_444   dim_445   dim_446   dim_447   dim_448  \n",
       "46   1.546212  0.701456 -0.417296  2.205014 -2.338213 -1.252558 -0.207984  \n",
       "101  0.544198  1.757790 -0.963274  2.303173 -0.294457 -0.247084  2.795963  \n",
       "175  1.710699 -0.205781  0.221282  2.097013 -2.484610 -1.032043  0.472173  \n",
       "9    1.228584  1.375461 -2.406342  0.712337 -1.958422 -1.374814 -1.371111  \n",
       "136  0.769096  1.184941  2.701294  0.989609 -2.073087 -1.652956 -0.242727  \n",
       "\n",
       "[5 rows x 448 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-all_parts/predictor.pkl\n",
      "Loading: ./agModels-all_parts/learner.pkl\n",
      "Loading: ./agModels-all_parts/models/trainer.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L4/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.04749126205305158\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.04749126205305158,\n",
      "    \"mean_squared_error\": -0.002255419971391617,\n",
      "    \"mean_absolute_error\": -0.03642181108485569,\n",
      "    \"r2\": 0.2330097621923941,\n",
      "    \"pearsonr\": 0.4912116690363939,\n",
      "    \"median_absolute_error\": -0.030018040537834162\n",
      "}\n",
      "Loading: ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'KNeighborsUnif_BAG_L1': -0.055620911667156984, 'KNeighborsDist_BAG_L1': -0.0547830038397141, 'LightGBMXT_BAG_L1': -0.048776020231336856, 'LightGBM_BAG_L1': -0.05010858639339003, 'RandomForestMSE_BAG_L1': -0.050053304988936814, 'CatBoost_BAG_L1': -0.04947725829421238, 'ExtraTreesMSE_BAG_L1': -0.049535851632918716, 'NeuralNetFastAI_BAG_L1': -0.04855164419518627, 'XGBoost_BAG_L1': -0.04943532933362713, 'NeuralNetTorch_BAG_L1': -0.051609882195865424, 'LightGBMLarge_BAG_L1': -0.049867052673816595, 'WeightedEnsemble_L2': -0.049179433190713114, 'LightGBMXT_BAG_L2': -0.0487029153616811, 'LightGBM_BAG_L2': -0.04913911305293151, 'RandomForestMSE_BAG_L2': -0.04799159050334716, 'CatBoost_BAG_L2': -0.04979663020243783, 'ExtraTreesMSE_BAG_L2': -0.047891472787577535, 'NeuralNetFastAI_BAG_L2': -0.04895395678284408, 'XGBoost_BAG_L2': -0.04921720899564167, 'NeuralNetTorch_BAG_L2': -0.050622441295370184, 'LightGBMLarge_BAG_L2': -0.04904280061186147, 'WeightedEnsemble_L3': -0.04918491051493448, 'LightGBMXT_BAG_L3': -0.04907394599911236, 'LightGBM_BAG_L3': -0.048948662122673896, 'RandomForestMSE_BAG_L3': -0.047969933392267905, 'CatBoost_BAG_L3': -0.04903437117855866, 'ExtraTreesMSE_BAG_L3': -0.04748775225045537, 'NeuralNetFastAI_BAG_L3': -0.04778165655293775, 'XGBoost_BAG_L3': -0.04875032997795888, 'NeuralNetTorch_BAG_L3': -0.05115121981117866, 'LightGBMLarge_BAG_L3': -0.048360164619985484, 'WeightedEnsemble_L4': -0.04749126205305158, 'LightGBMXT_BAG_L4': -0.048294158028244424, 'LightGBM_BAG_L4': -0.048086353714935574, 'RandomForestMSE_BAG_L4': -0.04764338561150791, 'CatBoost_BAG_L4': -0.04886774294782188, 'ExtraTreesMSE_BAG_L4': -0.0475131056017078, 'NeuralNetFastAI_BAG_L4': -0.04835332174053202, 'XGBoost_BAG_L4': -0.047430756926424275, 'NeuralNetTorch_BAG_L4': -0.05133349503822826, 'LightGBMLarge_BAG_L4': -0.048371599079923513, 'WeightedEnsemble_L5': -0.04809996960740023}\n"
     ]
    }
   ],
   "source": [
    "%%capture log_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%config Application.log_level = 'DEBUG'\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "with open('./output_all_parts.log', 'w') as f:\n",
    "    f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n",
      "AutoGluon identified the following types of features:\n",
      "('float', []) : 448 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39184391498565674\n",
      "0.38747626543045044\n",
      "0.4197539985179901\n",
      "0.4179936647415161\n",
      "0.3793541193008423\n",
      "0.3751015067100525\n",
      "0.44055819511413574\n",
      "0.38958820700645447\n",
      "0.3726438581943512\n",
      "0.3715391159057617\n",
      "0.3620454967021942\n",
      "0.49061012268066406\n",
      "0.44387468695640564\n",
      "0.380361944437027\n",
      "0.41504812240600586\n",
      "0.4479149878025055\n",
      "0.3274679183959961\n",
      "0.4147564172744751\n",
      "0.48429781198501587\n",
      "0.3661191761493683\n",
      "0.4156646430492401\n",
      "0.45305365324020386\n",
      "0.34406012296676636\n",
      "0.42071548104286194\n",
      "0.4072604477405548\n",
      "0.41768452525138855\n",
      "0.3798379600048065\n",
      "0.41840359568595886\n",
      "0.33708423376083374\n",
      "0.35109180212020874\n",
      "0.44828689098358154\n",
      "0.41982996463775635\n",
      "0.4782492518424988\n",
      "0.43675580620765686\n",
      "0.36623162031173706\n",
      "0.3798624873161316\n",
      "0.40959155559539795\n",
      "0.4721307158470154\n",
      "0.35714036226272583\n",
      "0.3607688248157501\n",
      "0.487091988325119\n",
      "0.3831229507923126\n",
      "0.35296615958213806\n",
      "0.33161357045173645\n",
      "0.3642938435077667\n",
      "0.3847861886024475\n",
      "0.3893302381038666\n",
      "0.41547268629074097\n",
      "0.35462716221809387\n",
      "0.3950325548648834\n",
      "0.3961527347564697\n",
      "0.37040096521377563\n",
      "0.3903968930244446\n",
      "0.35033807158470154\n",
      "0.4153662323951721\n",
      "0.38551774621009827\n",
      "0.42836934328079224\n",
      "0.37544989585876465\n",
      "0.3446009159088135\n",
      "0.3657964766025543\n",
      "0.3539283871650696\n",
      "0.3665899932384491\n",
      "0.4271245300769806\n",
      "0.3722672760486603\n",
      "0.37576228380203247\n",
      "0.39239293336868286\n",
      "0.41940954327583313\n",
      "0.34363263845443726\n",
      "0.4239197075366974\n",
      "0.3872629404067993\n",
      "0.4168173670768738\n",
      "0.3751964569091797\n",
      "0.37465402483940125\n",
      "0.3691132068634033\n",
      "0.389254629611969\n",
      "0.4036239981651306\n",
      "0.4529602825641632\n",
      "0.42517659068107605\n",
      "0.39905980229377747\n",
      "0.4221632778644562\n",
      "0.41353389620780945\n",
      "0.4695809781551361\n",
      "0.3393700420856476\n",
      "0.34196746349334717\n",
      "0.36763548851013184\n",
      "0.424232542514801\n",
      "0.3813389241695404\n",
      "0.4392990469932556\n",
      "0.3943294286727905\n",
      "0.3919379413127899\n",
      "0.36031535267829895\n",
      "0.3361523151397705\n",
      "0.44649437069892883\n",
      "0.36317652463912964\n",
      "0.43298739194869995\n",
      "0.3665120601654053\n",
      "0.38394588232040405\n",
      "0.357658714056015\n",
      "0.4789997637271881\n",
      "0.35767027735710144\n",
      "0.4118354916572571\n",
      "0.4166136682033539\n",
      "0.3725990056991577\n",
      "0.41304755210876465\n",
      "0.4257862865924835\n",
      "0.35144394636154175\n",
      "0.34444287419319153\n",
      "0.4457743763923645\n",
      "0.4069654643535614\n",
      "0.4623532295227051\n",
      "0.3354107439517975\n",
      "0.41581475734710693\n",
      "0.37690451741218567\n",
      "0.403453528881073\n",
      "0.4171822667121887\n",
      "0.38721442222595215\n",
      "0.3532582223415375\n",
      "0.35179227590560913\n",
      "0.49280858039855957\n",
      "0.3702608644962311\n",
      "0.39914584159851074\n",
      "0.4148375988006592\n",
      "0.38399505615234375\n",
      "0.41520822048187256\n",
      "0.4381655156612396\n",
      "0.3548906147480011\n",
      "0.4317963719367981\n",
      "0.4574386477470398\n",
      "0.3810540735721588\n",
      "0.35679206252098083\n",
      "0.39015457034111023\n",
      "0.4534246027469635\n",
      "0.3448278307914734\n",
      "0.39637628197669983\n",
      "0.4319388270378113\n",
      "0.4188306927680969\n",
      "0.3953566253185272\n",
      "0.4400483965873718\n",
      "0.37593841552734375\n",
      "0.36100777983665466\n",
      "0.4372093379497528\n",
      "0.41778385639190674\n",
      "0.38006508350372314\n",
      "0.37373611330986023\n",
      "0.4030231237411499\n",
      "0.3883446156978607\n",
      "0.40621498227119446\n",
      "0.4063863754272461\n",
      "0.4499000608921051\n",
      "0.3555653989315033\n",
      "0.43129077553749084\n",
      "0.43712183833122253\n",
      "0.46964335441589355\n",
      "0.4593094289302826\n",
      "0.38796156644821167\n",
      "0.36617955565452576\n",
      "0.3929626941680908\n",
      "0.4414779543876648\n",
      "0.4210461676120758\n",
      "0.374612420797348\n",
      "0.4467184543609619\n",
      "0.35933244228363037\n",
      "0.4340542256832123\n",
      "0.3991110026836395\n",
      "0.3613097071647644\n",
      "0.3594462275505066\n",
      "0.4220617115497589\n",
      "0.42662930488586426\n",
      "0.34103259444236755\n",
      "0.44370409846305847\n",
      "0.3730688989162445\n",
      "0.40814539790153503\n",
      "0.4030286371707916\n",
      "0.3974732756614685\n",
      "0.38748374581336975\n",
      "0.4380107820034027\n",
      "0.46091705560684204\n",
      "0.38293910026550293\n",
      "0.43151870369911194\n",
      "0.414945513010025\n",
      "0.39423438906669617\n",
      "0.34930017590522766\n",
      "0.395037442445755\n",
      "0.3923671245574951\n",
      "0.38835617899894714\n",
      "0.37325212359428406\n",
      "0.435719758272171\n",
      "0.3477468192577362\n",
      "0.43632179498672485\n",
      "0.3696293830871582\n",
      "0.46122339367866516\n",
      "0.35792076587677\n",
      "0.38385698199272156\n",
      "0.4850633144378662\n",
      "0.4603959023952484\n",
      "0.43245217204093933\n",
      "0.39681994915008545\n",
      "0.449175089597702\n",
      "0.3633424639701843\n",
      "0.4328898787498474\n",
      "0.3931238353252411\n",
      "0.4056514799594879\n",
      "0.3656133711338043\n",
      "0.3581487238407135\n",
      "0.42713040113449097\n",
      "0.3513309061527252\n",
      "0.39003950357437134\n",
      "0.4097082316875458\n",
      "0.4133468568325043\n",
      "0.3825795650482178\n",
      "0.45823222398757935\n",
      "0.3822348117828369\n",
      "0.3688589632511139\n",
      "0.4127151370048523\n",
      "0.37215355038642883\n",
      "0.37579450011253357\n",
      "0.3856180012226105\n",
      "0.41256800293922424\n",
      "0.4064987301826477\n",
      "0.41638854146003723\n",
      "0.3802379071712494\n",
      "0.3493833541870117\n",
      "0.4587576985359192\n",
      "0.40941011905670166\n",
      "0.4568403959274292\n",
      "0.32505276799201965\n",
      "0.3517538011074066\n",
      "0.40866678953170776\n",
      "0.38754740357398987\n",
      "0.3558083176612854\n",
      "0.39643436670303345\n",
      "0.3405582308769226\n",
      "0.4050852358341217\n",
      "0.39025089144706726\n",
      "0.3583996891975403\n",
      "0.3488965332508087\n",
      "0.467549592256546\n",
      "0.3632654845714569\n",
      "0.47370797395706177\n",
      "0.3734629452228546\n",
      "0.4116056561470032\n",
      "0.39310571551322937\n",
      "0.35725247859954834\n",
      "0.4075923562049866\n",
      "0.40790969133377075\n",
      "0.37090688943862915\n",
      "0.40523406863212585\n",
      "0.42411306500434875\n",
      "0.38481026887893677\n",
      "0.4042742848396301\n",
      "0.371744304895401\n",
      "0.3913342356681824\n",
      "0.3903489112854004\n",
      "0.40303388237953186\n",
      "0.3913673460483551\n",
      "0.43723416328430176\n",
      "0.3678027093410492\n",
      "0.43328413367271423\n",
      "0.3818299472332001\n",
      "0.36386221647262573\n",
      "0.36796465516090393\n",
      "0.37547174096107483\n",
      "0.4476827085018158\n",
      "0.3556669056415558\n",
      "0.4511468708515167\n",
      "0.3862929940223694\n",
      "0.38052064180374146\n",
      "0.4740799069404602\n",
      "0.4387049078941345\n",
      "0.3879908621311188\n",
      "0.4732248783111572\n",
      "0.44262465834617615\n",
      "0.39145854115486145\n",
      "0.34529370069503784\n",
      "0.3505261540412903\n",
      "0.41496795415878296\n",
      "0.32822179794311523\n",
      "0.3597830832004547\n",
      "0.45814189314842224\n",
      "0.38746002316474915\n",
      "0.4262370467185974\n",
      "0.3373795449733734\n",
      "0.401555597782135\n",
      "0.3985717296600342\n",
      "0.3930738568305969\n",
      "0.3492370545864105\n",
      "0.3381752371788025\n",
      "0.4585689902305603\n",
      "0.4067647159099579\n",
      "0.4911209046840668\n",
      "0.42189258337020874\n",
      "0.3715621531009674\n",
      "0.3312419354915619\n",
      "0.36599841713905334\n",
      "0.37377309799194336\n",
      "0.42084527015686035\n",
      "0.3707365095615387\n",
      "0.5111597180366516\n",
      "0.35643255710601807\n",
      "0.42371782660484314\n",
      "0.38799288868904114\n",
      "0.35096532106399536\n",
      "0.4088643193244934\n",
      "0.35737037658691406\n",
      "0.33948877453804016\n",
      "0.4116601049900055\n",
      "0.3886887729167938\n",
      "0.3715536892414093\n",
      "0.3552146852016449\n",
      "0.4413459599018097\n",
      "0.4922274947166443\n",
      "0.48216432332992554\n",
      "0.43905922770500183\n",
      "0.38355588912963867\n",
      "0.4790076017379761\n",
      "0.4273154139518738\n",
      "0.4099656939506531\n",
      "0.42009487748146057\n",
      "0.39926743507385254\n",
      "0.41065725684165955\n",
      "0.4971557557582855\n",
      "0.3660593330860138\n",
      "0.3491195738315582\n",
      "0.3654983639717102\n",
      "0.3518529236316681\n",
      "0.44949352741241455\n",
      "0.40224966406822205\n",
      "0.39409253001213074\n",
      "0.31582796573638916\n",
      "0.3790261745452881\n",
      "0.40953171253204346\n",
      "0.32878708839416504\n",
      "0.41516509652137756\n",
      "0.453483521938324\n",
      "0.41775354743003845\n",
      "0.45047569274902344\n",
      "0.43092355132102966\n",
      "0.45365071296691895\n",
      "0.3558754324913025\n",
      "0.3741653859615326\n",
      "0.3761918544769287\n",
      "0.3857627511024475\n",
      "0.3501061499118805\n",
      "0.4299892783164978\n",
      "0.41884902119636536\n",
      "0.4767812192440033\n",
      "0.3444517254829407\n",
      "0.4231759011745453\n",
      "0.36298927664756775\n",
      "0.3996957838535309\n",
      "0.36198359727859497\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model='WeightedEnsemble_L2')\n",
    "for item in train_data_pred:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-all_parts/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-all_parts/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.384922057390213\n",
      "0.38217824697494507\n",
      "0.4016181230545044\n",
      "0.4046119451522827\n",
      "0.4317357540130615\n",
      "0.4018993377685547\n",
      "0.3992326259613037\n",
      "0.44062340259552\n",
      "0.4211746156215668\n",
      "0.36477047204971313\n",
      "0.4024960696697235\n",
      "0.4058777391910553\n",
      "0.37610968947410583\n",
      "0.42764168977737427\n",
      "0.40456944704055786\n",
      "0.41403016448020935\n",
      "0.3857561945915222\n",
      "0.3971380591392517\n",
      "0.3829162120819092\n",
      "0.37643003463745117\n",
      "0.4069160223007202\n",
      "0.4054562747478485\n",
      "0.37352097034454346\n",
      "0.3897387683391571\n",
      "0.4212469458580017\n",
      "0.4098832607269287\n",
      "0.4114890992641449\n",
      "0.3821398913860321\n",
      "0.4004173278808594\n",
      "0.3805646300315857\n",
      "0.4311654269695282\n",
      "0.3803538680076599\n",
      "0.40003323554992676\n",
      "0.4070470333099365\n",
      "0.389871209859848\n",
      "0.3711824417114258\n",
      "0.3777167499065399\n",
      "0.41139066219329834\n",
      "0.3946819603443146\n",
      "0.38867270946502686\n",
      "0.4345022439956665\n",
      "0.3786471486091614\n",
      "0.41710034012794495\n",
      "0.3966688811779022\n",
      "0.3841814696788788\n",
      "0.3991056978702545\n",
      "0.3795452415943146\n",
      "0.36832818388938904\n",
      "0.40859171748161316\n",
      "0.394782155752182\n",
      "0.4247400164604187\n",
      "0.3549221456050873\n",
      "0.41813722252845764\n",
      "0.3805334270000458\n",
      "0.3577946126461029\n",
      "0.4243495464324951\n",
      "0.4039001762866974\n",
      "0.4075087904930115\n",
      "0.38289037346839905\n",
      "0.37787798047065735\n",
      "0.4131229519844055\n",
      "0.3846067786216736\n",
      "0.38511011004447937\n",
      "0.3986705243587494\n",
      "0.3785584568977356\n",
      "0.39542198181152344\n",
      "0.4029683768749237\n",
      "0.36496227979660034\n",
      "0.37632718682289124\n",
      "0.4022549092769623\n",
      "0.40613406896591187\n",
      "0.37801623344421387\n",
      "0.38770630955696106\n",
      "0.4045064151287079\n",
      "0.3744775950908661\n",
      "0.4306551516056061\n",
      "0.42273175716400146\n",
      "0.3779926896095276\n",
      "0.409873902797699\n",
      "0.41064074635505676\n",
      "0.3789525330066681\n",
      "0.4067153036594391\n",
      "0.3606656789779663\n",
      "0.3914467692375183\n",
      "0.4194595217704773\n",
      "0.43085333704948425\n",
      "0.39276015758514404\n",
      "0.4156000018119812\n"
     ]
    }
   ],
   "source": [
    "test_data_pred = predictor.predict(test_data, model='WeightedEnsemble_L2')\n",
    "for item in test_data_pred:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
