{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "File delimiter for ./2500_vectors_drags.csv inferred as ',' (comma). If this is incorrect, please manually load the data as a pandas DataFrame.\n",
      "Loaded data from: ./2500_vectors_drags.csv | Columns = 2503 / 2503 | Rows = 439 -> 439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_2492</th>\n",
       "      <th>dim_2493</th>\n",
       "      <th>dim_2494</th>\n",
       "      <th>dim_2495</th>\n",
       "      <th>dim_2496</th>\n",
       "      <th>dim_2497</th>\n",
       "      <th>dim_2498</th>\n",
       "      <th>dim_2499</th>\n",
       "      <th>dim_2500</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2501 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "61     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "354    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "358    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "275    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "18     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_2492  dim_2493  dim_2494  dim_2495  dim_2496  dim_2497  \\\n",
       "61   ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "354  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "358  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "275  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "18   ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "     dim_2498  dim_2499  dim_2500   drag  \n",
       "61        0.0       0.0       0.0  0.375  \n",
       "354       0.0       0.0       0.0  0.374  \n",
       "358       0.0       0.0       0.0  0.435  \n",
       "275       0.0       0.0       0.0  0.437  \n",
       "18        0.0       0.0       0.0  0.367  \n",
       "\n",
       "[5 rows x 2501 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = './2500_vectors_drags.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-2500\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Saving ./agModels-2500/learner.pkl\n",
      "Saving ./agModels-2500/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-2500/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 2500\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    253637.23 MB\n",
      "\tTrain Data (Original)  Memory Usage: 7.02 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tNote: Converting 931 features to boolean dtype as they only contain 2 unique values.\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\t0.8s = Fit runtime\n",
      "\t\t\t931 features in original data used to generate 931 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t931 features in original data used to generate 931 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t931 features in original data used to generate 931 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('int8', 'int') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t931 features in original data used to generate 931 features in processed data.\n",
      "\tUseless Original Features (Count: 1569): ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', 'dim_6', 'dim_7', 'dim_8', 'dim_9', 'dim_10', 'dim_11', 'dim_12', 'dim_13', 'dim_14', 'dim_15', 'dim_16', 'dim_17', 'dim_18', 'dim_19', 'dim_20', 'dim_21', 'dim_22', 'dim_23', 'dim_24', 'dim_25', 'dim_26', 'dim_27', 'dim_28', 'dim_29', 'dim_30', 'dim_31', 'dim_32', 'dim_33', 'dim_34', 'dim_35', 'dim_36', 'dim_37', 'dim_38', 'dim_39', 'dim_40', 'dim_41', 'dim_42', 'dim_43', 'dim_44', 'dim_47', 'dim_48', 'dim_49', 'dim_50', 'dim_51', 'dim_52', 'dim_53', 'dim_54', 'dim_55', 'dim_57', 'dim_58', 'dim_59', 'dim_60', 'dim_61', 'dim_62', 'dim_63', 'dim_67', 'dim_68', 'dim_69', 'dim_70', 'dim_71', 'dim_72', 'dim_74', 'dim_77', 'dim_78', 'dim_79', 'dim_80', 'dim_81', 'dim_82', 'dim_83', 'dim_87', 'dim_88', 'dim_89', 'dim_90', 'dim_91', 'dim_92', 'dim_93', 'dim_95', 'dim_97', 'dim_98', 'dim_99', 'dim_100', 'dim_101', 'dim_102', 'dim_103', 'dim_105', 'dim_106', 'dim_107', 'dim_108', 'dim_109', 'dim_110', 'dim_111', 'dim_112', 'dim_113', 'dim_114', 'dim_115', 'dim_116', 'dim_117', 'dim_118', 'dim_119', 'dim_120', 'dim_121', 'dim_122', 'dim_123', 'dim_124', 'dim_125', 'dim_126', 'dim_127', 'dim_128', 'dim_129', 'dim_130', 'dim_131', 'dim_132', 'dim_133', 'dim_134', 'dim_135', 'dim_136', 'dim_137', 'dim_138', 'dim_139', 'dim_140', 'dim_141', 'dim_142', 'dim_143', 'dim_144', 'dim_145', 'dim_146', 'dim_147', 'dim_148', 'dim_149', 'dim_150', 'dim_151', 'dim_152', 'dim_153', 'dim_154', 'dim_155', 'dim_156', 'dim_157', 'dim_158', 'dim_159', 'dim_160', 'dim_161', 'dim_162', 'dim_163', 'dim_165', 'dim_166', 'dim_167', 'dim_168', 'dim_169', 'dim_170', 'dim_171', 'dim_172', 'dim_173', 'dim_174', 'dim_176', 'dim_177', 'dim_178', 'dim_179', 'dim_180', 'dim_181', 'dim_182', 'dim_187', 'dim_188', 'dim_189', 'dim_190', 'dim_191', 'dim_192', 'dim_194', 'dim_195', 'dim_196', 'dim_197', 'dim_198', 'dim_199', 'dim_200', 'dim_201', 'dim_202', 'dim_203', 'dim_204', 'dim_205', 'dim_206', 'dim_207', 'dim_208', 'dim_209', 'dim_210', 'dim_211', 'dim_212', 'dim_213', 'dim_214', 'dim_215', 'dim_216', 'dim_217', 'dim_218', 'dim_219', 'dim_220', 'dim_221', 'dim_222', 'dim_223', 'dim_224', 'dim_225', 'dim_226', 'dim_227', 'dim_228', 'dim_229', 'dim_230', 'dim_231', 'dim_232', 'dim_233', 'dim_234', 'dim_235', 'dim_236', 'dim_237', 'dim_238', 'dim_239', 'dim_240', 'dim_241', 'dim_242', 'dim_243', 'dim_244', 'dim_245', 'dim_246', 'dim_247', 'dim_248', 'dim_249', 'dim_250', 'dim_251', 'dim_252', 'dim_253', 'dim_254', 'dim_255', 'dim_256', 'dim_257', 'dim_258', 'dim_259', 'dim_260', 'dim_261', 'dim_262', 'dim_263', 'dim_264', 'dim_265', 'dim_266', 'dim_267', 'dim_268', 'dim_269', 'dim_270', 'dim_271', 'dim_272', 'dim_273', 'dim_277', 'dim_279', 'dim_280', 'dim_281', 'dim_282', 'dim_283', 'dim_289', 'dim_290', 'dim_291', 'dim_292', 'dim_299', 'dim_300', 'dim_301', 'dim_302', 'dim_308', 'dim_309', 'dim_310', 'dim_318', 'dim_319', 'dim_320', 'dim_328', 'dim_329', 'dim_330', 'dim_331', 'dim_338', 'dim_339', 'dim_340', 'dim_341', 'dim_349', 'dim_350', 'dim_351', 'dim_352', 'dim_359', 'dim_360', 'dim_361', 'dim_362', 'dim_369', 'dim_370', 'dim_371', 'dim_372', 'dim_378', 'dim_379', 'dim_380', 'dim_381', 'dim_382', 'dim_388', 'dim_389', 'dim_390', 'dim_391', 'dim_392', 'dim_399', 'dim_400', 'dim_401', 'dim_402', 'dim_408', 'dim_409', 'dim_410', 'dim_411', 'dim_412', 'dim_418', 'dim_419', 'dim_420', 'dim_421', 'dim_422', 'dim_428', 'dim_429', 'dim_430', 'dim_431', 'dim_432', 'dim_438', 'dim_439', 'dim_440', 'dim_447', 'dim_448', 'dim_449', 'dim_450', 'dim_457', 'dim_458', 'dim_459', 'dim_460', 'dim_461', 'dim_462', 'dim_467', 'dim_468', 'dim_469', 'dim_470', 'dim_471', 'dim_472', 'dim_477', 'dim_478', 'dim_479', 'dim_480', 'dim_481', 'dim_482', 'dim_483', 'dim_484', 'dim_485', 'dim_486', 'dim_487', 'dim_488', 'dim_489', 'dim_490', 'dim_491', 'dim_492', 'dim_493', 'dim_494', 'dim_495', 'dim_496', 'dim_497', 'dim_498', 'dim_499', 'dim_500', 'dim_501', 'dim_502', 'dim_503', 'dim_504', 'dim_505', 'dim_506', 'dim_507', 'dim_508', 'dim_509', 'dim_510', 'dim_511', 'dim_512', 'dim_513', 'dim_514', 'dim_515', 'dim_516', 'dim_517', 'dim_518', 'dim_519', 'dim_520', 'dim_521', 'dim_522', 'dim_523', 'dim_527', 'dim_529', 'dim_530', 'dim_531', 'dim_532', 'dim_539', 'dim_540', 'dim_541', 'dim_542', 'dim_550', 'dim_551', 'dim_552', 'dim_560', 'dim_561', 'dim_565', 'dim_566', 'dim_570', 'dim_571', 'dim_576', 'dim_580', 'dim_581', 'dim_586', 'dim_590', 'dim_591', 'dim_592', 'dim_595', 'dim_596', 'dim_600', 'dim_601', 'dim_602', 'dim_605', 'dim_606', 'dim_610', 'dim_611', 'dim_612', 'dim_615', 'dim_616', 'dim_620', 'dim_621', 'dim_622', 'dim_625', 'dim_626', 'dim_630', 'dim_631', 'dim_632', 'dim_635', 'dim_636', 'dim_640', 'dim_641', 'dim_642', 'dim_645', 'dim_646', 'dim_650', 'dim_651', 'dim_652', 'dim_655', 'dim_656', 'dim_660', 'dim_661', 'dim_662', 'dim_665', 'dim_670', 'dim_671', 'dim_672', 'dim_675', 'dim_679', 'dim_680', 'dim_681', 'dim_682', 'dim_685', 'dim_689', 'dim_690', 'dim_691', 'dim_695', 'dim_698', 'dim_699', 'dim_700', 'dim_701', 'dim_705', 'dim_707', 'dim_708', 'dim_709', 'dim_710', 'dim_711', 'dim_712', 'dim_715', 'dim_717', 'dim_718', 'dim_719', 'dim_720', 'dim_721', 'dim_722', 'dim_727', 'dim_728', 'dim_729', 'dim_730', 'dim_731', 'dim_732', 'dim_733', 'dim_736', 'dim_737', 'dim_738', 'dim_739', 'dim_740', 'dim_741', 'dim_742', 'dim_743', 'dim_744', 'dim_745', 'dim_746', 'dim_747', 'dim_748', 'dim_749', 'dim_750', 'dim_751', 'dim_752', 'dim_753', 'dim_754', 'dim_755', 'dim_756', 'dim_757', 'dim_758', 'dim_759', 'dim_760', 'dim_761', 'dim_762', 'dim_763', 'dim_764', 'dim_765', 'dim_766', 'dim_767', 'dim_768', 'dim_769', 'dim_770', 'dim_771', 'dim_772', 'dim_773', 'dim_779', 'dim_780', 'dim_781', 'dim_782', 'dim_789', 'dim_790', 'dim_791', 'dim_792', 'dim_800', 'dim_801', 'dim_802', 'dim_806', 'dim_810', 'dim_811', 'dim_812', 'dim_815', 'dim_816', 'dim_820', 'dim_821', 'dim_822', 'dim_825', 'dim_826', 'dim_831', 'dim_832', 'dim_835', 'dim_836', 'dim_840', 'dim_841', 'dim_842', 'dim_845', 'dim_846', 'dim_850', 'dim_851', 'dim_852', 'dim_855', 'dim_856', 'dim_860', 'dim_861', 'dim_862', 'dim_865', 'dim_866', 'dim_867', 'dim_870', 'dim_871', 'dim_872', 'dim_875', 'dim_876', 'dim_877', 'dim_880', 'dim_881', 'dim_882', 'dim_885', 'dim_886', 'dim_887', 'dim_890', 'dim_891', 'dim_892', 'dim_895', 'dim_896', 'dim_900', 'dim_901', 'dim_902', 'dim_905', 'dim_906', 'dim_910', 'dim_911', 'dim_912', 'dim_915', 'dim_916', 'dim_920', 'dim_921', 'dim_922', 'dim_925', 'dim_926', 'dim_929', 'dim_930', 'dim_931', 'dim_932', 'dim_935', 'dim_939', 'dim_940', 'dim_941', 'dim_942', 'dim_945', 'dim_948', 'dim_949', 'dim_950', 'dim_951', 'dim_952', 'dim_955', 'dim_958', 'dim_959', 'dim_960', 'dim_961', 'dim_962', 'dim_965', 'dim_967', 'dim_968', 'dim_969', 'dim_970', 'dim_971', 'dim_972', 'dim_977', 'dim_978', 'dim_979', 'dim_980', 'dim_981', 'dim_982', 'dim_987', 'dim_988', 'dim_989', 'dim_990', 'dim_991', 'dim_992', 'dim_993', 'dim_994', 'dim_995', 'dim_996', 'dim_997', 'dim_998', 'dim_999', 'dim_1000', 'dim_1001', 'dim_1002', 'dim_1003', 'dim_1004', 'dim_1005', 'dim_1006', 'dim_1007', 'dim_1008', 'dim_1009', 'dim_1010', 'dim_1011', 'dim_1012', 'dim_1013', 'dim_1014', 'dim_1015', 'dim_1016', 'dim_1017', 'dim_1018', 'dim_1019', 'dim_1020', 'dim_1021', 'dim_1022', 'dim_1023', 'dim_1029', 'dim_1030', 'dim_1031', 'dim_1032', 'dim_1039', 'dim_1040', 'dim_1041', 'dim_1042', 'dim_1045', 'dim_1046', 'dim_1050', 'dim_1051', 'dim_1052', 'dim_1056', 'dim_1060', 'dim_1061', 'dim_1062', 'dim_1066', 'dim_1070', 'dim_1071', 'dim_1072', 'dim_1076', 'dim_1081', 'dim_1082', 'dim_1085', 'dim_1086', 'dim_1090', 'dim_1091', 'dim_1092', 'dim_1095', 'dim_1096', 'dim_1100', 'dim_1101', 'dim_1102', 'dim_1105', 'dim_1106', 'dim_1110', 'dim_1111', 'dim_1112', 'dim_1115', 'dim_1116', 'dim_1120', 'dim_1121', 'dim_1122', 'dim_1125', 'dim_1126', 'dim_1131', 'dim_1132', 'dim_1135', 'dim_1136', 'dim_1137', 'dim_1140', 'dim_1141', 'dim_1142', 'dim_1145', 'dim_1146', 'dim_1150', 'dim_1151', 'dim_1152', 'dim_1155', 'dim_1156', 'dim_1160', 'dim_1161', 'dim_1162', 'dim_1165', 'dim_1166', 'dim_1170', 'dim_1171', 'dim_1172', 'dim_1175', 'dim_1176', 'dim_1179', 'dim_1180', 'dim_1181', 'dim_1182', 'dim_1185', 'dim_1189', 'dim_1190', 'dim_1191', 'dim_1192', 'dim_1195', 'dim_1198', 'dim_1199', 'dim_1200', 'dim_1201', 'dim_1202', 'dim_1205', 'dim_1208', 'dim_1209', 'dim_1210', 'dim_1211', 'dim_1212', 'dim_1215', 'dim_1217', 'dim_1218', 'dim_1219', 'dim_1220', 'dim_1221', 'dim_1222', 'dim_1227', 'dim_1228', 'dim_1229', 'dim_1230', 'dim_1231', 'dim_1232', 'dim_1237', 'dim_1238', 'dim_1239', 'dim_1240', 'dim_1241', 'dim_1242', 'dim_1243', 'dim_1244', 'dim_1245', 'dim_1246', 'dim_1247', 'dim_1248', 'dim_1249', 'dim_1250', 'dim_1251', 'dim_1252', 'dim_1253', 'dim_1254', 'dim_1255', 'dim_1256', 'dim_1257', 'dim_1258', 'dim_1259', 'dim_1260', 'dim_1261', 'dim_1262', 'dim_1263', 'dim_1264', 'dim_1265', 'dim_1266', 'dim_1267', 'dim_1268', 'dim_1269', 'dim_1270', 'dim_1271', 'dim_1272', 'dim_1273', 'dim_1279', 'dim_1280', 'dim_1281', 'dim_1282', 'dim_1289', 'dim_1290', 'dim_1291', 'dim_1292', 'dim_1295', 'dim_1296', 'dim_1300', 'dim_1301', 'dim_1302', 'dim_1306', 'dim_1310', 'dim_1311', 'dim_1312', 'dim_1316', 'dim_1320', 'dim_1321', 'dim_1322', 'dim_1326', 'dim_1331', 'dim_1332', 'dim_1335', 'dim_1336', 'dim_1340', 'dim_1341', 'dim_1342', 'dim_1345', 'dim_1346', 'dim_1350', 'dim_1351', 'dim_1352', 'dim_1355', 'dim_1356', 'dim_1360', 'dim_1361', 'dim_1362', 'dim_1365', 'dim_1366', 'dim_1370', 'dim_1371', 'dim_1372', 'dim_1375', 'dim_1376', 'dim_1380', 'dim_1381', 'dim_1382', 'dim_1385', 'dim_1386', 'dim_1387', 'dim_1390', 'dim_1391', 'dim_1392', 'dim_1395', 'dim_1396', 'dim_1400', 'dim_1401', 'dim_1402', 'dim_1405', 'dim_1406', 'dim_1410', 'dim_1411', 'dim_1412', 'dim_1415', 'dim_1416', 'dim_1420', 'dim_1421', 'dim_1422', 'dim_1425', 'dim_1426', 'dim_1429', 'dim_1430', 'dim_1431', 'dim_1432', 'dim_1435', 'dim_1439', 'dim_1440', 'dim_1441', 'dim_1442', 'dim_1445', 'dim_1448', 'dim_1449', 'dim_1450', 'dim_1451', 'dim_1452', 'dim_1455', 'dim_1458', 'dim_1459', 'dim_1460', 'dim_1461', 'dim_1462', 'dim_1465', 'dim_1467', 'dim_1468', 'dim_1469', 'dim_1470', 'dim_1471', 'dim_1472', 'dim_1477', 'dim_1478', 'dim_1479', 'dim_1480', 'dim_1481', 'dim_1482', 'dim_1487', 'dim_1488', 'dim_1489', 'dim_1490', 'dim_1491', 'dim_1492', 'dim_1493', 'dim_1494', 'dim_1495', 'dim_1496', 'dim_1497', 'dim_1498', 'dim_1499', 'dim_1500', 'dim_1501', 'dim_1502', 'dim_1503', 'dim_1504', 'dim_1505', 'dim_1506', 'dim_1507', 'dim_1508', 'dim_1509', 'dim_1510', 'dim_1511', 'dim_1512', 'dim_1513', 'dim_1514', 'dim_1515', 'dim_1516', 'dim_1517', 'dim_1518', 'dim_1519', 'dim_1520', 'dim_1521', 'dim_1522', 'dim_1523', 'dim_1529', 'dim_1530', 'dim_1531', 'dim_1532', 'dim_1539', 'dim_1540', 'dim_1541', 'dim_1542', 'dim_1550', 'dim_1551', 'dim_1552', 'dim_1556', 'dim_1560', 'dim_1561', 'dim_1562', 'dim_1565', 'dim_1566', 'dim_1570', 'dim_1571', 'dim_1572', 'dim_1575', 'dim_1576', 'dim_1581', 'dim_1582', 'dim_1585', 'dim_1586', 'dim_1591', 'dim_1592', 'dim_1595', 'dim_1596', 'dim_1600', 'dim_1601', 'dim_1602', 'dim_1605', 'dim_1606', 'dim_1610', 'dim_1611', 'dim_1612', 'dim_1615', 'dim_1616', 'dim_1617', 'dim_1620', 'dim_1621', 'dim_1622', 'dim_1625', 'dim_1626', 'dim_1627', 'dim_1630', 'dim_1631', 'dim_1632', 'dim_1635', 'dim_1636', 'dim_1637', 'dim_1640', 'dim_1641', 'dim_1642', 'dim_1645', 'dim_1646', 'dim_1650', 'dim_1651', 'dim_1652', 'dim_1655', 'dim_1656', 'dim_1660', 'dim_1661', 'dim_1662', 'dim_1665', 'dim_1666', 'dim_1670', 'dim_1671', 'dim_1672', 'dim_1675', 'dim_1676', 'dim_1679', 'dim_1680', 'dim_1681', 'dim_1682', 'dim_1685', 'dim_1689', 'dim_1690', 'dim_1691', 'dim_1692', 'dim_1695', 'dim_1698', 'dim_1699', 'dim_1700', 'dim_1701', 'dim_1702', 'dim_1705', 'dim_1708', 'dim_1709', 'dim_1710', 'dim_1711', 'dim_1712', 'dim_1715', 'dim_1717', 'dim_1718', 'dim_1719', 'dim_1720', 'dim_1721', 'dim_1722', 'dim_1727', 'dim_1728', 'dim_1729', 'dim_1730', 'dim_1731', 'dim_1732', 'dim_1737', 'dim_1738', 'dim_1739', 'dim_1740', 'dim_1741', 'dim_1742', 'dim_1743', 'dim_1744', 'dim_1745', 'dim_1746', 'dim_1747', 'dim_1748', 'dim_1749', 'dim_1750', 'dim_1751', 'dim_1752', 'dim_1753', 'dim_1754', 'dim_1755', 'dim_1756', 'dim_1757', 'dim_1758', 'dim_1759', 'dim_1760', 'dim_1761', 'dim_1762', 'dim_1763', 'dim_1764', 'dim_1765', 'dim_1766', 'dim_1767', 'dim_1768', 'dim_1769', 'dim_1770', 'dim_1771', 'dim_1772', 'dim_1773', 'dim_1777', 'dim_1779', 'dim_1780', 'dim_1781', 'dim_1782', 'dim_1789', 'dim_1790', 'dim_1791', 'dim_1792', 'dim_1800', 'dim_1801', 'dim_1802', 'dim_1810', 'dim_1811', 'dim_1815', 'dim_1816', 'dim_1820', 'dim_1821', 'dim_1826', 'dim_1830', 'dim_1831', 'dim_1835', 'dim_1836', 'dim_1840', 'dim_1841', 'dim_1842', 'dim_1845', 'dim_1846', 'dim_1850', 'dim_1851', 'dim_1852', 'dim_1855', 'dim_1856', 'dim_1860', 'dim_1861', 'dim_1862', 'dim_1865', 'dim_1866', 'dim_1870', 'dim_1871', 'dim_1872', 'dim_1875', 'dim_1876', 'dim_1880', 'dim_1881', 'dim_1882', 'dim_1885', 'dim_1886', 'dim_1890', 'dim_1891', 'dim_1892', 'dim_1895', 'dim_1896', 'dim_1900', 'dim_1901', 'dim_1902', 'dim_1905', 'dim_1906', 'dim_1910', 'dim_1911', 'dim_1912', 'dim_1915', 'dim_1916', 'dim_1920', 'dim_1921', 'dim_1922', 'dim_1925', 'dim_1929', 'dim_1930', 'dim_1931', 'dim_1932', 'dim_1935', 'dim_1939', 'dim_1940', 'dim_1941', 'dim_1945', 'dim_1948', 'dim_1949', 'dim_1950', 'dim_1951', 'dim_1955', 'dim_1957', 'dim_1958', 'dim_1959', 'dim_1960', 'dim_1961', 'dim_1965', 'dim_1967', 'dim_1968', 'dim_1969', 'dim_1970', 'dim_1971', 'dim_1972', 'dim_1977', 'dim_1978', 'dim_1979', 'dim_1980', 'dim_1981', 'dim_1982', 'dim_1983', 'dim_1986', 'dim_1987', 'dim_1988', 'dim_1989', 'dim_1990', 'dim_1991', 'dim_1992', 'dim_1993', 'dim_1994', 'dim_1995', 'dim_1996', 'dim_1997', 'dim_1998', 'dim_1999', 'dim_2000', 'dim_2001', 'dim_2002', 'dim_2003', 'dim_2004', 'dim_2005', 'dim_2006', 'dim_2007', 'dim_2008', 'dim_2009', 'dim_2010', 'dim_2011', 'dim_2012', 'dim_2013', 'dim_2014', 'dim_2015', 'dim_2016', 'dim_2017', 'dim_2018', 'dim_2019', 'dim_2020', 'dim_2021', 'dim_2022', 'dim_2023', 'dim_2027', 'dim_2029', 'dim_2030', 'dim_2031', 'dim_2032', 'dim_2033', 'dim_2039', 'dim_2040', 'dim_2041', 'dim_2042', 'dim_2049', 'dim_2050', 'dim_2051', 'dim_2058', 'dim_2059', 'dim_2060', 'dim_2068', 'dim_2069', 'dim_2070', 'dim_2078', 'dim_2079', 'dim_2080', 'dim_2081', 'dim_2088', 'dim_2089', 'dim_2090', 'dim_2091', 'dim_2099', 'dim_2100', 'dim_2101', 'dim_2102', 'dim_2109', 'dim_2110', 'dim_2111', 'dim_2112', 'dim_2119', 'dim_2120', 'dim_2121', 'dim_2122', 'dim_2128', 'dim_2129', 'dim_2130', 'dim_2131', 'dim_2132', 'dim_2138', 'dim_2139', 'dim_2140', 'dim_2141', 'dim_2142', 'dim_2149', 'dim_2150', 'dim_2151', 'dim_2152', 'dim_2158', 'dim_2159', 'dim_2160', 'dim_2161', 'dim_2162', 'dim_2168', 'dim_2169', 'dim_2170', 'dim_2171', 'dim_2172', 'dim_2178', 'dim_2179', 'dim_2180', 'dim_2181', 'dim_2188', 'dim_2189', 'dim_2190', 'dim_2197', 'dim_2198', 'dim_2199', 'dim_2200', 'dim_2207', 'dim_2208', 'dim_2209', 'dim_2210', 'dim_2211', 'dim_2217', 'dim_2218', 'dim_2219', 'dim_2220', 'dim_2221', 'dim_2222', 'dim_2227', 'dim_2228', 'dim_2229', 'dim_2230', 'dim_2231', 'dim_2232', 'dim_2233', 'dim_2234', 'dim_2235', 'dim_2236', 'dim_2237', 'dim_2238', 'dim_2239', 'dim_2240', 'dim_2241', 'dim_2242', 'dim_2243', 'dim_2244', 'dim_2245', 'dim_2246', 'dim_2247', 'dim_2248', 'dim_2249', 'dim_2250', 'dim_2251', 'dim_2252', 'dim_2253', 'dim_2254', 'dim_2255', 'dim_2256', 'dim_2257', 'dim_2258', 'dim_2259', 'dim_2260', 'dim_2261', 'dim_2262', 'dim_2263', 'dim_2264', 'dim_2265', 'dim_2266', 'dim_2267', 'dim_2268', 'dim_2269', 'dim_2270', 'dim_2271', 'dim_2272', 'dim_2273', 'dim_2274', 'dim_2275', 'dim_2276', 'dim_2277', 'dim_2278', 'dim_2279', 'dim_2280', 'dim_2281', 'dim_2282', 'dim_2283', 'dim_2284', 'dim_2285', 'dim_2286', 'dim_2287', 'dim_2289', 'dim_2290', 'dim_2291', 'dim_2292', 'dim_2293', 'dim_2296', 'dim_2297', 'dim_2298', 'dim_2299', 'dim_2300', 'dim_2301', 'dim_2302', 'dim_2303', 'dim_2304', 'dim_2305', 'dim_2307', 'dim_2308', 'dim_2309', 'dim_2310', 'dim_2311', 'dim_2312', 'dim_2313', 'dim_2317', 'dim_2318', 'dim_2319', 'dim_2320', 'dim_2321', 'dim_2322', 'dim_2327', 'dim_2328', 'dim_2329', 'dim_2330', 'dim_2331', 'dim_2332', 'dim_2333', 'dim_2337', 'dim_2338', 'dim_2339', 'dim_2340', 'dim_2341', 'dim_2342', 'dim_2343', 'dim_2345', 'dim_2347', 'dim_2348', 'dim_2349', 'dim_2350', 'dim_2351', 'dim_2352', 'dim_2353', 'dim_2355', 'dim_2356', 'dim_2357', 'dim_2358', 'dim_2359', 'dim_2360', 'dim_2361', 'dim_2362', 'dim_2363', 'dim_2364', 'dim_2365', 'dim_2366', 'dim_2367', 'dim_2368', 'dim_2369', 'dim_2370', 'dim_2371', 'dim_2372', 'dim_2373', 'dim_2374', 'dim_2375', 'dim_2376', 'dim_2377', 'dim_2378', 'dim_2379', 'dim_2380', 'dim_2381', 'dim_2382', 'dim_2383', 'dim_2384', 'dim_2385', 'dim_2386', 'dim_2387', 'dim_2388', 'dim_2389', 'dim_2390', 'dim_2391', 'dim_2392', 'dim_2393', 'dim_2394', 'dim_2395', 'dim_2396', 'dim_2397', 'dim_2398', 'dim_2399', 'dim_2400', 'dim_2401', 'dim_2402', 'dim_2403', 'dim_2404', 'dim_2405', 'dim_2406', 'dim_2407', 'dim_2408', 'dim_2409', 'dim_2410', 'dim_2411', 'dim_2412', 'dim_2413', 'dim_2414', 'dim_2415', 'dim_2416', 'dim_2417', 'dim_2418', 'dim_2419', 'dim_2420', 'dim_2421', 'dim_2422', 'dim_2423', 'dim_2424', 'dim_2425', 'dim_2426', 'dim_2427', 'dim_2428', 'dim_2429', 'dim_2430', 'dim_2431', 'dim_2432', 'dim_2434', 'dim_2435', 'dim_2436', 'dim_2437', 'dim_2438', 'dim_2439', 'dim_2440', 'dim_2441', 'dim_2442', 'dim_2447', 'dim_2448', 'dim_2449', 'dim_2450', 'dim_2451', 'dim_2452', 'dim_2453', 'dim_2457', 'dim_2458', 'dim_2459', 'dim_2460', 'dim_2461', 'dim_2462', 'dim_2463', 'dim_2464', 'dim_2465', 'dim_2466', 'dim_2467', 'dim_2468', 'dim_2469', 'dim_2470', 'dim_2471', 'dim_2472', 'dim_2473', 'dim_2474', 'dim_2475', 'dim_2476', 'dim_2477', 'dim_2478', 'dim_2479', 'dim_2480', 'dim_2481', 'dim_2482', 'dim_2483', 'dim_2484', 'dim_2485', 'dim_2486', 'dim_2487', 'dim_2488', 'dim_2489', 'dim_2490', 'dim_2491', 'dim_2492', 'dim_2493', 'dim_2494', 'dim_2495', 'dim_2496', 'dim_2497', 'dim_2498', 'dim_2499', 'dim_2500']\n",
      "\t\tThese features carry no predictive signal and should be manually investigated.\n",
      "\t\tThis is typically a feature which has the same value for all rows.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('int8', 'int') : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n",
      "\t2.8s = Fit runtime\n",
      "\t931 features in original data used to generate 931 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.33 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 2.94s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-2500/learner.pkl\n",
      "Saving ./agModels-2500/utils/data/X.pkl\n",
      "Saving ./agModels-2500/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 931 of 931 features.\n",
      "\tNo valid features to train KNeighborsUnif_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 931 of 931 features.\n",
      "\tNo valid features to train KNeighborsDist_BAG_L1... Skipping this model.\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0492\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.15s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0492\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 931 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0507\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.33s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0488\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.9s\t = Training   runtime\n",
      "\t0.94s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 931 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0505\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.24s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.97s\t = Training   runtime\n",
      "\t0.26s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.049\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.44s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.0484\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.95s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 931 features.\n",
      "\tDropped 0 of 931 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 931 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0514\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.14s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 63\n",
      "Ensemble indices: [7, 5, 0, 5, 7, 5, 7, 0, 5, 7, 6, 5, 7, 5, 7, 0, 5, 7, 5, 0, 7, 5, 7, 5, 0, 7, 5, 7, 5, 0, 7, 5, 7, 5, 0, 7, 5, 7, 5, 0, 7, 5, 6, 7, 5, 0, 7, 5, 7, 5, 0, 7, 5, 5, 7, 0, 5, 7, 0, 5, 7, 7, 5]\n",
      "Ensemble weights: \n",
      "[0.19047619 0.         0.         0.         0.         0.3968254\n",
      " 0.03174603 0.38095238 0.        ]\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.047\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.42s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0478\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.38s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0483\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 940 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0482\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.35s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0487\t = Validation score   (-root_mean_squared_error)\n",
      "\t66.86s\t = Training   runtime\n",
      "\t1.04s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 940 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.28s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.56s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.049\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.78s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0479\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.87s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.0491\t = Validation score   (-root_mean_squared_error)\n",
      "\t21.0s\t = Training   runtime\n",
      "\t0.36s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 16\n",
      "Ensemble indices: [0, 5, 7, 2, 5, 7, 0, 2, 5, 7, 0, 5, 2, 7, 0, 5]\n",
      "Ensemble weights: \n",
      "[0.25   0.     0.1875 0.     0.     0.3125 0.     0.25   0.    ]\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.047\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.0478\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.95s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0473\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.08s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 940 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.34s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t64.8s\t = Training   runtime\n",
      "\t0.99s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 940 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0484\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.4s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.048\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.67s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0486\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.72s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.048\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.43s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.71s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 17\n",
      "Ensemble indices: [1, 5, 7, 1, 5, 1, 5, 1, 7, 1, 5, 1, 5, 1, 7, 5, 1]\n",
      "Ensemble weights: \n",
      "[0.         0.47058824 0.         0.         0.         0.35294118\n",
      " 0.         0.17647059 0.        ]\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.0466\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.47s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.0475\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.75s\t = Training   runtime\n",
      "\t0.3s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0486\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.65s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 940 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.049\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.38s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0488\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.01s\t = Training   runtime\n",
      "\t0.93s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 940 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0485\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.41s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.0477\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.98s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.0491\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.61s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.0471\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.98s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 940 features.\n",
      "\tDropped 0 of 940 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 940 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.0491\t = Validation score   (-root_mean_squared_error)\n",
      "\t3.88s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 17\n",
      "Ensemble indices: [7, 5, 0, 7, 5, 7, 0, 5, 7, 5, 7, 0, 5, 7, 0, 7, 5]\n",
      "Ensemble weights: \n",
      "[0.23529412 0.         0.         0.         0.         0.35294118\n",
      " 0.         0.41176471 0.        ]\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-2500/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0464\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.43s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 465.71s ... Best model: \"WeightedEnsemble_L5\"\n",
      "Loading: ./agModels-2500/models/trainer.pkl\n",
      "Saving ./agModels-2500/models/trainer.pkl\n",
      "Saving ./agModels-2500/learner.pkl\n",
      "Saving ./agModels-2500/predictor.pkl\n",
      "Saving ./agModels-2500/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-2500/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-2500/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-2500'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_2491</th>\n",
       "      <th>dim_2492</th>\n",
       "      <th>dim_2493</th>\n",
       "      <th>dim_2494</th>\n",
       "      <th>dim_2495</th>\n",
       "      <th>dim_2496</th>\n",
       "      <th>dim_2497</th>\n",
       "      <th>dim_2498</th>\n",
       "      <th>dim_2499</th>\n",
       "      <th>dim_2500</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2500 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     dim_1  dim_2  dim_3  dim_4  dim_5  dim_6  dim_7  dim_8  dim_9  dim_10  \\\n",
       "46     0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "101    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "175    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "9      0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "136    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0     0.0   \n",
       "\n",
       "     ...  dim_2491  dim_2492  dim_2493  dim_2494  dim_2495  dim_2496  \\\n",
       "46   ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "101  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "175  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "9    ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "136  ...       0.0       0.0       0.0       0.0       0.0       0.0   \n",
       "\n",
       "     dim_2497  dim_2498  dim_2499  dim_2500  \n",
       "46        0.0       0.0       0.0       0.0  \n",
       "101       0.0       0.0       0.0       0.0  \n",
       "175       0.0       0.0       0.0       0.0  \n",
       "9         0.0       0.0       0.0       0.0  \n",
       "136       0.0       0.0       0.0       0.0  \n",
       "\n",
       "[5 rows x 2500 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-2500/predictor.pkl\n",
      "Loading: ./agModels-2500/learner.pkl\n",
      "Loading: ./agModels-2500/models/trainer.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L5/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.04761924492101431\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.04761924492101431,\n",
      "    \"mean_squared_error\": -0.0022675924868475472,\n",
      "    \"mean_absolute_error\": -0.03446906540610573,\n",
      "    \"r2\": 0.22887031116212764,\n",
      "    \"pearsonr\": 0.486947584161539,\n",
      "    \"median_absolute_error\": -0.026868349075317377\n",
      "}\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'LightGBMXT_BAG_L1': -0.05102421558485313, 'LightGBM_BAG_L1': -0.05102421545128328, 'RandomForestMSE_BAG_L1': -0.048911641796746265, 'CatBoost_BAG_L1': -0.047231987447211514, 'ExtraTreesMSE_BAG_L1': -0.04890842394146744, 'NeuralNetFastAI_BAG_L1': -0.04816492093497614, 'XGBoost_BAG_L1': -0.0484973435589255, 'NeuralNetTorch_BAG_L1': -0.049029582675579976, 'LightGBMLarge_BAG_L1': -0.04855881687493455, 'WeightedEnsemble_L2': -0.04772182987322847, 'LightGBMXT_BAG_L2': -0.0486043417549059, 'LightGBM_BAG_L2': -0.0482208965523629, 'RandomForestMSE_BAG_L2': -0.04841283016499473, 'CatBoost_BAG_L2': -0.047207711311814164, 'ExtraTreesMSE_BAG_L2': -0.04789028968715468, 'NeuralNetFastAI_BAG_L2': -0.04839358326088624, 'XGBoost_BAG_L2': -0.05002487514894737, 'NeuralNetTorch_BAG_L2': -0.04943206799072096, 'LightGBMLarge_BAG_L2': -0.04942023149464669, 'WeightedEnsemble_L3': -0.04797533644074911, 'LightGBMXT_BAG_L3': -0.047323717732859406, 'LightGBM_BAG_L3': -0.047035315208062874, 'RandomForestMSE_BAG_L3': -0.048986223463105445, 'CatBoost_BAG_L3': -0.04676782244444329, 'ExtraTreesMSE_BAG_L3': -0.04838125749481359, 'NeuralNetFastAI_BAG_L3': -0.04816558907273846, 'XGBoost_BAG_L3': -0.04966997421085586, 'NeuralNetTorch_BAG_L3': -0.049139731002137824, 'LightGBMLarge_BAG_L3': -0.048136263299285026, 'WeightedEnsemble_L4': -0.04712585980625486, 'LightGBMXT_BAG_L4': -0.04787126813236954, 'LightGBM_BAG_L4': -0.04791052312171174, 'RandomForestMSE_BAG_L4': -0.04973846632669525, 'CatBoost_BAG_L4': -0.04691061408480312, 'ExtraTreesMSE_BAG_L4': -0.04936934758059131, 'NeuralNetFastAI_BAG_L4': -0.048132826767471056, 'XGBoost_BAG_L4': -0.049005441802237884, 'NeuralNetTorch_BAG_L4': -0.04878997808311537, 'LightGBMLarge_BAG_L4': -0.04827332494246293, 'WeightedEnsemble_L5': -0.04761924492101431}\n"
     ]
    }
   ],
   "source": [
    "%%capture log_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%config Application.log_level = 'DEBUG'\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "with open('./output_2500.log', 'w') as f:\n",
    "    f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n",
      "AutoGluon identified the following types of features:\n",
      "('int', ['bool']) : 931 | ['dim_45', 'dim_46', 'dim_56', 'dim_64', 'dim_65', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39710330963134766\n",
      "0.38989314436912537\n",
      "0.4161602854728699\n",
      "0.4024948179721832\n",
      "0.3839481472969055\n",
      "0.376065194606781\n",
      "0.4571440815925598\n",
      "0.3815762400627136\n",
      "0.3585003614425659\n",
      "0.3601437211036682\n",
      "0.38085508346557617\n",
      "0.46290290355682373\n",
      "0.4863201975822449\n",
      "0.3890072703361511\n",
      "0.41789019107818604\n",
      "0.45741745829582214\n",
      "0.35142141580581665\n",
      "0.4084116816520691\n",
      "0.4917626976966858\n",
      "0.3900336027145386\n",
      "0.4312480092048645\n",
      "0.4155806303024292\n",
      "0.3693515658378601\n",
      "0.44637858867645264\n",
      "0.40180501341819763\n",
      "0.43551403284072876\n",
      "0.3980194330215454\n",
      "0.40118175745010376\n",
      "0.3574053943157196\n",
      "0.34789609909057617\n",
      "0.42498672008514404\n",
      "0.4511289596557617\n",
      "0.45619142055511475\n",
      "0.4138869643211365\n",
      "0.3632771372795105\n",
      "0.38285842537879944\n",
      "0.40462321043014526\n",
      "0.4843026101589203\n",
      "0.39087235927581787\n",
      "0.3579680621623993\n",
      "0.5039079189300537\n",
      "0.377186119556427\n",
      "0.35702213644981384\n",
      "0.33902156352996826\n",
      "0.3688298463821411\n",
      "0.39509856700897217\n",
      "0.4170309007167816\n",
      "0.4031684100627899\n",
      "0.3557468056678772\n",
      "0.3782719373703003\n",
      "0.3849126398563385\n",
      "0.3704322874546051\n",
      "0.3744587004184723\n",
      "0.3619674742221832\n",
      "0.41482067108154297\n",
      "0.39382612705230713\n",
      "0.41887789964675903\n",
      "0.3789104223251343\n",
      "0.37324875593185425\n",
      "0.3631044924259186\n",
      "0.35986024141311646\n",
      "0.39097246527671814\n",
      "0.4556425213813782\n",
      "0.37479907274246216\n",
      "0.3711857795715332\n",
      "0.39347803592681885\n",
      "0.3927406668663025\n",
      "0.35138335824012756\n",
      "0.4227966070175171\n",
      "0.37219178676605225\n",
      "0.36803799867630005\n",
      "0.39155277609825134\n",
      "0.3959135115146637\n",
      "0.3783232569694519\n",
      "0.3933708667755127\n",
      "0.40241819620132446\n",
      "0.4770708680152893\n",
      "0.4336223900318146\n",
      "0.37173277139663696\n",
      "0.4260188341140747\n",
      "0.41121864318847656\n",
      "0.47235172986984253\n",
      "0.3597477078437805\n",
      "0.3620043396949768\n",
      "0.3734092712402344\n",
      "0.40994930267333984\n",
      "0.39567992091178894\n",
      "0.4156615138053894\n",
      "0.4205625355243683\n",
      "0.4047662019729614\n",
      "0.37444740533828735\n",
      "0.35205137729644775\n",
      "0.42819303274154663\n",
      "0.37604403495788574\n",
      "0.41129767894744873\n",
      "0.38668543100357056\n",
      "0.38991591334342957\n",
      "0.3630834221839905\n",
      "0.4976244568824768\n",
      "0.35917729139328003\n",
      "0.42972245812416077\n",
      "0.4122035503387451\n",
      "0.3862426280975342\n",
      "0.39396581053733826\n",
      "0.43176403641700745\n",
      "0.33754611015319824\n",
      "0.37322998046875\n",
      "0.42384421825408936\n",
      "0.41190338134765625\n",
      "0.4836997389793396\n",
      "0.355156809091568\n",
      "0.4262833595275879\n",
      "0.37714338302612305\n",
      "0.411312460899353\n",
      "0.4244304299354553\n",
      "0.40384384989738464\n",
      "0.3785306513309479\n",
      "0.3632577061653137\n",
      "0.5136656165122986\n",
      "0.3824983239173889\n",
      "0.39359545707702637\n",
      "0.3963037133216858\n",
      "0.38179314136505127\n",
      "0.43897688388824463\n",
      "0.4501837491989136\n",
      "0.3722032308578491\n",
      "0.4124525487422943\n",
      "0.4494738280773163\n",
      "0.3872257173061371\n",
      "0.37358611822128296\n",
      "0.39194175601005554\n",
      "0.45495903491973877\n",
      "0.37428468465805054\n",
      "0.3973909616470337\n",
      "0.43652981519699097\n",
      "0.41292452812194824\n",
      "0.406328946352005\n",
      "0.42501187324523926\n",
      "0.38902634382247925\n",
      "0.37046611309051514\n",
      "0.43037447333335876\n",
      "0.4359869360923767\n",
      "0.4038468301296234\n",
      "0.3746655583381653\n",
      "0.40430283546447754\n",
      "0.38530200719833374\n",
      "0.4049142897129059\n",
      "0.4158284068107605\n",
      "0.4024244546890259\n",
      "0.35874366760253906\n",
      "0.42798829078674316\n",
      "0.429379403591156\n",
      "0.46959012746810913\n",
      "0.4684154987335205\n",
      "0.37576496601104736\n",
      "0.34937357902526855\n",
      "0.38768237829208374\n",
      "0.39797624945640564\n",
      "0.3958226442337036\n",
      "0.38313883543014526\n",
      "0.4664316773414612\n",
      "0.36572933197021484\n",
      "0.4365444779396057\n",
      "0.43256568908691406\n",
      "0.3659031391143799\n",
      "0.3642914891242981\n",
      "0.4158809185028076\n",
      "0.43593502044677734\n",
      "0.35037773847579956\n",
      "0.4346615970134735\n",
      "0.36918890476226807\n",
      "0.4020932614803314\n",
      "0.423151433467865\n",
      "0.3970397114753723\n",
      "0.3757229447364807\n",
      "0.449703186750412\n",
      "0.4181106686592102\n",
      "0.3839777708053589\n",
      "0.4350089132785797\n",
      "0.4323734939098358\n",
      "0.38734179735183716\n",
      "0.3548222780227661\n",
      "0.3937785029411316\n",
      "0.38586047291755676\n",
      "0.39347586035728455\n",
      "0.3844718337059021\n",
      "0.45235300064086914\n",
      "0.364853173494339\n",
      "0.43640148639678955\n",
      "0.3637915253639221\n",
      "0.47167137265205383\n",
      "0.36336183547973633\n",
      "0.3592853546142578\n",
      "0.519976019859314\n",
      "0.4598196744918823\n",
      "0.43379706144332886\n",
      "0.40143489837646484\n",
      "0.44711628556251526\n",
      "0.3570399880409241\n",
      "0.4194004535675049\n",
      "0.40854236483573914\n",
      "0.4276360273361206\n",
      "0.37118834257125854\n",
      "0.3643202781677246\n",
      "0.43241825699806213\n",
      "0.37139350175857544\n",
      "0.4055083990097046\n",
      "0.4123913049697876\n",
      "0.40833160281181335\n",
      "0.38674283027648926\n",
      "0.455616295337677\n",
      "0.3883281350135803\n",
      "0.3572452664375305\n",
      "0.4140736758708954\n",
      "0.3867024779319763\n",
      "0.39291059970855713\n",
      "0.39544877409935\n",
      "0.42582014203071594\n",
      "0.4093492031097412\n",
      "0.40542733669281006\n",
      "0.37258073687553406\n",
      "0.3520827293395996\n",
      "0.4609670639038086\n",
      "0.37050706148147583\n",
      "0.4448011517524719\n",
      "0.347087025642395\n",
      "0.36034128069877625\n",
      "0.41007956862449646\n",
      "0.38623541593551636\n",
      "0.3432590961456299\n",
      "0.39715173840522766\n",
      "0.3523007035255432\n",
      "0.409784734249115\n",
      "0.37982672452926636\n",
      "0.37231260538101196\n",
      "0.3628363013267517\n",
      "0.4734950661659241\n",
      "0.36277684569358826\n",
      "0.48968231678009033\n",
      "0.36071765422821045\n",
      "0.38287484645843506\n",
      "0.39681702852249146\n",
      "0.3516167402267456\n",
      "0.399556428194046\n",
      "0.41060107946395874\n",
      "0.39153730869293213\n",
      "0.3874240219593048\n",
      "0.422176331281662\n",
      "0.3861667513847351\n",
      "0.405111700296402\n",
      "0.3630966544151306\n",
      "0.3754849433898926\n",
      "0.3917180597782135\n",
      "0.39062637090682983\n",
      "0.4118552505970001\n",
      "0.43832531571388245\n",
      "0.38188230991363525\n",
      "0.4135515093803406\n",
      "0.3829415440559387\n",
      "0.3718907833099365\n",
      "0.3777437210083008\n",
      "0.38095521926879883\n",
      "0.4596502184867859\n",
      "0.37785804271698\n",
      "0.45709502696990967\n",
      "0.3773416578769684\n",
      "0.38954898715019226\n",
      "0.463321328163147\n",
      "0.42649707198143005\n",
      "0.38838499784469604\n",
      "0.44980451464653015\n",
      "0.4354614019393921\n",
      "0.414512038230896\n",
      "0.3600940704345703\n",
      "0.3470008075237274\n",
      "0.42065492272377014\n",
      "0.35474836826324463\n",
      "0.36786210536956787\n",
      "0.44257405400276184\n",
      "0.3794320523738861\n",
      "0.40705984830856323\n",
      "0.3548073172569275\n",
      "0.38410598039627075\n",
      "0.39106953144073486\n",
      "0.3984982967376709\n",
      "0.37029197812080383\n",
      "0.3522542715072632\n",
      "0.4533696174621582\n",
      "0.392219215631485\n",
      "0.48694878816604614\n",
      "0.3850195109844208\n",
      "0.38469281792640686\n",
      "0.3343204855918884\n",
      "0.3920244574546814\n",
      "0.3838483989238739\n",
      "0.4179859161376953\n",
      "0.3694526255130768\n",
      "0.5321606397628784\n",
      "0.3797048330307007\n",
      "0.4373704493045807\n",
      "0.3970873951911926\n",
      "0.36287522315979004\n",
      "0.44198042154312134\n",
      "0.358875036239624\n",
      "0.3520636260509491\n",
      "0.38498979806900024\n",
      "0.37338873744010925\n",
      "0.3734322488307953\n",
      "0.35194647312164307\n",
      "0.45107513666152954\n",
      "0.5009890794754028\n",
      "0.4902094602584839\n",
      "0.4228525757789612\n",
      "0.38027215003967285\n",
      "0.46917223930358887\n",
      "0.4196197986602783\n",
      "0.4087180197238922\n",
      "0.4256052076816559\n",
      "0.39396581053733826\n",
      "0.3969995975494385\n",
      "0.5192272663116455\n",
      "0.36277687549591064\n",
      "0.35856419801712036\n",
      "0.38258597254753113\n",
      "0.37913838028907776\n",
      "0.4543880820274353\n",
      "0.4204251170158386\n",
      "0.3989417552947998\n",
      "0.33505329489707947\n",
      "0.3882659077644348\n",
      "0.4090016484260559\n",
      "0.34953218698501587\n",
      "0.4452832341194153\n",
      "0.40378332138061523\n",
      "0.38804417848587036\n",
      "0.4473537802696228\n",
      "0.41294577717781067\n",
      "0.46813374757766724\n",
      "0.3511112928390503\n",
      "0.3825870156288147\n",
      "0.3815048635005951\n",
      "0.3899766504764557\n",
      "0.36167699098587036\n",
      "0.4374294579029083\n",
      "0.4439397156238556\n",
      "0.48179978132247925\n",
      "0.36201345920562744\n",
      "0.41789114475250244\n",
      "0.3627684712409973\n",
      "0.388350248336792\n",
      "0.3586454391479492\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model='WeightedEnsemble_L2')\n",
    "for item in train_data_pred:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-2500/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-2500/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3709581792354584\n",
      "0.39781123399734497\n",
      "0.38652729988098145\n",
      "0.48394468426704407\n",
      "0.3812899589538574\n",
      "0.391161173582077\n",
      "0.44227761030197144\n",
      "0.45776379108428955\n",
      "0.3832433223724365\n",
      "0.3516301214694977\n",
      "0.35559791326522827\n",
      "0.4239308536052704\n",
      "0.3728588819503784\n",
      "0.4037756621837616\n",
      "0.43105006217956543\n",
      "0.4614136219024658\n",
      "0.4070982336997986\n",
      "0.39379018545150757\n",
      "0.3815392255783081\n",
      "0.3702477514743805\n",
      "0.4392383098602295\n",
      "0.407199501991272\n",
      "0.3669878840446472\n",
      "0.3767237663269043\n",
      "0.4583629369735718\n",
      "0.36462634801864624\n",
      "0.43059027194976807\n",
      "0.3997010886669159\n",
      "0.4041351079940796\n",
      "0.3874240219593048\n",
      "0.4131343364715576\n",
      "0.3683365285396576\n",
      "0.3995247483253479\n",
      "0.3906843364238739\n",
      "0.3939160108566284\n",
      "0.3839848041534424\n",
      "0.36563029885292053\n",
      "0.4125688970088959\n",
      "0.35674184560775757\n",
      "0.382817804813385\n",
      "0.4668094515800476\n",
      "0.3648838996887207\n",
      "0.42102473974227905\n",
      "0.3817184567451477\n",
      "0.428200364112854\n",
      "0.41982775926589966\n",
      "0.4509764313697815\n",
      "0.3938429057598114\n",
      "0.41135165095329285\n",
      "0.38856297731399536\n",
      "0.3862987756729126\n",
      "0.350617915391922\n",
      "0.4581168293952942\n",
      "0.4202098846435547\n",
      "0.3654058873653412\n",
      "0.37919971346855164\n",
      "0.395775705575943\n",
      "0.39327359199523926\n",
      "0.37035804986953735\n",
      "0.44403308629989624\n",
      "0.40348637104034424\n",
      "0.38572126626968384\n",
      "0.37905383110046387\n",
      "0.4339207410812378\n",
      "0.37636226415634155\n",
      "0.36806952953338623\n",
      "0.41047120094299316\n",
      "0.37151551246643066\n",
      "0.39291059970855713\n",
      "0.4080016016960144\n",
      "0.3686985671520233\n",
      "0.4026948809623718\n",
      "0.3818836808204651\n",
      "0.39158496260643005\n",
      "0.40687140822410583\n",
      "0.3670119345188141\n",
      "0.40493395924568176\n",
      "0.36403757333755493\n",
      "0.3736141622066498\n",
      "0.3910522758960724\n",
      "0.3867274522781372\n",
      "0.41593167185783386\n",
      "0.35367506742477417\n",
      "0.3711698055267334\n",
      "0.401802659034729\n",
      "0.42909279465675354\n",
      "0.3724996745586395\n",
      "0.3981844186782837\n"
     ]
    }
   ],
   "source": [
    "test_data_pred = predictor.predict(test_data, model='WeightedEnsemble_L2')\n",
    "for item in test_data_pred:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
