{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xli/anaconda3/envs/surrogate/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_56</th>\n",
       "      <th>dim_57</th>\n",
       "      <th>dim_58</th>\n",
       "      <th>dim_59</th>\n",
       "      <th>dim_60</th>\n",
       "      <th>dim_61</th>\n",
       "      <th>dim_62</th>\n",
       "      <th>dim_63</th>\n",
       "      <th>dim_64</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-6.639910</td>\n",
       "      <td>-2.575970</td>\n",
       "      <td>-4.333867</td>\n",
       "      <td>0.348634</td>\n",
       "      <td>-6.591602</td>\n",
       "      <td>4.137893</td>\n",
       "      <td>3.448946</td>\n",
       "      <td>9.801783</td>\n",
       "      <td>-4.944950</td>\n",
       "      <td>-1.340411</td>\n",
       "      <td>...</td>\n",
       "      <td>4.211274</td>\n",
       "      <td>0.876610</td>\n",
       "      <td>2.535916</td>\n",
       "      <td>4.460216</td>\n",
       "      <td>7.625662</td>\n",
       "      <td>5.399125</td>\n",
       "      <td>2.165930</td>\n",
       "      <td>1.335564</td>\n",
       "      <td>-6.787674</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>5.044733</td>\n",
       "      <td>2.543681</td>\n",
       "      <td>-3.247805</td>\n",
       "      <td>-5.378260</td>\n",
       "      <td>0.549456</td>\n",
       "      <td>-1.075264</td>\n",
       "      <td>6.259791</td>\n",
       "      <td>5.443143</td>\n",
       "      <td>1.828774</td>\n",
       "      <td>5.774058</td>\n",
       "      <td>...</td>\n",
       "      <td>5.602760</td>\n",
       "      <td>-0.438914</td>\n",
       "      <td>-1.589318</td>\n",
       "      <td>4.962416</td>\n",
       "      <td>2.475589</td>\n",
       "      <td>-6.530942</td>\n",
       "      <td>-0.353212</td>\n",
       "      <td>1.797986</td>\n",
       "      <td>-2.464886</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-0.939149</td>\n",
       "      <td>0.704528</td>\n",
       "      <td>0.749587</td>\n",
       "      <td>-1.643254</td>\n",
       "      <td>-3.556550</td>\n",
       "      <td>0.293420</td>\n",
       "      <td>3.039790</td>\n",
       "      <td>-3.084175</td>\n",
       "      <td>-3.810488</td>\n",
       "      <td>3.759489</td>\n",
       "      <td>...</td>\n",
       "      <td>-4.860520</td>\n",
       "      <td>-0.330673</td>\n",
       "      <td>2.862438</td>\n",
       "      <td>-0.245570</td>\n",
       "      <td>2.726983</td>\n",
       "      <td>-3.573323</td>\n",
       "      <td>-3.095024</td>\n",
       "      <td>0.883057</td>\n",
       "      <td>-0.973858</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-1.177986</td>\n",
       "      <td>1.175732</td>\n",
       "      <td>-1.834498</td>\n",
       "      <td>1.306601</td>\n",
       "      <td>-0.493694</td>\n",
       "      <td>1.298445</td>\n",
       "      <td>2.197183</td>\n",
       "      <td>4.541283</td>\n",
       "      <td>1.859666</td>\n",
       "      <td>3.284920</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.512394</td>\n",
       "      <td>-5.162504</td>\n",
       "      <td>0.902922</td>\n",
       "      <td>7.131485</td>\n",
       "      <td>-3.511894</td>\n",
       "      <td>4.393147</td>\n",
       "      <td>-5.885215</td>\n",
       "      <td>0.389388</td>\n",
       "      <td>5.135883</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.390329</td>\n",
       "      <td>-1.530953</td>\n",
       "      <td>-2.521950</td>\n",
       "      <td>-4.864147</td>\n",
       "      <td>-0.742480</td>\n",
       "      <td>0.146031</td>\n",
       "      <td>-0.156536</td>\n",
       "      <td>1.740131</td>\n",
       "      <td>-2.943921</td>\n",
       "      <td>5.280754</td>\n",
       "      <td>...</td>\n",
       "      <td>1.704322</td>\n",
       "      <td>5.339616</td>\n",
       "      <td>3.019771</td>\n",
       "      <td>6.336881</td>\n",
       "      <td>1.606373</td>\n",
       "      <td>-2.136702</td>\n",
       "      <td>-7.156015</td>\n",
       "      <td>3.795955</td>\n",
       "      <td>1.753440</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "61  -6.639910 -2.575970 -4.333867  0.348634 -6.591602  4.137893  3.448946   \n",
       "354  5.044733  2.543681 -3.247805 -5.378260  0.549456 -1.075264  6.259791   \n",
       "358 -0.939149  0.704528  0.749587 -1.643254 -3.556550  0.293420  3.039790   \n",
       "275 -1.177986  1.175732 -1.834498  1.306601 -0.493694  1.298445  2.197183   \n",
       "18   0.390329 -1.530953 -2.521950 -4.864147 -0.742480  0.146031 -0.156536   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...    dim_56    dim_57    dim_58  \\\n",
       "61   9.801783 -4.944950 -1.340411  ...  4.211274  0.876610  2.535916   \n",
       "354  5.443143  1.828774  5.774058  ...  5.602760 -0.438914 -1.589318   \n",
       "358 -3.084175 -3.810488  3.759489  ... -4.860520 -0.330673  2.862438   \n",
       "275  4.541283  1.859666  3.284920  ... -2.512394 -5.162504  0.902922   \n",
       "18   1.740131 -2.943921  5.280754  ...  1.704322  5.339616  3.019771   \n",
       "\n",
       "       dim_59    dim_60    dim_61    dim_62    dim_63    dim_64   drag  \n",
       "61   4.460216  7.625662  5.399125  2.165930  1.335564 -6.787674  0.375  \n",
       "354  4.962416  2.475589 -6.530942 -0.353212  1.797986 -2.464886  0.374  \n",
       "358 -0.245570  2.726983 -3.573323 -3.095024  0.883057 -0.973858  0.435  \n",
       "275  7.131485 -3.511894  4.393147 -5.885215  0.389388  5.135883  0.437  \n",
       "18   6.336881  1.606373 -2.136702 -7.156015  3.795955  1.753440  0.367  \n",
       "\n",
       "[5 rows x 65 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = './body_vectors_drags.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-body\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Saving ./agModels-body/learner.pkl\n",
      "Saving ./agModels-body/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-body/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 64\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    253345.55 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t64 features in original data used to generate 64 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t0.2s = Fit runtime\n",
      "\t64 features in original data used to generate 64 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.18 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.26s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-body/learner.pkl\n",
      "Saving ./agModels-body/utils/data/X.pkl\n",
      "Saving ./agModels-body/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 64 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t-0.0575\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 64 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t-0.0572\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.01s\t = Training   runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.053\t = Validation score   (-root_mean_squared_error)\n",
      "\t4.5s\t = Training   runtime\n",
      "\t0.05s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0535\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.62s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 64 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.054\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.25s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.053\t = Validation score   (-root_mean_squared_error)\n",
      "\t103.69s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 64 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0535\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.39s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0523\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.34s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0541\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.9s\t = Training   runtime\n",
      "\t0.77s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.0511\t = Validation score   (-root_mean_squared_error)\n",
      "\t18.92s\t = Training   runtime\n",
      "\t0.55s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 64 features.\n",
      "\tDropped 0 of 64 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 64 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0544\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.93s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 11 features.\n",
      "\tDropped 0 of 11 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 11 features.\n",
      "Ensemble size: 57\n",
      "Ensemble indices: [9, 7, 9, 9, 6, 9, 7, 9, 1, 9, 9, 7, 9, 9, 7, 9, 9, 8, 9, 1, 9, 7, 9, 9, 7, 9, 9, 7, 9, 9, 1, 9, 8, 9, 9, 7, 9, 7, 9, 9, 7, 9, 1, 9, 9, 8, 9, 7, 9, 9, 7, 9, 9, 1, 7, 9, 9]\n",
      "Ensemble weights: \n",
      "[0.         0.0877193  0.         0.         0.         0.\n",
      " 0.01754386 0.22807018 0.05263158 0.61403509 0.        ]\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.0506\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.86s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-body/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0522\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.28s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0533\t = Validation score   (-root_mean_squared_error)\n",
      "\t33.08s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 75 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0532\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.2s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0521\t = Validation score   (-root_mean_squared_error)\n",
      "\t82.86s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 75 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0519\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.29s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0496\t = Validation score   (-root_mean_squared_error)\n",
      "\t11.32s\t = Training   runtime\n",
      "\t0.59s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.0536\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.9s\t = Training   runtime\n",
      "\t0.48s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0498\t = Validation score   (-root_mean_squared_error)\n",
      "\t16.05s\t = Training   runtime\n",
      "\t0.51s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 75 features.\n",
      "\tDropped 0 of 75 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 75 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.0536\t = Validation score   (-root_mean_squared_error)\n",
      "\t43.98s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 13\n",
      "Ensemble indices: [5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5, 7, 5]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.         0.53846154\n",
      " 0.         0.46153846 0.        ]\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.0488\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.58s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.0506\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.48s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0507\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.0s\t = Training   runtime\n",
      "\t0.13s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 73 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.0512\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.99s\t = Training   runtime\n",
      "\t0.17s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0512\t = Validation score   (-root_mean_squared_error)\n",
      "\t32.8s\t = Training   runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 73 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0512\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.56s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.0487\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.26s\t = Training   runtime\n",
      "\t0.61s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0516\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.19s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.0502\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.6s\t = Training   runtime\n",
      "\t0.87s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0514\t = Validation score   (-root_mean_squared_error)\n",
      "\t17.62s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 29\n",
      "Ensemble indices: [5, 7, 5, 5, 5, 7, 5, 5, 6, 5, 5, 7, 5, 5, 7, 5, 5, 5, 7, 5, 5, 6, 5, 7, 5, 5, 5, 7, 5]\n",
      "Ensemble weights: \n",
      "[0.         0.         0.         0.         0.         0.68965517\n",
      " 0.06896552 0.24137931 0.        ]\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.0484\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.67s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.05\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.8s\t = Training   runtime\n",
      "\t0.18s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0502\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.64s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 73 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.0508\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.77s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0502\t = Validation score   (-root_mean_squared_error)\n",
      "\t35.28s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 73 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0499\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.48s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.0507\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.95s\t = Training   runtime\n",
      "\t0.5s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.0509\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.79s\t = Training   runtime\n",
      "\t0.42s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.051\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.49s\t = Training   runtime\n",
      "\t0.67s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 73 features.\n",
      "\tDropped 0 of 73 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 73 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-body/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.0504\t = Validation score   (-root_mean_squared_error)\n",
      "\t34.67s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 25\n",
      "Ensemble indices: [4, 1, 5, 7, 8, 4, 6, 4, 5, 7, 8, 4, 5, 4, 7, 8, 5, 4, 4, 1, 6, 7, 8, 5, 4]\n",
      "Ensemble weights: \n",
      "[0.   0.08 0.   0.   0.32 0.2  0.08 0.16 0.16]\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-body/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0495\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.68s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 840.41s ... Best model: \"WeightedEnsemble_L4\"\n",
      "Loading: ./agModels-body/models/trainer.pkl\n",
      "Saving ./agModels-body/models/trainer.pkl\n",
      "Saving ./agModels-body/learner.pkl\n",
      "Saving ./agModels-body/predictor.pkl\n",
      "Saving ./agModels-body/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-body/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-body/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-body'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_55</th>\n",
       "      <th>dim_56</th>\n",
       "      <th>dim_57</th>\n",
       "      <th>dim_58</th>\n",
       "      <th>dim_59</th>\n",
       "      <th>dim_60</th>\n",
       "      <th>dim_61</th>\n",
       "      <th>dim_62</th>\n",
       "      <th>dim_63</th>\n",
       "      <th>dim_64</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>3.262418</td>\n",
       "      <td>4.623484</td>\n",
       "      <td>5.207058</td>\n",
       "      <td>1.474604</td>\n",
       "      <td>5.149589</td>\n",
       "      <td>1.366774</td>\n",
       "      <td>7.350364</td>\n",
       "      <td>4.988407</td>\n",
       "      <td>-4.451728</td>\n",
       "      <td>2.715955</td>\n",
       "      <td>...</td>\n",
       "      <td>3.239450</td>\n",
       "      <td>0.271440</td>\n",
       "      <td>-1.450751</td>\n",
       "      <td>6.201051</td>\n",
       "      <td>2.322523</td>\n",
       "      <td>-0.651795</td>\n",
       "      <td>-2.503192</td>\n",
       "      <td>-1.329733</td>\n",
       "      <td>5.614099</td>\n",
       "      <td>4.784914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-1.815653</td>\n",
       "      <td>0.467063</td>\n",
       "      <td>-0.713573</td>\n",
       "      <td>-2.519432</td>\n",
       "      <td>-6.833046</td>\n",
       "      <td>3.925573</td>\n",
       "      <td>3.131740</td>\n",
       "      <td>2.785505</td>\n",
       "      <td>-0.169789</td>\n",
       "      <td>3.797550</td>\n",
       "      <td>...</td>\n",
       "      <td>8.718956</td>\n",
       "      <td>-4.833921</td>\n",
       "      <td>-1.387358</td>\n",
       "      <td>1.010315</td>\n",
       "      <td>0.467406</td>\n",
       "      <td>-7.262593</td>\n",
       "      <td>0.406025</td>\n",
       "      <td>-4.430325</td>\n",
       "      <td>-4.493312</td>\n",
       "      <td>3.210908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>-0.128397</td>\n",
       "      <td>-0.347771</td>\n",
       "      <td>-4.491439</td>\n",
       "      <td>-0.143762</td>\n",
       "      <td>-1.139696</td>\n",
       "      <td>1.523660</td>\n",
       "      <td>4.283424</td>\n",
       "      <td>1.275272</td>\n",
       "      <td>-3.277825</td>\n",
       "      <td>-0.944104</td>\n",
       "      <td>...</td>\n",
       "      <td>2.371663</td>\n",
       "      <td>-0.860736</td>\n",
       "      <td>-2.739771</td>\n",
       "      <td>4.489244</td>\n",
       "      <td>4.020984</td>\n",
       "      <td>1.973119</td>\n",
       "      <td>3.365454</td>\n",
       "      <td>-2.144289</td>\n",
       "      <td>1.310637</td>\n",
       "      <td>-1.411514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.334880</td>\n",
       "      <td>-0.358754</td>\n",
       "      <td>-5.121314</td>\n",
       "      <td>-1.869275</td>\n",
       "      <td>0.053525</td>\n",
       "      <td>2.998930</td>\n",
       "      <td>-0.482418</td>\n",
       "      <td>1.283854</td>\n",
       "      <td>-1.355309</td>\n",
       "      <td>-0.988547</td>\n",
       "      <td>...</td>\n",
       "      <td>4.671710</td>\n",
       "      <td>-1.422821</td>\n",
       "      <td>0.833765</td>\n",
       "      <td>5.060172</td>\n",
       "      <td>3.785773</td>\n",
       "      <td>1.105779</td>\n",
       "      <td>2.158277</td>\n",
       "      <td>-2.020028</td>\n",
       "      <td>-0.746978</td>\n",
       "      <td>1.548296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>0.339348</td>\n",
       "      <td>2.649365</td>\n",
       "      <td>-1.346519</td>\n",
       "      <td>0.872298</td>\n",
       "      <td>-2.672357</td>\n",
       "      <td>1.983254</td>\n",
       "      <td>2.075392</td>\n",
       "      <td>6.573480</td>\n",
       "      <td>-0.809723</td>\n",
       "      <td>-2.231186</td>\n",
       "      <td>...</td>\n",
       "      <td>0.290699</td>\n",
       "      <td>-0.446408</td>\n",
       "      <td>-5.342670</td>\n",
       "      <td>5.205126</td>\n",
       "      <td>5.651273</td>\n",
       "      <td>-2.507123</td>\n",
       "      <td>1.437673</td>\n",
       "      <td>-3.640510</td>\n",
       "      <td>-1.535356</td>\n",
       "      <td>4.507751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "46   3.262418  4.623484  5.207058  1.474604  5.149589  1.366774  7.350364   \n",
       "101 -1.815653  0.467063 -0.713573 -2.519432 -6.833046  3.925573  3.131740   \n",
       "175 -0.128397 -0.347771 -4.491439 -0.143762 -1.139696  1.523660  4.283424   \n",
       "9   -0.334880 -0.358754 -5.121314 -1.869275  0.053525  2.998930 -0.482418   \n",
       "136  0.339348  2.649365 -1.346519  0.872298 -2.672357  1.983254  2.075392   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...    dim_55    dim_56    dim_57  \\\n",
       "46   4.988407 -4.451728  2.715955  ...  3.239450  0.271440 -1.450751   \n",
       "101  2.785505 -0.169789  3.797550  ...  8.718956 -4.833921 -1.387358   \n",
       "175  1.275272 -3.277825 -0.944104  ...  2.371663 -0.860736 -2.739771   \n",
       "9    1.283854 -1.355309 -0.988547  ...  4.671710 -1.422821  0.833765   \n",
       "136  6.573480 -0.809723 -2.231186  ...  0.290699 -0.446408 -5.342670   \n",
       "\n",
       "       dim_58    dim_59    dim_60    dim_61    dim_62    dim_63    dim_64  \n",
       "46   6.201051  2.322523 -0.651795 -2.503192 -1.329733  5.614099  4.784914  \n",
       "101  1.010315  0.467406 -7.262593  0.406025 -4.430325 -4.493312  3.210908  \n",
       "175  4.489244  4.020984  1.973119  3.365454 -2.144289  1.310637 -1.411514  \n",
       "9    5.060172  3.785773  1.105779  2.158277 -2.020028 -0.746978  1.548296  \n",
       "136  5.205126  5.651273 -2.507123  1.437673 -3.640510 -1.535356  4.507751  \n",
       "\n",
       "[5 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-body/predictor.pkl\n",
      "Loading: ./agModels-body/learner.pkl\n",
      "Loading: ./agModels-body/models/trainer.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L4/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.04923380913265923\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.04923380913265923,\n",
      "    \"mean_squared_error\": -0.002423967961711119,\n",
      "    \"mean_absolute_error\": -0.03645631952448325,\n",
      "    \"r2\": 0.17569242669971186,\n",
      "    \"pearsonr\": 0.42282582143949493,\n",
      "    \"median_absolute_error\": -0.02583747529983521\n",
      "}\n",
      "Loading: ./agModels-body/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'KNeighborsUnif_BAG_L1': -0.05686107468730059, 'KNeighborsDist_BAG_L1': -0.055438219737917495, 'LightGBMXT_BAG_L1': -0.05075740661540731, 'LightGBM_BAG_L1': -0.05125246960815693, 'RandomForestMSE_BAG_L1': -0.05130225527692228, 'CatBoost_BAG_L1': -0.05067925051963413, 'ExtraTreesMSE_BAG_L1': -0.051148361874148174, 'NeuralNetFastAI_BAG_L1': -0.05044114598582887, 'XGBoost_BAG_L1': -0.05126322689534521, 'NeuralNetTorch_BAG_L1': -0.050248873470712115, 'LightGBMLarge_BAG_L1': -0.051409297596885055, 'WeightedEnsemble_L2': -0.04988936601242728, 'LightGBMXT_BAG_L2': -0.05037209243096568, 'LightGBM_BAG_L2': -0.05003862998878183, 'RandomForestMSE_BAG_L2': -0.050975719438399986, 'CatBoost_BAG_L2': -0.05075726206586275, 'ExtraTreesMSE_BAG_L2': -0.05029219871920635, 'NeuralNetFastAI_BAG_L2': -0.04829357728535367, 'XGBoost_BAG_L2': -0.04938961835137461, 'NeuralNetTorch_BAG_L2': -0.05097545881302333, 'LightGBMLarge_BAG_L2': -0.04989085683305959, 'WeightedEnsemble_L3': -0.048994133181961726, 'LightGBMXT_BAG_L3': -0.04997624763255918, 'LightGBM_BAG_L3': -0.0500385489034137, 'RandomForestMSE_BAG_L3': -0.05064893879012936, 'CatBoost_BAG_L3': -0.05018089028642185, 'ExtraTreesMSE_BAG_L3': -0.04960497960524449, 'NeuralNetFastAI_BAG_L3': -0.04895331763434849, 'XGBoost_BAG_L3': -0.05036904578000151, 'NeuralNetTorch_BAG_L3': -0.05187595710538203, 'LightGBMLarge_BAG_L3': -0.04992768997696414, 'WeightedEnsemble_L4': -0.04923380913265923, 'LightGBMXT_BAG_L4': -0.04904986003849432, 'LightGBM_BAG_L4': -0.04833761451716064, 'RandomForestMSE_BAG_L4': -0.049643660697475576, 'CatBoost_BAG_L4': -0.049552619326125355, 'ExtraTreesMSE_BAG_L4': -0.04987652725127662, 'NeuralNetFastAI_BAG_L4': -0.04896496319781716, 'XGBoost_BAG_L4': -0.04808674714148483, 'NeuralNetTorch_BAG_L4': -0.05197031889995571, 'LightGBMLarge_BAG_L4': -0.04880257768318725, 'WeightedEnsemble_L5': -0.04909957407478259}\n"
     ]
    }
   ],
   "source": [
    "%%capture log_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%config Application.log_level = 'DEBUG'\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "with open('./output_body.log', 'w') as f:\n",
    "    f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n",
      "AutoGluon identified the following types of features:\n",
      "('float', []) : 64 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3881307542324066\n",
      "0.38251906633377075\n",
      "0.4216409921646118\n",
      "0.42200013995170593\n",
      "0.38096821308135986\n",
      "0.38039225339889526\n",
      "0.43873852491378784\n",
      "0.3907563090324402\n",
      "0.3591312766075134\n",
      "0.36643072962760925\n",
      "0.3667054772377014\n",
      "0.464578241109848\n",
      "0.44710612297058105\n",
      "0.3700430393218994\n",
      "0.4197707176208496\n",
      "0.4617459177970886\n",
      "0.34730568528175354\n",
      "0.402360200881958\n",
      "0.4759341776371002\n",
      "0.3781774938106537\n",
      "0.4198276996612549\n",
      "0.44099026918411255\n",
      "0.3795541226863861\n",
      "0.4393346309661865\n",
      "0.3853849172592163\n",
      "0.42261114716529846\n",
      "0.3792082667350769\n",
      "0.410521924495697\n",
      "0.3458259105682373\n",
      "0.3492019772529602\n",
      "0.425506055355072\n",
      "0.42241501808166504\n",
      "0.4663676917552948\n",
      "0.44577187299728394\n",
      "0.3637714385986328\n",
      "0.3725951910018921\n",
      "0.3737543225288391\n",
      "0.46589332818984985\n",
      "0.3713909387588501\n",
      "0.34792181849479675\n",
      "0.47387123107910156\n",
      "0.385734498500824\n",
      "0.35619544982910156\n",
      "0.36536723375320435\n",
      "0.38496220111846924\n",
      "0.3746044635772705\n",
      "0.4077088236808777\n",
      "0.42901134490966797\n",
      "0.363161563873291\n",
      "0.4003538489341736\n",
      "0.39476826786994934\n",
      "0.3890886604785919\n",
      "0.3793041706085205\n",
      "0.35769766569137573\n",
      "0.4281940162181854\n",
      "0.39216214418411255\n",
      "0.43153077363967896\n",
      "0.3657521605491638\n",
      "0.3439664840698242\n",
      "0.37200671434402466\n",
      "0.3588109612464905\n",
      "0.37860435247421265\n",
      "0.4285070300102234\n",
      "0.3679886758327484\n",
      "0.3692900538444519\n",
      "0.38589155673980713\n",
      "0.3961983919143677\n",
      "0.3425557613372803\n",
      "0.43515121936798096\n",
      "0.3807433843612671\n",
      "0.4027467966079712\n",
      "0.39486682415008545\n",
      "0.381844162940979\n",
      "0.37785804271698\n",
      "0.39255693554878235\n",
      "0.40220099687576294\n",
      "0.4386063516139984\n",
      "0.43176478147506714\n",
      "0.3911522924900055\n",
      "0.4074800908565521\n",
      "0.42837169766426086\n",
      "0.4815424084663391\n",
      "0.34815114736557007\n",
      "0.34563374519348145\n",
      "0.3676265478134155\n",
      "0.43568915128707886\n",
      "0.3710018992424011\n",
      "0.4250980019569397\n",
      "0.396548867225647\n",
      "0.4045674800872803\n",
      "0.3703958988189697\n",
      "0.3434680104255676\n",
      "0.42125463485717773\n",
      "0.36178046464920044\n",
      "0.43230241537094116\n",
      "0.36855027079582214\n",
      "0.3810480237007141\n",
      "0.3544088900089264\n",
      "0.4652901887893677\n",
      "0.35666388273239136\n",
      "0.42394179105758667\n",
      "0.41328108310699463\n",
      "0.37307208776474\n",
      "0.4210749864578247\n",
      "0.4202582836151123\n",
      "0.35805630683898926\n",
      "0.34856468439102173\n",
      "0.45129653811454773\n",
      "0.4110890030860901\n",
      "0.46035945415496826\n",
      "0.33335426449775696\n",
      "0.417273610830307\n",
      "0.36555159091949463\n",
      "0.4024571180343628\n",
      "0.4298287630081177\n",
      "0.39357855916023254\n",
      "0.353534072637558\n",
      "0.36343914270401\n",
      "0.4715690612792969\n",
      "0.3670707941055298\n",
      "0.40185487270355225\n",
      "0.4018300771713257\n",
      "0.37711167335510254\n",
      "0.4094787836074829\n",
      "0.4328550398349762\n",
      "0.36388683319091797\n",
      "0.43586432933807373\n",
      "0.4563762843608856\n",
      "0.3826602101325989\n",
      "0.38009288907051086\n",
      "0.39618098735809326\n",
      "0.4535062909126282\n",
      "0.3440168797969818\n",
      "0.39406058192253113\n",
      "0.43976688385009766\n",
      "0.4219018220901489\n",
      "0.399461030960083\n",
      "0.43909746408462524\n",
      "0.37587276101112366\n",
      "0.3719899654388428\n",
      "0.4322656989097595\n",
      "0.4230920076370239\n",
      "0.3748946189880371\n",
      "0.3668115735054016\n",
      "0.4054984748363495\n",
      "0.37595775723457336\n",
      "0.40080899000167847\n",
      "0.4223671555519104\n",
      "0.44918906688690186\n",
      "0.36607131361961365\n",
      "0.42737525701522827\n",
      "0.4275650680065155\n",
      "0.4635320007801056\n",
      "0.4608118534088135\n",
      "0.3746805191040039\n",
      "0.35340309143066406\n",
      "0.3933940827846527\n",
      "0.42300647497177124\n",
      "0.41592153906822205\n",
      "0.3893587589263916\n",
      "0.4600728452205658\n",
      "0.3539193272590637\n",
      "0.4390583038330078\n",
      "0.4031658470630646\n",
      "0.3580003082752228\n",
      "0.361508846282959\n",
      "0.4205905795097351\n",
      "0.42846283316612244\n",
      "0.33815068006515503\n",
      "0.43847569823265076\n",
      "0.35977739095687866\n",
      "0.40216368436813354\n",
      "0.40963858366012573\n",
      "0.3987133502960205\n",
      "0.37266266345977783\n",
      "0.443276584148407\n",
      "0.420356810092926\n",
      "0.3808120787143707\n",
      "0.4302856922149658\n",
      "0.41978204250335693\n",
      "0.3901834487915039\n",
      "0.34780192375183105\n",
      "0.39549118280410767\n",
      "0.3847307860851288\n",
      "0.3977819085121155\n",
      "0.35803887248039246\n",
      "0.447094589471817\n",
      "0.34711435437202454\n",
      "0.44972848892211914\n",
      "0.37743836641311646\n",
      "0.4686606526374817\n",
      "0.36040452122688293\n",
      "0.3786783814430237\n",
      "0.4865558445453644\n",
      "0.45655518770217896\n",
      "0.41658860445022583\n",
      "0.4017699360847473\n",
      "0.45319244265556335\n",
      "0.3551461100578308\n",
      "0.4369276165962219\n",
      "0.3971855640411377\n",
      "0.3999101519584656\n",
      "0.3539649248123169\n",
      "0.3523317575454712\n",
      "0.4394404888153076\n",
      "0.3500520586967468\n",
      "0.40496504306793213\n",
      "0.4111941456794739\n",
      "0.42037010192871094\n",
      "0.38766640424728394\n",
      "0.44896185398101807\n",
      "0.3774510622024536\n",
      "0.359078973531723\n",
      "0.41185224056243896\n",
      "0.3643684387207031\n",
      "0.4011837840080261\n",
      "0.3786075711250305\n",
      "0.4192897081375122\n",
      "0.410305380821228\n",
      "0.4032032787799835\n",
      "0.3802614212036133\n",
      "0.3513178825378418\n",
      "0.45529454946517944\n",
      "0.39516597986221313\n",
      "0.45280295610427856\n",
      "0.3222009837627411\n",
      "0.34867510199546814\n",
      "0.4203246235847473\n",
      "0.3928568363189697\n",
      "0.35503512620925903\n",
      "0.4036979079246521\n",
      "0.3515956997871399\n",
      "0.4091055989265442\n",
      "0.3872218132019043\n",
      "0.36127859354019165\n",
      "0.3507743775844574\n",
      "0.4601731300354004\n",
      "0.35891735553741455\n",
      "0.48303818702697754\n",
      "0.36904266476631165\n",
      "0.3965906500816345\n",
      "0.3927859365940094\n",
      "0.35672852396965027\n",
      "0.40103879570961\n",
      "0.4008018970489502\n",
      "0.37130820751190186\n",
      "0.40467405319213867\n",
      "0.4294643998146057\n",
      "0.3568073809146881\n",
      "0.38098281621932983\n",
      "0.3727509379386902\n",
      "0.36937248706817627\n",
      "0.3915032148361206\n",
      "0.40377193689346313\n",
      "0.39127644896507263\n",
      "0.44489797949790955\n",
      "0.3502398133277893\n",
      "0.438956618309021\n",
      "0.39483073353767395\n",
      "0.37801873683929443\n",
      "0.371640145778656\n",
      "0.36456024646759033\n",
      "0.44856154918670654\n",
      "0.34120607376098633\n",
      "0.4543631970882416\n",
      "0.38312432169914246\n",
      "0.39333897829055786\n",
      "0.465596079826355\n",
      "0.4455832839012146\n",
      "0.38466453552246094\n",
      "0.451166033744812\n",
      "0.44738537073135376\n",
      "0.3982253968715668\n",
      "0.34825438261032104\n",
      "0.343169629573822\n",
      "0.42075538635253906\n",
      "0.3359188437461853\n",
      "0.37170636653900146\n",
      "0.4520261287689209\n",
      "0.37206268310546875\n",
      "0.4282768964767456\n",
      "0.3374941945075989\n",
      "0.40115851163864136\n",
      "0.3808978497982025\n",
      "0.3796083927154541\n",
      "0.3552144169807434\n",
      "0.33819061517715454\n",
      "0.44953054189682007\n",
      "0.4073004424571991\n",
      "0.4817332625389099\n",
      "0.4171673059463501\n",
      "0.3758007287979126\n",
      "0.3351380228996277\n",
      "0.37941789627075195\n",
      "0.3757626414299011\n",
      "0.426708459854126\n",
      "0.36284109950065613\n",
      "0.49805593490600586\n",
      "0.3610764741897583\n",
      "0.4320499300956726\n",
      "0.3771536946296692\n",
      "0.3568304181098938\n",
      "0.4000924825668335\n",
      "0.3653581142425537\n",
      "0.3222072720527649\n",
      "0.40991973876953125\n",
      "0.3945624828338623\n",
      "0.3888029456138611\n",
      "0.3585394024848938\n",
      "0.4407055974006653\n",
      "0.47802191972732544\n",
      "0.4714180827140808\n",
      "0.43604540824890137\n",
      "0.3829541802406311\n",
      "0.4676631689071655\n",
      "0.43887823820114136\n",
      "0.4153585135936737\n",
      "0.41971805691719055\n",
      "0.3928722143173218\n",
      "0.40544143319129944\n",
      "0.4955534338951111\n",
      "0.3603314757347107\n",
      "0.3401618003845215\n",
      "0.3724900782108307\n",
      "0.34417131543159485\n",
      "0.44082677364349365\n",
      "0.41640281677246094\n",
      "0.3917335271835327\n",
      "0.3302592635154724\n",
      "0.3822396397590637\n",
      "0.4040537476539612\n",
      "0.3262079358100891\n",
      "0.42684078216552734\n",
      "0.4490145444869995\n",
      "0.39275282621383667\n",
      "0.4521244764328003\n",
      "0.4254350960254669\n",
      "0.44821077585220337\n",
      "0.3511965870857239\n",
      "0.36933112144470215\n",
      "0.359286904335022\n",
      "0.38457992672920227\n",
      "0.33839911222457886\n",
      "0.41717320680618286\n",
      "0.4179080128669739\n",
      "0.45963770151138306\n",
      "0.3440364599227905\n",
      "0.4232262074947357\n",
      "0.3577364683151245\n",
      "0.39229369163513184\n",
      "0.35686570405960083\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model='WeightedEnsemble_L2')\n",
    "for item in train_data_pred:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-body/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-body/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3720833957195282\n",
      "0.36141401529312134\n",
      "0.4118857979774475\n",
      "0.3735848665237427\n",
      "0.39341333508491516\n",
      "0.4107148051261902\n",
      "0.4215391278266907\n",
      "0.4600366950035095\n",
      "0.4157896637916565\n",
      "0.36618757247924805\n",
      "0.3986116051673889\n",
      "0.4177819490432739\n",
      "0.36982667446136475\n",
      "0.429219514131546\n",
      "0.41951000690460205\n",
      "0.40689948201179504\n",
      "0.3786681890487671\n",
      "0.3794932961463928\n",
      "0.3641781806945801\n",
      "0.3630257844924927\n",
      "0.4237116277217865\n",
      "0.410045862197876\n",
      "0.38450005650520325\n",
      "0.4103325605392456\n",
      "0.44294214248657227\n",
      "0.38281816244125366\n",
      "0.4273238182067871\n",
      "0.39389359951019287\n",
      "0.4268495440483093\n",
      "0.39158082008361816\n",
      "0.41073477268218994\n",
      "0.37258750200271606\n",
      "0.38087838888168335\n",
      "0.42573630809783936\n",
      "0.4052094519138336\n",
      "0.3732624053955078\n",
      "0.3703404664993286\n",
      "0.3769264221191406\n",
      "0.40301376581192017\n",
      "0.39169740676879883\n",
      "0.4110051095485687\n",
      "0.3684316873550415\n",
      "0.4364423453807831\n",
      "0.385244220495224\n",
      "0.4016824960708618\n",
      "0.39341384172439575\n",
      "0.40804240107536316\n",
      "0.38155168294906616\n",
      "0.34783822298049927\n",
      "0.3813866376876831\n",
      "0.4023202657699585\n",
      "0.3502122461795807\n",
      "0.43471550941467285\n",
      "0.3897412419319153\n",
      "0.3801504969596863\n",
      "0.3943442106246948\n",
      "0.36864587664604187\n",
      "0.3926504850387573\n",
      "0.3756239414215088\n",
      "0.3729109764099121\n",
      "0.4098741412162781\n",
      "0.3823084831237793\n",
      "0.36965322494506836\n",
      "0.41049131751060486\n",
      "0.37241148948669434\n",
      "0.3538551330566406\n",
      "0.3937172293663025\n",
      "0.3512486219406128\n",
      "0.40288496017456055\n",
      "0.3970578908920288\n",
      "0.3764130175113678\n",
      "0.3848602771759033\n",
      "0.3759842813014984\n",
      "0.40992599725723267\n",
      "0.37758737802505493\n",
      "0.3890823721885681\n",
      "0.41134196519851685\n",
      "0.3736436665058136\n",
      "0.39220601320266724\n",
      "0.36523276567459106\n",
      "0.38973119854927063\n",
      "0.4120485782623291\n",
      "0.37307846546173096\n",
      "0.38072440028190613\n",
      "0.3799424171447754\n",
      "0.4164334237575531\n",
      "0.4073110520839691\n",
      "0.40277576446533203\n"
     ]
    }
   ],
   "source": [
    "test_data_pred = predictor.predict(test_data, model='WeightedEnsemble_L2')\n",
    "for item in test_data_pred:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
