{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loaded data from: ./spvae_vectors_drags.csv | Columns = 131 / 131 | Rows = 439 -> 439\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_120</th>\n",
       "      <th>dim_121</th>\n",
       "      <th>dim_122</th>\n",
       "      <th>dim_123</th>\n",
       "      <th>dim_124</th>\n",
       "      <th>dim_125</th>\n",
       "      <th>dim_126</th>\n",
       "      <th>dim_127</th>\n",
       "      <th>dim_128</th>\n",
       "      <th>drag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>-0.996583</td>\n",
       "      <td>0.253377</td>\n",
       "      <td>2.345441</td>\n",
       "      <td>-0.989086</td>\n",
       "      <td>-2.179726</td>\n",
       "      <td>4.450816</td>\n",
       "      <td>-0.333054</td>\n",
       "      <td>-0.833110</td>\n",
       "      <td>0.170525</td>\n",
       "      <td>0.681121</td>\n",
       "      <td>...</td>\n",
       "      <td>1.321793</td>\n",
       "      <td>-0.977492</td>\n",
       "      <td>0.493258</td>\n",
       "      <td>-2.447803</td>\n",
       "      <td>-0.851386</td>\n",
       "      <td>0.003659</td>\n",
       "      <td>-0.704168</td>\n",
       "      <td>0.301570</td>\n",
       "      <td>0.179546</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>-0.107085</td>\n",
       "      <td>1.786517</td>\n",
       "      <td>1.586284</td>\n",
       "      <td>-1.288352</td>\n",
       "      <td>-1.469519</td>\n",
       "      <td>1.856284</td>\n",
       "      <td>0.022899</td>\n",
       "      <td>0.707441</td>\n",
       "      <td>0.195338</td>\n",
       "      <td>0.934119</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785785</td>\n",
       "      <td>-1.589034</td>\n",
       "      <td>-3.525021</td>\n",
       "      <td>-4.223967</td>\n",
       "      <td>-2.653476</td>\n",
       "      <td>0.012422</td>\n",
       "      <td>0.597222</td>\n",
       "      <td>0.977202</td>\n",
       "      <td>-0.662360</td>\n",
       "      <td>0.374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>-3.295154</td>\n",
       "      <td>-1.133777</td>\n",
       "      <td>-0.713116</td>\n",
       "      <td>0.946432</td>\n",
       "      <td>0.027521</td>\n",
       "      <td>0.023506</td>\n",
       "      <td>0.565126</td>\n",
       "      <td>-1.224105</td>\n",
       "      <td>-0.519147</td>\n",
       "      <td>0.146645</td>\n",
       "      <td>...</td>\n",
       "      <td>2.272549</td>\n",
       "      <td>-0.996835</td>\n",
       "      <td>5.970934</td>\n",
       "      <td>0.562599</td>\n",
       "      <td>3.063003</td>\n",
       "      <td>-0.003317</td>\n",
       "      <td>1.284646</td>\n",
       "      <td>-0.388674</td>\n",
       "      <td>0.367492</td>\n",
       "      <td>0.435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>-0.809618</td>\n",
       "      <td>-1.043127</td>\n",
       "      <td>0.594460</td>\n",
       "      <td>1.935878</td>\n",
       "      <td>0.173827</td>\n",
       "      <td>1.941216</td>\n",
       "      <td>-0.689809</td>\n",
       "      <td>-1.535557</td>\n",
       "      <td>1.745006</td>\n",
       "      <td>0.349334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.602183</td>\n",
       "      <td>-0.519529</td>\n",
       "      <td>0.047703</td>\n",
       "      <td>1.788710</td>\n",
       "      <td>-0.448435</td>\n",
       "      <td>-0.003273</td>\n",
       "      <td>-0.998566</td>\n",
       "      <td>-0.302207</td>\n",
       "      <td>0.684875</td>\n",
       "      <td>0.437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.572277</td>\n",
       "      <td>-0.328782</td>\n",
       "      <td>0.444743</td>\n",
       "      <td>0.411545</td>\n",
       "      <td>-1.628947</td>\n",
       "      <td>3.242414</td>\n",
       "      <td>-0.008619</td>\n",
       "      <td>-0.790840</td>\n",
       "      <td>0.288297</td>\n",
       "      <td>0.432827</td>\n",
       "      <td>...</td>\n",
       "      <td>2.103731</td>\n",
       "      <td>-2.167353</td>\n",
       "      <td>-1.278066</td>\n",
       "      <td>-1.638192</td>\n",
       "      <td>2.981116</td>\n",
       "      <td>0.002460</td>\n",
       "      <td>-0.616031</td>\n",
       "      <td>-0.505367</td>\n",
       "      <td>0.432376</td>\n",
       "      <td>0.367</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 129 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "61  -0.996583  0.253377  2.345441 -0.989086 -2.179726  4.450816 -0.333054   \n",
       "354 -0.107085  1.786517  1.586284 -1.288352 -1.469519  1.856284  0.022899   \n",
       "358 -3.295154 -1.133777 -0.713116  0.946432  0.027521  0.023506  0.565126   \n",
       "275 -0.809618 -1.043127  0.594460  1.935878  0.173827  1.941216 -0.689809   \n",
       "18  -0.572277 -0.328782  0.444743  0.411545 -1.628947  3.242414 -0.008619   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...   dim_120   dim_121   dim_122  \\\n",
       "61  -0.833110  0.170525  0.681121  ...  1.321793 -0.977492  0.493258   \n",
       "354  0.707441  0.195338  0.934119  ...  0.785785 -1.589034 -3.525021   \n",
       "358 -1.224105 -0.519147  0.146645  ...  2.272549 -0.996835  5.970934   \n",
       "275 -1.535557  1.745006  0.349334  ...  0.602183 -0.519529  0.047703   \n",
       "18  -0.790840  0.288297  0.432827  ...  2.103731 -2.167353 -1.278066   \n",
       "\n",
       "      dim_123   dim_124   dim_125   dim_126   dim_127   dim_128   drag  \n",
       "61  -2.447803 -0.851386  0.003659 -0.704168  0.301570  0.179546  0.375  \n",
       "354 -4.223967 -2.653476  0.012422  0.597222  0.977202 -0.662360  0.374  \n",
       "358  0.562599  3.063003 -0.003317  1.284646 -0.388674  0.367492  0.435  \n",
       "275  1.788710 -0.448435 -0.003273 -0.998566 -0.302207  0.684875  0.437  \n",
       "18  -1.638192  2.981116  0.002460 -0.616031 -0.505367  0.432376  0.367  \n",
       "\n",
       "[5 rows x 129 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#surrogate models\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_file = './spvae_vectors_drags.csv'\n",
    "df = TabularDataset(data_file)\n",
    "\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=777)\n",
    "\n",
    "#exclue the first two columns of train data\n",
    "train_data = train_df.drop(columns=['i', 'name'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 , 0.375\n",
      "354 , 0.374\n",
      "358 , 0.435\n",
      "275 , 0.437\n",
      "18 , 0.367\n",
      "107 , 0.36\n",
      "57 , 0.456\n",
      "430 , 0.386\n",
      "374 , 0.345\n",
      "179 , 0.345\n",
      "287 , 0.341\n",
      "51 , 0.55\n",
      "395 , 0.48\n",
      "133 , 0.371\n",
      "233 , 0.427\n",
      "210 , 0.478\n",
      "151 , 0.294\n",
      "375 , 0.411\n",
      "24 , 0.538\n",
      "311 , 0.356\n",
      "152 , 0.429\n",
      "369 , 0.478\n",
      "8 , 0.317\n",
      "90 , 0.439\n",
      "47 , 0.418\n",
      "305 , 0.423\n",
      "421 , 0.377\n",
      "253 , 0.418\n",
      "167 , 0.322\n",
      "315 , 0.355\n",
      "345 , 0.489\n",
      "366 , 0.42\n",
      "41 , 0.51\n",
      "359 , 0.453\n",
      "269 , 0.362\n",
      "56 , 0.375\n",
      "193 , 0.408\n",
      "283 , 0.513\n",
      "204 , 0.315\n",
      "224 , 0.333\n",
      "316 , 0.571\n",
      "19 , 0.375\n",
      "150 , 0.33\n",
      "118 , 0.298\n",
      "58 , 0.341\n",
      "223 , 0.359\n",
      "1 , 0.393\n",
      "226 , 0.403\n",
      "124 , 0.339\n",
      "232 , 0.404\n",
      "278 , 0.404\n",
      "342 , 0.344\n",
      "26 , 0.4\n",
      "390 , 0.326\n",
      "379 , 0.417\n",
      "81 , 0.384\n",
      "236 , 0.432\n",
      "100 , 0.374\n",
      "383 , 0.315\n",
      "148 , 0.334\n",
      "3 , 0.337\n",
      "371 , 0.329\n",
      "123 , 0.446\n",
      "231 , 0.348\n",
      "248 , 0.37\n",
      "39 , 0.379\n",
      "120 , 0.439\n",
      "273 , 0.317\n",
      "29 , 0.436\n",
      "378 , 0.371\n",
      "352 , 0.429\n",
      "154 , 0.362\n",
      "407 , 0.347\n",
      "131 , 0.357\n",
      "261 , 0.387\n",
      "262 , 0.402\n",
      "382 , 0.468\n",
      "10 , 0.425\n",
      "88 , 0.402\n",
      "372 , 0.445\n",
      "73 , 0.417\n",
      "234 , 0.516\n",
      "106 , 0.307\n",
      "213 , 0.334\n",
      "364 , 0.356\n",
      "206 , 0.434\n",
      "33 , 0.38\n",
      "437 , 0.456\n",
      "353 , 0.392\n",
      "176 , 0.397\n",
      "337 , 0.336\n",
      "399 , 0.304\n",
      "335 , 0.469\n",
      "140 , 0.349\n",
      "256 , 0.427\n",
      "250 , 0.344\n",
      "419 , 0.373\n",
      "98 , 0.335\n",
      "373 , 0.516\n",
      "93 , 0.335\n",
      "208 , 0.423\n",
      "149 , 0.431\n",
      "70 , 0.358\n",
      "336 , 0.416\n",
      "13 , 0.435\n",
      "293 , 0.322\n",
      "327 , 0.315\n",
      "212 , 0.441\n",
      "319 , 0.404\n",
      "289 , 0.518\n",
      "119 , 0.294\n",
      "76 , 0.418\n",
      "158 , 0.355\n",
      "320 , 0.407\n",
      "191 , 0.431\n",
      "155 , 0.384\n",
      "414 , 0.324\n",
      "240 , 0.341\n",
      "67 , 0.547\n",
      "22 , 0.357\n",
      "367 , 0.408\n",
      "246 , 0.42\n",
      "160 , 0.374\n",
      "194 , 0.425\n",
      "332 , 0.454\n",
      "249 , 0.332\n",
      "143 , 0.456\n",
      "393 , 0.49\n",
      "132 , 0.366\n",
      "15 , 0.327\n",
      "137 , 0.372\n",
      "96 , 0.465\n",
      "308 , 0.322\n",
      "201 , 0.387\n",
      "209 , 0.459\n",
      "296 , 0.437\n",
      "285 , 0.388\n",
      "156 , 0.479\n",
      "114 , 0.367\n",
      "135 , 0.337\n",
      "141 , 0.441\n",
      "279 , 0.415\n",
      "329 , 0.381\n",
      "306 , 0.364\n",
      "424 , 0.402\n",
      "267 , 0.377\n",
      "403 , 0.4\n",
      "284 , 0.397\n",
      "218 , 0.474\n",
      "159 , 0.339\n",
      "247 , 0.441\n",
      "391 , 0.453\n",
      "389 , 0.509\n",
      "270 , 0.472\n",
      "207 , 0.394\n",
      "122 , 0.35\n",
      "377 , 0.387\n",
      "310 , 0.452\n",
      "434 , 0.432\n",
      "301 , 0.365\n",
      "69 , 0.477\n",
      "230 , 0.348\n",
      "121 , 0.44\n",
      "68 , 0.411\n",
      "129 , 0.338\n",
      "197 , 0.334\n",
      "111 , 0.433\n",
      "258 , 0.441\n",
      "84 , 0.306\n",
      "219 , 0.417\n",
      "216 , 0.358\n",
      "214 , 0.403\n",
      "268 , 0.407\n",
      "139 , 0.399\n",
      "386 , 0.409\n",
      "45 , 0.449\n",
      "405 , 0.478\n",
      "163 , 0.382\n",
      "105 , 0.428\n",
      "344 , 0.437\n",
      "11 , 0.429\n",
      "43 , 0.333\n",
      "82 , 0.393\n",
      "350 , 0.38\n",
      "396 , 0.403\n",
      "102 , 0.349\n",
      "220 , 0.458\n",
      "274 , 0.337\n",
      "27 , 0.46\n",
      "299 , 0.366\n",
      "66 , 0.47\n",
      "112 , 0.347\n",
      "211 , 0.375\n",
      "370 , 0.547\n",
      "35 , 0.503\n",
      "333 , 0.436\n",
      "266 , 0.415\n",
      "180 , 0.47\n",
      "254 , 0.323\n",
      "291 , 0.456\n",
      "40 , 0.387\n",
      "2 , 0.404\n",
      "244 , 0.357\n",
      "64 , 0.327\n",
      "313 , 0.445\n",
      "14 , 0.335\n",
      "94 , 0.393\n",
      "410 , 0.422\n",
      "404 , 0.414\n",
      "83 , 0.385\n",
      "288 , 0.522\n",
      "259 , 0.373\n",
      "162 , 0.355\n",
      "203 , 0.419\n",
      "113 , 0.355\n",
      "205 , 0.345\n",
      "431 , 0.373\n",
      "385 , 0.418\n",
      "42 , 0.427\n",
      "380 , 0.421\n",
      "387 , 0.361\n",
      "104 , 0.318\n",
      "317 , 0.497\n",
      "298 , 0.407\n",
      "294 , 0.483\n",
      "348 , 0.288\n",
      "394 , 0.333\n",
      "227 , 0.393\n",
      "198 , 0.363\n",
      "435 , 0.319\n",
      "126 , 0.403\n",
      "331 , 0.321\n",
      "363 , 0.417\n",
      "164 , 0.384\n",
      "251 , 0.336\n",
      "181 , 0.339\n",
      "357 , 0.51\n",
      "49 , 0.357\n",
      "432 , 0.527\n",
      "346 , 0.358\n",
      "388 , 0.424\n",
      "425 , 0.393\n",
      "323 , 0.333\n",
      "20 , 0.4\n",
      "99 , 0.409\n",
      "413 , 0.364\n",
      "415 , 0.417\n",
      "199 , 0.427\n",
      "30 , 0.357\n",
      "297 , 0.387\n",
      "343 , 0.358\n",
      "62 , 0.375\n",
      "109 , 0.402\n",
      "91 , 0.399\n",
      "44 , 0.395\n",
      "23 , 0.472\n",
      "37 , 0.328\n",
      "314 , 0.451\n",
      "125 , 0.36\n",
      "235 , 0.341\n",
      "195 , 0.333\n",
      "34 , 0.363\n",
      "182 , 0.466\n",
      "95 , 0.321\n",
      "190 , 0.481\n",
      "85 , 0.377\n",
      "272 , 0.398\n",
      "108 , 0.495\n",
      "265 , 0.471\n",
      "264 , 0.375\n",
      "17 , 0.507\n",
      "429 , 0.478\n",
      "189 , 0.397\n",
      "427 , 0.318\n",
      "217 , 0.325\n",
      "183 , 0.431\n",
      "309 , 0.296\n",
      "0 , 0.32\n",
      "341 , 0.481\n",
      "392 , 0.382\n",
      "117 , 0.446\n",
      "356 , 0.313\n",
      "361 , 0.395\n",
      "80 , 0.394\n",
      "4 , 0.377\n",
      "330 , 0.34\n",
      "228 , 0.322\n",
      "138 , 0.494\n",
      "276 , 0.394\n",
      "225 , 0.53\n",
      "221 , 0.421\n",
      "229 , 0.368\n",
      "92 , 0.296\n",
      "245 , 0.338\n",
      "28 , 0.362\n",
      "78 , 0.435\n",
      "53 , 0.361\n",
      "38 , 0.598\n",
      "384 , 0.345\n",
      "171 , 0.428\n",
      "292 , 0.371\n",
      "115 , 0.334\n",
      "237 , 0.405\n",
      "355 , 0.335\n",
      "16 , 0.323\n",
      "130 , 0.415\n",
      "186 , 0.413\n",
      "307 , 0.36\n",
      "360 , 0.335\n",
      "128 , 0.444\n",
      "376 , 0.573\n",
      "271 , 0.541\n",
      "60 , 0.438\n",
      "202 , 0.381\n",
      "322 , 0.536\n",
      "326 , 0.433\n",
      "312 , 0.454\n",
      "324 , 0.424\n",
      "365 , 0.391\n",
      "318 , 0.395\n",
      "50 , 0.576\n",
      "418 , 0.367\n",
      "74 , 0.322\n",
      "438 , 0.351\n",
      "187 , 0.327\n",
      "31 , 0.461\n",
      "65 , 0.39\n",
      "263 , 0.409\n",
      "325 , 0.278\n",
      "340 , 0.378\n",
      "338 , 0.413\n",
      "321 , 0.299\n",
      "347 , 0.435\n",
      "32 , 0.484\n",
      "142 , 0.429\n",
      "397 , 0.468\n",
      "402 , 0.441\n",
      "295 , 0.482\n",
      "280 , 0.345\n",
      "302 , 0.367\n",
      "423 , 0.355\n",
      "116 , 0.388\n",
      "127 , 0.328\n",
      "157 , 0.417\n",
      "71 , 0.419\n",
      "433 , 0.503\n",
      "87 , 0.321\n",
      "422 , 0.437\n",
      "59 , 0.338\n",
      "303 , 0.385\n",
      "103 , 0.337\n"
     ]
    }
   ],
   "source": [
    "train_drags = train_df[\"drag\"]\n",
    "train_index = train_df[\"i\"]\n",
    "for index, drag in zip(train_index, train_drags):\n",
    "    print(index, \",\" ,drag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of class variable: \n",
      " count    351.000000\n",
      "mean       0.398513\n",
      "std        0.060013\n",
      "min        0.278000\n",
      "25%        0.353000\n",
      "50%        0.394000\n",
      "75%        0.435000\n",
      "max        0.598000\n",
      "Name: drag, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "label = 'drag'\n",
    "print(\"Summary of class variable: \\n\", train_data[label].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"./agModels-spvae\"\n",
      "Presets specified: ['best_quality']\n",
      "============ fit kwarg info ============\n",
      "User Specified kwargs:\n",
      "{'auto_stack': 'True',\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'verbosity': 4}\n",
      "Full kwargs:\n",
      "{'_feature_generator_kwargs': None,\n",
      " '_save_bag_folds': None,\n",
      " 'ag_args': None,\n",
      " 'ag_args_ensemble': None,\n",
      " 'ag_args_fit': None,\n",
      " 'auto_stack': 'True',\n",
      " 'calibrate': 'auto',\n",
      " 'excluded_model_types': None,\n",
      " 'feature_generator': 'auto',\n",
      " 'feature_prune_kwargs': None,\n",
      " 'holdout_frac': None,\n",
      " 'hyperparameter_tune_kwargs': None,\n",
      " 'keep_only_best': False,\n",
      " 'name_suffix': None,\n",
      " 'num_bag_folds': 5,\n",
      " 'num_bag_sets': 3,\n",
      " 'num_stack_levels': 3,\n",
      " 'pseudo_data': None,\n",
      " 'refit_full': False,\n",
      " 'save_space': False,\n",
      " 'set_best_to_refit_full': False,\n",
      " 'unlabeled_data': None,\n",
      " 'use_bag_holdout': False,\n",
      " 'verbosity': 4}\n",
      "========================================\n",
      "Stack configuration (auto_stack=True): num_stack_levels=3, num_bag_folds=5, num_bag_sets=3\n",
      "Saving ./agModels-spvae/learner.pkl\n",
      "Saving ./agModels-spvae/predictor.pkl\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"./agModels-spvae/\"\n",
      "AutoGluon Version:  0.7.0\n",
      "Python Version:     3.10.10\n",
      "Operating System:   Linux\n",
      "Platform Machine:   x86_64\n",
      "Platform Version:   #51-Ubuntu SMP Mon Jul 4 06:41:22 UTC 2022\n",
      "Train Data Rows:    351\n",
      "Train Data Columns: 128\n",
      "Label Column: drag\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'regression' (because dtype of label-column == float and many unique label-values observed).\n",
      "\tLabel info (max, min, mean, stddev): (0.598, 0.278, 0.39851, 0.06001)\n",
      "\tIf 'regression' is not the correct problem_type, please manually specify the problem_type parameter during predictor init (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    253255.16 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\t\t\tOriginal Features (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.1s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\t\tSkipping CategoryFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping DatetimeFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextSpecialFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping TextNgramFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IdentityFeatureGenerator: No input feature with required dtypes.\n",
      "\t\tSkipping IsNanFeatureGenerator: No input feature with required dtypes.\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\t\t\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t\t\t0.0s = Fit runtime\n",
      "\t\t\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTypes of features in original data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (exact raw dtype, raw dtype):\n",
      "\t\t('float64', 'float') : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n",
      "\t0.3s = Fit runtime\n",
      "\t128 features in original data used to generate 128 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.36 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 0.38s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_error'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "\tTo change this, specify the eval_metric parameter of Predictor()\n",
      "Saving ./agModels-spvae/learner.pkl\n",
      "Saving ./agModels-spvae/utils/data/X.pkl\n",
      "Saving ./agModels-spvae/utils/data/y.pkl\n",
      "AutoGluon will fit 4 stack levels (L1 to L4) ...\n",
      "Model configs that will be trained (in order):\n",
      "\tKNeighborsUnif_BAG_L1: \t{'weights': 'uniform', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Unif', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tKNeighborsDist_BAG_L1: \t{'weights': 'distance', 'ag_args': {'valid_stacker': False, 'name_suffix': 'Dist', 'model_type': <class 'autogluon.tabular.models.knn.knn_model.KNNModel'>, 'priority': 100}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tLightGBMXT_BAG_L1: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L1: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L1: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L1: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 11 L1 models ...\n",
      "Fitting model: KNeighborsUnif_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting KNeighborsUnif_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsUnif_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 128 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "\t-0.0575\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.29s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: KNeighborsDist_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting KNeighborsDist_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 128 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "\t-0.0572\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.02s\t = Training   runtime\n",
      "\t0.27s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBMXT_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting LightGBMXT_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L1/model.pkl\n",
      "\t-0.0565\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.23s\t = Training   runtime\n",
      "\t0.03s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting LightGBM_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L1/model.pkl\n",
      "\t-0.0563\t = Validation score   (-root_mean_squared_error)\n",
      "\t19.62s\t = Training   runtime\n",
      "\t0.14s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting RandomForestMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 128 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "\t-0.0573\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.77s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting CatBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L1/model.pkl\n",
      "\t-0.0563\t = Validation score   (-root_mean_squared_error)\n",
      "\t37.89s\t = Training   runtime\n",
      "\t0.12s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/utils/model_template.pkl\n",
      "\tDropped 0 of 128 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "\t-0.0564\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.88s\t = Training   runtime\n",
      "\t0.19s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "\t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\t5.09s\t = Training   runtime\n",
      "\t0.47s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting XGBoost_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L1/model.pkl\n",
      "\t-0.0584\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.36s\t = Training   runtime\n",
      "\t0.16s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting NeuralNetTorch_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "\t-0.057\t = Validation score   (-root_mean_squared_error)\n",
      "\t7.16s\t = Training   runtime\n",
      "\t0.25s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L1 ...\n",
      "\tDropped 0 of 128 features.\n",
      "\tDropped 0 of 128 features.\n",
      "\tFitting LightGBMLarge_BAG_L1 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L1/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 128 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "\t-0.0571\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.78s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L2: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\tDropped 0 of 11 features.\n",
      "\tDropped 0 of 11 features.\n",
      "\tFitting WeightedEnsemble_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 11 features.\n",
      "Ensemble size: 17\n",
      "Ensemble indices: [7, 1, 3, 7, 1, 3, 1, 7, 3, 1, 7, 3, 1, 7, 3, 1, 7]\n",
      "Ensemble weights: \n",
      "[0.         0.35294118 0.         0.29411765 0.         0.\n",
      " 0.         0.35294118 0.         0.         0.        ]\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L2/model.pkl\n",
      "\t-0.0552\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.77s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L2: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L2: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L2: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L2: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L2 models ...\n",
      "Loading: ./agModels-spvae/models/KNeighborsUnif_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L1/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L1/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting LightGBMXT_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L2/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t24.65s\t = Training   runtime\n",
      "\t0.54s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting LightGBM_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L2/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t54.66s\t = Training   runtime\n",
      "\t0.33s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting RandomForestMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 139 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "\t-0.0567\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.59s\t = Training   runtime\n",
      "\t0.23s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting CatBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L2/model.pkl\n",
      "\t-0.0556\t = Validation score   (-root_mean_squared_error)\n",
      "\t381.57s\t = Training   runtime\n",
      "\t0.22s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/utils/model_template.pkl\n",
      "\tDropped 0 of 139 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "\t-0.0561\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.02s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "\t-0.0526\t = Validation score   (-root_mean_squared_error)\n",
      "\t14.65s\t = Training   runtime\n",
      "\t0.7s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting XGBoost_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L2/model.pkl\n",
      "\t-0.058\t = Validation score   (-root_mean_squared_error)\n",
      "\t22.03s\t = Training   runtime\n",
      "\t0.31s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting NeuralNetTorch_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "\t-0.0521\t = Validation score   (-root_mean_squared_error)\n",
      "\t25.51s\t = Training   runtime\n",
      "\t0.64s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L2 ...\n",
      "\tDropped 0 of 139 features.\n",
      "\tDropped 0 of 139 features.\n",
      "\tFitting LightGBMLarge_BAG_L2 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L2/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 139 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "\t-0.0557\t = Validation score   (-root_mean_squared_error)\n",
      "\t36.28s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L3: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L3 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 5\n",
      "Ensemble indices: [7, 5, 7, 5, 7]\n",
      "Ensemble weights: \n",
      "[0.  0.  0.  0.  0.  0.4 0.  0.6 0. ]\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L3/model.pkl\n",
      "\t-0.0517\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.7s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L3: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L3: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L3: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L3: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L3 models ...\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L2/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L2/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting LightGBMXT_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L3/model.pkl\n",
      "\t-0.053\t = Validation score   (-root_mean_squared_error)\n",
      "\t29.89s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting LightGBM_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L3/model.pkl\n",
      "\t-0.0531\t = Validation score   (-root_mean_squared_error)\n",
      "\t50.3s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting RandomForestMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 137 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "\t-0.0548\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.79s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting CatBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L3/model.pkl\n",
      "\t-0.0545\t = Validation score   (-root_mean_squared_error)\n",
      "\t75.15s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/utils/model_template.pkl\n",
      "\tDropped 0 of 137 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "\t-0.0539\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.82s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "\t-0.0533\t = Validation score   (-root_mean_squared_error)\n",
      "\t9.59s\t = Training   runtime\n",
      "\t0.52s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting XGBoost_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L3/model.pkl\n",
      "\t-0.0555\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.74s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting NeuralNetTorch_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "\t-0.0553\t = Validation score   (-root_mean_squared_error)\n",
      "\t10.03s\t = Training   runtime\n",
      "\t0.32s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L3 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting LightGBMLarge_BAG_L3 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L3/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "\t-0.0548\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.97s\t = Training   runtime\n",
      "\t0.15s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L4: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L4 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 33\n",
      "Ensemble indices: [0, 5, 1, 5, 0, 1, 5, 0, 5, 0, 1, 5, 0, 5, 0, 1, 5, 0, 5, 1, 0, 5, 6, 1, 5, 0, 5, 0, 1, 5, 1, 5, 0]\n",
      "Ensemble weights: \n",
      "[0.33333333 0.24242424 0.         0.         0.         0.39393939\n",
      " 0.03030303 0.         0.        ]\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L4/model.pkl\n",
      "\t-0.0526\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.66s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tLightGBMXT_BAG_L4: \t{'extra_trees': True, 'ag_args': {'name_suffix': 'XT', 'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tLightGBM_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'priority': 90}}\n",
      "\tRandomForestMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.rf.rf_model.RFModel'>, 'priority': 80}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tCatBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.catboost.catboost_model.CatBoostModel'>, 'priority': 70}}\n",
      "\tExtraTreesMSE_BAG_L4: \t{'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile'], 'model_type': <class 'autogluon.tabular.models.xt.xt_model.XTModel'>, 'priority': 60}, 'ag_args_ensemble': {'use_child_oof': True}}\n",
      "\tNeuralNetFastAI_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.fastainn.tabular_nn_fastai.NNFastAiTabularModel'>, 'priority': 50}}\n",
      "\tXGBoost_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.xgboost.xgboost_model.XGBoostModel'>, 'priority': 40}}\n",
      "\tNeuralNetTorch_BAG_L4: \t{'ag_args': {'model_type': <class 'autogluon.tabular.models.tabular_nn.torch.tabular_nn_torch.TabularNeuralNetTorchModel'>, 'priority': 25}}\n",
      "\tLightGBMLarge_BAG_L4: \t{'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 5, 'ag_args': {'model_type': <class 'autogluon.tabular.models.lgb.lgb_model.LGBModel'>, 'name_suffix': 'Large', 'hyperparameter_tune_kwargs': None, 'priority': 0}}\n",
      "Fitting 9 L4 models ...\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L3/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L3/utils/oof.pkl\n",
      "Fitting model: LightGBMXT_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting LightGBMXT_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMXT_BAG_L4/model.pkl\n",
      "\t-0.0547\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.12s\t = Training   runtime\n",
      "\t0.07s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBM_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting LightGBM_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBM_BAG_L4/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t2.85s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: RandomForestMSE_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting RandomForestMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 137 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "\t-0.056\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.8s\t = Training   runtime\n",
      "\t0.21s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: CatBoost_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting CatBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/CatBoost_BAG_L4/model.pkl\n",
      "\t-0.0548\t = Validation score   (-root_mean_squared_error)\n",
      "\t42.3s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: ExtraTreesMSE_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting ExtraTreesMSE_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/utils/model_template.pkl\n",
      "\tDropped 0 of 137 features.\n",
      "\t`use_child_oof` was specified for this model. It will function similarly to a bagged model, but will only fit one child model.\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t1.53s\t = Training   runtime\n",
      "\t0.2s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetFastAI_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting NeuralNetFastAI_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "\t-0.0551\t = Validation score   (-root_mean_squared_error)\n",
      "\t6.09s\t = Training   runtime\n",
      "\t0.35s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: XGBoost_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting XGBoost_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/XGBoost_BAG_L4/model.pkl\n",
      "\t-0.0566\t = Validation score   (-root_mean_squared_error)\n",
      "\t8.27s\t = Training   runtime\n",
      "\t0.28s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: NeuralNetTorch_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting NeuralNetTorch_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "\t-0.0549\t = Validation score   (-root_mean_squared_error)\n",
      "\t13.61s\t = Training   runtime\n",
      "\t0.44s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Fitting model: LightGBMLarge_BAG_L4 ...\n",
      "\tDropped 0 of 137 features.\n",
      "\tDropped 0 of 137 features.\n",
      "\tFitting LightGBMLarge_BAG_L4 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L4/utils/model_template.pkl\n",
      "Upper level total_num_cpus, num_gpus 40 | 0\n",
      "\tDropped 0 of 137 features.\n",
      "minimum_model_resources: {'num_cpus': 1}\n",
      "user_cpu_per_job, user_gpu_per_job None | None\n",
      "user_ensemble_cpu, user_ensemble_gpu None | None\n",
      "Resources info for CpuResourceCalculator: {'resources_per_job': {'cpu': 2}, 'num_parallel_jobs': 15, 'batches': 1, 'cpu_per_job': 2}\n",
      "\tFitting 15 child models (S1F1 - S3F5) | Fitting with ParallelLocalFoldFittingStrategy\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Folding resources per job {'num_gpus': 0, 'num_cpus': 2}\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "\t-0.0554\t = Validation score   (-root_mean_squared_error)\n",
      "\t12.06s\t = Training   runtime\n",
      "\t0.1s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L4/utils/oof.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L4/utils/oof.pkl\n",
      "Model configs that will be trained (in order):\n",
      "\tWeightedEnsemble_L5: \t{'ag_args': {'valid_base': False, 'name_bag_suffix': '', 'model_type': <class 'autogluon.core.models.greedy_ensemble.greedy_weighted_ensemble_model.GreedyWeightedEnsembleModel'>, 'priority': 0}, 'ag_args_ensemble': {'save_bag_folds': True}}\n",
      "Fitting model: WeightedEnsemble_L5 ...\n",
      "\tDropped 0 of 9 features.\n",
      "\tDropped 0 of 9 features.\n",
      "\tFitting WeightedEnsemble_L5 with 'num_gpus': 0, 'num_cpus': 40\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L5/utils/model_template.pkl\n",
      "\tDropped 0 of 9 features.\n",
      "Ensemble size: 44\n",
      "Ensemble indices: [0, 7, 5, 4, 7, 5, 7, 4, 5, 7, 4, 5, 7, 5, 7, 4, 5, 7, 4, 7, 5, 7, 5, 4, 7, 5, 4, 7, 5, 7, 4, 5, 7, 4, 7, 5, 4, 7, 5, 7, 5, 7, 5, 4]\n",
      "Ensemble weights: \n",
      "[0.02272727 0.         0.         0.         0.25       0.34090909\n",
      " 0.         0.38636364 0.        ]\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L5/utils/oof.pkl\n",
      "Saving ./agModels-spvae/models/WeightedEnsemble_L5/model.pkl\n",
      "\t-0.0542\t = Validation score   (-root_mean_squared_error)\n",
      "\t0.75s\t = Training   runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "AutoGluon training complete, total runtime = 1090.63s ... Best model: \"WeightedEnsemble_L3\"\n",
      "Loading: ./agModels-spvae/models/trainer.pkl\n",
      "Saving ./agModels-spvae/models/trainer.pkl\n",
      "Saving ./agModels-spvae/learner.pkl\n",
      "Saving ./agModels-spvae/predictor.pkl\n",
      "Saving ./agModels-spvae/__version__ with contents \"0.7.0\"\n",
      "Saving ./agModels-spvae/metadata.json\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"./agModels-spvae/\")\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "save_path = './agModels-spvae'  # specifies folder to store trained models\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "bag_folds = 5 #suggestion range [5, 10]\n",
    "bag_sets = 3 #suggestion range [1, 20]\n",
    "stack_levels = 3 #suggestion range [0, 3]\n",
    "metric = 'root_mean_squared_error' #Regression:mean_absolute_error, mean_squared_error,root_mean_squared_error (default), r2\n",
    "predictor = TabularPredictor(label=label, path=save_path, eval_metric=metric).fit(train_data, \n",
    "                                                                                  presets='best_quality', \n",
    "                                                                                  auto_stack=\"True\", \n",
    "                                                                                  num_bag_folds=bag_folds, \n",
    "                                                                                  num_bag_sets=bag_sets,\n",
    "                                                                                  num_stack_levels=stack_levels,\n",
    "                                                                                  verbosity=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dim_1</th>\n",
       "      <th>dim_2</th>\n",
       "      <th>dim_3</th>\n",
       "      <th>dim_4</th>\n",
       "      <th>dim_5</th>\n",
       "      <th>dim_6</th>\n",
       "      <th>dim_7</th>\n",
       "      <th>dim_8</th>\n",
       "      <th>dim_9</th>\n",
       "      <th>dim_10</th>\n",
       "      <th>...</th>\n",
       "      <th>dim_119</th>\n",
       "      <th>dim_120</th>\n",
       "      <th>dim_121</th>\n",
       "      <th>dim_122</th>\n",
       "      <th>dim_123</th>\n",
       "      <th>dim_124</th>\n",
       "      <th>dim_125</th>\n",
       "      <th>dim_126</th>\n",
       "      <th>dim_127</th>\n",
       "      <th>dim_128</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-1.675357</td>\n",
       "      <td>0.774387</td>\n",
       "      <td>-2.380979</td>\n",
       "      <td>-0.728630</td>\n",
       "      <td>-1.412328</td>\n",
       "      <td>1.705713</td>\n",
       "      <td>-0.913276</td>\n",
       "      <td>-0.664502</td>\n",
       "      <td>-0.036643</td>\n",
       "      <td>0.697300</td>\n",
       "      <td>...</td>\n",
       "      <td>2.785418</td>\n",
       "      <td>-0.100383</td>\n",
       "      <td>-1.418045</td>\n",
       "      <td>-5.795298</td>\n",
       "      <td>-0.239288</td>\n",
       "      <td>-3.270577</td>\n",
       "      <td>0.005218</td>\n",
       "      <td>2.296032</td>\n",
       "      <td>-0.461153</td>\n",
       "      <td>1.085652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>-0.058659</td>\n",
       "      <td>0.094974</td>\n",
       "      <td>-0.148768</td>\n",
       "      <td>-1.709858</td>\n",
       "      <td>0.231730</td>\n",
       "      <td>0.003423</td>\n",
       "      <td>-0.203162</td>\n",
       "      <td>0.288094</td>\n",
       "      <td>-0.420197</td>\n",
       "      <td>-2.209749</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.907042</td>\n",
       "      <td>0.220606</td>\n",
       "      <td>0.879496</td>\n",
       "      <td>-1.250059</td>\n",
       "      <td>-0.911256</td>\n",
       "      <td>2.207671</td>\n",
       "      <td>-0.007707</td>\n",
       "      <td>1.828314</td>\n",
       "      <td>-0.745860</td>\n",
       "      <td>-1.381517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.408514</td>\n",
       "      <td>-0.318794</td>\n",
       "      <td>-0.195711</td>\n",
       "      <td>-1.258788</td>\n",
       "      <td>-0.074261</td>\n",
       "      <td>-3.524118</td>\n",
       "      <td>0.243094</td>\n",
       "      <td>-0.282567</td>\n",
       "      <td>0.518098</td>\n",
       "      <td>1.104262</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.164850</td>\n",
       "      <td>-2.873618</td>\n",
       "      <td>0.817046</td>\n",
       "      <td>1.877096</td>\n",
       "      <td>-1.402977</td>\n",
       "      <td>-0.992778</td>\n",
       "      <td>-0.002622</td>\n",
       "      <td>1.483371</td>\n",
       "      <td>0.380046</td>\n",
       "      <td>0.484612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-2.754269</td>\n",
       "      <td>-1.133549</td>\n",
       "      <td>-1.814455</td>\n",
       "      <td>0.036195</td>\n",
       "      <td>-0.159687</td>\n",
       "      <td>2.911953</td>\n",
       "      <td>-0.640023</td>\n",
       "      <td>-0.894014</td>\n",
       "      <td>0.440514</td>\n",
       "      <td>0.164435</td>\n",
       "      <td>...</td>\n",
       "      <td>-2.664808</td>\n",
       "      <td>1.762599</td>\n",
       "      <td>-0.071357</td>\n",
       "      <td>3.233031</td>\n",
       "      <td>-0.915575</td>\n",
       "      <td>2.781991</td>\n",
       "      <td>-0.008800</td>\n",
       "      <td>0.508250</td>\n",
       "      <td>-0.724321</td>\n",
       "      <td>-0.320688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>-1.054854</td>\n",
       "      <td>0.100548</td>\n",
       "      <td>0.473871</td>\n",
       "      <td>3.140375</td>\n",
       "      <td>-0.449581</td>\n",
       "      <td>2.196428</td>\n",
       "      <td>0.303511</td>\n",
       "      <td>-0.011313</td>\n",
       "      <td>0.375206</td>\n",
       "      <td>-0.866014</td>\n",
       "      <td>...</td>\n",
       "      <td>3.855908</td>\n",
       "      <td>0.273155</td>\n",
       "      <td>-2.094910</td>\n",
       "      <td>-3.537341</td>\n",
       "      <td>1.143077</td>\n",
       "      <td>-2.242801</td>\n",
       "      <td>-0.000889</td>\n",
       "      <td>0.217993</td>\n",
       "      <td>-0.597952</td>\n",
       "      <td>1.817741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        dim_1     dim_2     dim_3     dim_4     dim_5     dim_6     dim_7  \\\n",
       "46  -1.675357  0.774387 -2.380979 -0.728630 -1.412328  1.705713 -0.913276   \n",
       "101 -0.058659  0.094974 -0.148768 -1.709858  0.231730  0.003423 -0.203162   \n",
       "175  0.408514 -0.318794 -0.195711 -1.258788 -0.074261 -3.524118  0.243094   \n",
       "9   -2.754269 -1.133549 -1.814455  0.036195 -0.159687  2.911953 -0.640023   \n",
       "136 -1.054854  0.100548  0.473871  3.140375 -0.449581  2.196428  0.303511   \n",
       "\n",
       "        dim_8     dim_9    dim_10  ...   dim_119   dim_120   dim_121  \\\n",
       "46  -0.664502 -0.036643  0.697300  ...  2.785418 -0.100383 -1.418045   \n",
       "101  0.288094 -0.420197 -2.209749  ... -2.907042  0.220606  0.879496   \n",
       "175 -0.282567  0.518098  1.104262  ... -2.164850 -2.873618  0.817046   \n",
       "9   -0.894014  0.440514  0.164435  ... -2.664808  1.762599 -0.071357   \n",
       "136 -0.011313  0.375206 -0.866014  ...  3.855908  0.273155 -2.094910   \n",
       "\n",
       "      dim_122   dim_123   dim_124   dim_125   dim_126   dim_127   dim_128  \n",
       "46  -5.795298 -0.239288 -3.270577  0.005218  2.296032 -0.461153  1.085652  \n",
       "101 -1.250059 -0.911256  2.207671 -0.007707  1.828314 -0.745860 -1.381517  \n",
       "175  1.877096 -1.402977 -0.992778 -0.002622  1.483371  0.380046  0.484612  \n",
       "9    3.233031 -0.915575  2.781991 -0.008800  0.508250 -0.724321 -0.320688  \n",
       "136 -3.537341  1.143077 -2.242801 -0.000889  0.217993 -0.597952  1.817741  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data = test_df.drop(columns=['i', 'name'])\n",
    "# val_data.head()\n",
    "y_val = test_data[label]\n",
    "test_data_nolab = test_data.drop(columns=[label])  # delete label column to prove we're not cheating\n",
    "test_data_nolab.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46 , 0.548\n",
      "101 , 0.37\n",
      "175 , 0.38\n",
      "9 , 0.431\n",
      "136 , 0.38\n",
      "381 , 0.486\n",
      "239 , 0.435\n",
      "63 , 0.496\n",
      "401 , 0.414\n",
      "238 , 0.314\n",
      "168 , 0.326\n",
      "409 , 0.39\n",
      "97 , 0.361\n",
      "368 , 0.541\n",
      "215 , 0.429\n",
      "200 , 0.483\n",
      "172 , 0.426\n",
      "169 , 0.409\n",
      "282 , 0.369\n",
      "134 , 0.32\n",
      "243 , 0.398\n",
      "145 , 0.331\n",
      "166 , 0.327\n",
      "286 , 0.373\n",
      "6 , 0.431\n",
      "165 , 0.371\n",
      "75 , 0.435\n",
      "146 , 0.336\n",
      "25 , 0.388\n",
      "184 , 0.419\n",
      "12 , 0.445\n",
      "161 , 0.35\n",
      "89 , 0.364\n",
      "362 , 0.413\n",
      "72 , 0.413\n",
      "77 , 0.41\n",
      "147 , 0.32\n",
      "222 , 0.389\n",
      "412 , 0.401\n",
      "110 , 0.347\n",
      "290 , 0.631\n",
      "21 , 0.375\n",
      "178 , 0.436\n",
      "420 , 0.395\n",
      "257 , 0.406\n",
      "304 , 0.357\n",
      "52 , 0.407\n",
      "48 , 0.435\n",
      "177 , 0.363\n",
      "252 , 0.403\n",
      "436 , 0.375\n",
      "260 , 0.374\n",
      "406 , 0.464\n",
      "153 , 0.41\n",
      "281 , 0.394\n",
      "426 , 0.35\n",
      "400 , 0.456\n",
      "174 , 0.395\n",
      "144 , 0.345\n",
      "170 , 0.325\n",
      "192 , 0.339\n",
      "349 , 0.424\n",
      "36 , 0.361\n",
      "242 , 0.414\n",
      "185 , 0.395\n",
      "398 , 0.364\n",
      "241 , 0.309\n",
      "277 , 0.336\n",
      "86 , 0.365\n",
      "408 , 0.446\n",
      "351 , 0.438\n",
      "339 , 0.374\n",
      "417 , 0.446\n",
      "416 , 0.453\n",
      "54 , 0.417\n",
      "188 , 0.38\n",
      "79 , 0.39\n",
      "255 , 0.341\n",
      "411 , 0.355\n",
      "328 , 0.454\n",
      "300 , 0.376\n",
      "196 , 0.428\n",
      "7 , 0.307\n",
      "173 , 0.398\n",
      "5 , 0.372\n",
      "55 , 0.44\n",
      "428 , 0.365\n",
      "334 , 0.398\n"
     ]
    }
   ],
   "source": [
    "test_drags = test_df[\"drag\"]\n",
    "test_index = test_df[\"i\"]\n",
    "for index, drag in zip(test_index, test_drags):\n",
    "    print(index, \",\" ,drag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-spvae/predictor.pkl\n",
      "Loading: ./agModels-spvae/learner.pkl\n",
      "Loading: ./agModels-spvae/models/trainer.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L3/model.pkl\n",
      "Evaluation: root_mean_squared_error on test data: -0.05365927650482297\n",
      "\tNote: Scores are always higher_is_better. This metric score can be multiplied by -1 to get the metric value.\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"root_mean_squared_error\": -0.05365927650482297,\n",
      "    \"mean_squared_error\": -0.0028793179550210463,\n",
      "    \"mean_absolute_error\": -0.0408306018222462,\n",
      "    \"r2\": 0.020843660578791723,\n",
      "    \"pearsonr\": 0.22453544262188677,\n",
      "    \"median_absolute_error\": -0.03124112486839295\n",
      "}\n",
      "Loading: ./agModels-spvae/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L5/model.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsUnif_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L2/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L3/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMXT_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/RandomForestMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/CatBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/ExtraTreesMSE_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/XGBoost_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetTorch_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBMLarge_BAG_L4/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L5/model.pkl\n",
      "Model scores:\n",
      "{'KNeighborsUnif_BAG_L1': -0.060145535656539684, 'KNeighborsDist_BAG_L1': -0.05984951576678455, 'LightGBMXT_BAG_L1': -0.05172842377658943, 'LightGBM_BAG_L1': -0.0522468536354823, 'RandomForestMSE_BAG_L1': -0.05265751051051625, 'CatBoost_BAG_L1': -0.051773131782362584, 'ExtraTreesMSE_BAG_L1': -0.05159945613669657, 'NeuralNetFastAI_BAG_L1': -0.05268659524326332, 'XGBoost_BAG_L1': -0.05262626194400898, 'NeuralNetTorch_BAG_L1': -0.05271936856069128, 'LightGBMLarge_BAG_L1': -0.05280536041950834, 'WeightedEnsemble_L2': -0.05377815540154241, 'LightGBMXT_BAG_L2': -0.051919739953295206, 'LightGBM_BAG_L2': -0.05150238056153827, 'RandomForestMSE_BAG_L2': -0.0519101486940434, 'CatBoost_BAG_L2': -0.05147585498280663, 'ExtraTreesMSE_BAG_L2': -0.052039692574048904, 'NeuralNetFastAI_BAG_L2': -0.053056113523944806, 'XGBoost_BAG_L2': -0.05215895929102553, 'NeuralNetTorch_BAG_L2': -0.05463950622411773, 'LightGBMLarge_BAG_L2': -0.052186891578459016, 'WeightedEnsemble_L3': -0.05365927650482297, 'LightGBMXT_BAG_L3': -0.05239127509286927, 'LightGBM_BAG_L3': -0.0521998004537993, 'RandomForestMSE_BAG_L3': -0.05385152066566597, 'CatBoost_BAG_L3': -0.05197723477539791, 'ExtraTreesMSE_BAG_L3': -0.05326915842965808, 'NeuralNetFastAI_BAG_L3': -0.05270371675156511, 'XGBoost_BAG_L3': -0.054329543090068315, 'NeuralNetTorch_BAG_L3': -0.05409613833904239, 'LightGBMLarge_BAG_L3': -0.05212532875387104, 'WeightedEnsemble_L4': -0.052212779682867756, 'LightGBMXT_BAG_L4': -0.05114045611412852, 'LightGBM_BAG_L4': -0.05123511338654191, 'RandomForestMSE_BAG_L4': -0.05277132934236079, 'CatBoost_BAG_L4': -0.05137682708203935, 'ExtraTreesMSE_BAG_L4': -0.053203665157653394, 'NeuralNetFastAI_BAG_L4': -0.05233640313078859, 'XGBoost_BAG_L4': -0.052683747113912015, 'NeuralNetTorch_BAG_L4': -0.05376649895277298, 'LightGBMLarge_BAG_L4': -0.0517826659480563, 'WeightedEnsemble_L5': -0.05251253209533177}\n"
     ]
    }
   ],
   "source": [
    "%%capture log_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%config Application.log_level = 'DEBUG'\n",
    "%config IPCompleter.greedy = True\n",
    "\n",
    "predictor = TabularPredictor.load(save_path)  # unnecessary, just demonstrates how to load previously-trained predictor from file\n",
    "y_pred = predictor.predict(test_data_nolab)\n",
    "for item in y_pred:\n",
    "    print(item)\n",
    "print(\"Predictions:  \\n\", y_pred)\n",
    "perf = predictor.evaluate_predictions(y_true=y_val, y_pred=y_pred, auxiliary_metrics=True)\n",
    "print(perf)\n",
    "\n",
    "results = predictor.fit_summary(show_plot=True)\n",
    "print(results)\n",
    "print(predictor.leaderboard(test_data, silent=True))\n",
    "\n",
    "with open('./output_spvae.log', 'w') as f:\n",
    "    f.write(log_output.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoGluon infers problem type is:  regression\n",
      "AutoGluon identified the following types of features:\n",
      "('float', []) : 128 | ['dim_1', 'dim_2', 'dim_3', 'dim_4', 'dim_5', ...]\n"
     ]
    }
   ],
   "source": [
    "print(\"AutoGluon infers problem type is: \", predictor.problem_type)\n",
    "print(\"AutoGluon identified the following types of features:\")\n",
    "print(predictor.feature_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.39116281270980835\n",
      "0.38422268629074097\n",
      "0.4321916103363037\n",
      "0.4221478998661041\n",
      "0.381976842880249\n",
      "0.37929338216781616\n",
      "0.44311171770095825\n",
      "0.3903323709964752\n",
      "0.38242995738983154\n",
      "0.3697527348995209\n",
      "0.3696485161781311\n",
      "0.48752298951148987\n",
      "0.44381165504455566\n",
      "0.38811272382736206\n",
      "0.4178387224674225\n",
      "0.4455588459968567\n",
      "0.33955118060112\n",
      "0.4062100350856781\n",
      "0.4758799076080322\n",
      "0.3802383542060852\n",
      "0.41610413789749146\n",
      "0.44242262840270996\n",
      "0.35412436723709106\n",
      "0.4298839569091797\n",
      "0.4077208340167999\n",
      "0.41002267599105835\n",
      "0.38871702551841736\n",
      "0.411051869392395\n",
      "0.3525809645652771\n",
      "0.36932802200317383\n",
      "0.446757435798645\n",
      "0.4205259084701538\n",
      "0.4632236361503601\n",
      "0.42609119415283203\n",
      "0.3690805435180664\n",
      "0.3842049241065979\n",
      "0.41131722927093506\n",
      "0.45698171854019165\n",
      "0.353503555059433\n",
      "0.3623332977294922\n",
      "0.4831129312515259\n",
      "0.38434967398643494\n",
      "0.3578150272369385\n",
      "0.3488399088382721\n",
      "0.36573535203933716\n",
      "0.3847488760948181\n",
      "0.3968857526779175\n",
      "0.4063284397125244\n",
      "0.36181819438934326\n",
      "0.39586013555526733\n",
      "0.3985598683357239\n",
      "0.3737621307373047\n",
      "0.397972047328949\n",
      "0.35817083716392517\n",
      "0.411421537399292\n",
      "0.39144960045814514\n",
      "0.42196375131607056\n",
      "0.3754654824733734\n",
      "0.3563481271266937\n",
      "0.3593974709510803\n",
      "0.36741265654563904\n",
      "0.36750659346580505\n",
      "0.4241769313812256\n",
      "0.3622966408729553\n",
      "0.38023698329925537\n",
      "0.3892921209335327\n",
      "0.4222447872161865\n",
      "0.3517523407936096\n",
      "0.41972559690475464\n",
      "0.38423752784729004\n",
      "0.4189475178718567\n",
      "0.38280045986175537\n",
      "0.38353192806243896\n",
      "0.3778865933418274\n",
      "0.39249783754348755\n",
      "0.4013999402523041\n",
      "0.44117701053619385\n",
      "0.42314788699150085\n",
      "0.41182172298431396\n",
      "0.4289889633655548\n",
      "0.4115699529647827\n",
      "0.46459463238716125\n",
      "0.345133900642395\n",
      "0.355998158454895\n",
      "0.3782292902469635\n",
      "0.42615658044815063\n",
      "0.38810378313064575\n",
      "0.4273974299430847\n",
      "0.4079471826553345\n",
      "0.3944016695022583\n",
      "0.36231353878974915\n",
      "0.35278254747390747\n",
      "0.44073596596717834\n",
      "0.36887094378471375\n",
      "0.4201953411102295\n",
      "0.3685765266418457\n",
      "0.38184165954589844\n",
      "0.36649787425994873\n",
      "0.46734389662742615\n",
      "0.3721848726272583\n",
      "0.4025099277496338\n",
      "0.4136945307254791\n",
      "0.37405142188072205\n",
      "0.4216785430908203\n",
      "0.4219188094139099\n",
      "0.363497257232666\n",
      "0.3518613874912262\n",
      "0.4260523319244385\n",
      "0.4111593961715698\n",
      "0.45884275436401367\n",
      "0.344487726688385\n",
      "0.4067409634590149\n",
      "0.3774643540382385\n",
      "0.4025505781173706\n",
      "0.4111461043357849\n",
      "0.38823437690734863\n",
      "0.3549140393733978\n",
      "0.36307892203330994\n",
      "0.48725876212120056\n",
      "0.37710458040237427\n",
      "0.3970385789871216\n",
      "0.41958141326904297\n",
      "0.3958475887775421\n",
      "0.4125140309333801\n",
      "0.4395621418952942\n",
      "0.36620309948921204\n",
      "0.43660879135131836\n",
      "0.4447660446166992\n",
      "0.38567355275154114\n",
      "0.3579959273338318\n",
      "0.39295268058776855\n",
      "0.4374125599861145\n",
      "0.35292452573776245\n",
      "0.3947083353996277\n",
      "0.42857909202575684\n",
      "0.4094582200050354\n",
      "0.3956782817840576\n",
      "0.44024658203125\n",
      "0.3804241716861725\n",
      "0.3653184771537781\n",
      "0.42733556032180786\n",
      "0.41569608449935913\n",
      "0.3935874104499817\n",
      "0.382972776889801\n",
      "0.4112685024738312\n",
      "0.3817134499549866\n",
      "0.4025297462940216\n",
      "0.3980901837348938\n",
      "0.4514191746711731\n",
      "0.35944581031799316\n",
      "0.4236081838607788\n",
      "0.4296630024909973\n",
      "0.459611177444458\n",
      "0.4488102197647095\n",
      "0.3930875062942505\n",
      "0.36481815576553345\n",
      "0.39017337560653687\n",
      "0.43551912903785706\n",
      "0.4166974425315857\n",
      "0.3733747601509094\n",
      "0.44806671142578125\n",
      "0.3738110661506653\n",
      "0.4238027334213257\n",
      "0.40423789620399475\n",
      "0.36303210258483887\n",
      "0.36508405208587646\n",
      "0.4137960374355316\n",
      "0.42527061700820923\n",
      "0.3525455594062805\n",
      "0.42621910572052\n",
      "0.3815164864063263\n",
      "0.40327852964401245\n",
      "0.4034750461578369\n",
      "0.3982422351837158\n",
      "0.39828091859817505\n",
      "0.4282432794570923\n",
      "0.44921934604644775\n",
      "0.38510650396347046\n",
      "0.4231950044631958\n",
      "0.4126274883747101\n",
      "0.4083961844444275\n",
      "0.3624712824821472\n",
      "0.396433562040329\n",
      "0.39438343048095703\n",
      "0.3952777683734894\n",
      "0.3733482360839844\n",
      "0.432745099067688\n",
      "0.35697513818740845\n",
      "0.42542558908462524\n",
      "0.3772543668746948\n",
      "0.44234800338745117\n",
      "0.37128475308418274\n",
      "0.38227611780166626\n",
      "0.4743248224258423\n",
      "0.44627171754837036\n",
      "0.4256260395050049\n",
      "0.4005982279777527\n",
      "0.4401969611644745\n",
      "0.36169493198394775\n",
      "0.43104398250579834\n",
      "0.39352214336395264\n",
      "0.4046410322189331\n",
      "0.37807053327560425\n",
      "0.36579614877700806\n",
      "0.42646539211273193\n",
      "0.36242878437042236\n",
      "0.39865627884864807\n",
      "0.4089508354663849\n",
      "0.4087669253349304\n",
      "0.38785320520401\n",
      "0.4623417854309082\n",
      "0.3847060203552246\n",
      "0.38112500309944153\n",
      "0.41785115003585815\n",
      "0.3751389980316162\n",
      "0.3756720721721649\n",
      "0.38579726219177246\n",
      "0.41026490926742554\n",
      "0.411409854888916\n",
      "0.415698766708374\n",
      "0.3832036256790161\n",
      "0.3514364957809448\n",
      "0.4531806409358978\n",
      "0.41427111625671387\n",
      "0.45032334327697754\n",
      "0.34139543771743774\n",
      "0.3654514253139496\n",
      "0.40180033445358276\n",
      "0.38112086057662964\n",
      "0.3547018766403198\n",
      "0.39564189314842224\n",
      "0.35698169469833374\n",
      "0.4030371308326721\n",
      "0.39211681485176086\n",
      "0.37170618772506714\n",
      "0.36401402950286865\n",
      "0.4654299020767212\n",
      "0.3727663457393646\n",
      "0.46903395652770996\n",
      "0.3796188235282898\n",
      "0.410537451505661\n",
      "0.39170190691947937\n",
      "0.3625953197479248\n",
      "0.4013068675994873\n",
      "0.41371336579322815\n",
      "0.37782812118530273\n",
      "0.4018164277076721\n",
      "0.42298269271850586\n",
      "0.3836020827293396\n",
      "0.40012121200561523\n",
      "0.3724677562713623\n",
      "0.39517366886138916\n",
      "0.3934563100337982\n",
      "0.3983733654022217\n",
      "0.39242351055145264\n",
      "0.4320942759513855\n",
      "0.36384040117263794\n",
      "0.4334666132926941\n",
      "0.3818795084953308\n",
      "0.3645879030227661\n",
      "0.37104031443595886\n",
      "0.3840787410736084\n",
      "0.4379851818084717\n",
      "0.35934048891067505\n",
      "0.449428915977478\n",
      "0.39400190114974976\n",
      "0.3931942582130432\n",
      "0.4597446322441101\n",
      "0.4326561689376831\n",
      "0.38493090867996216\n",
      "0.4589359760284424\n",
      "0.44395512342453003\n",
      "0.3939369022846222\n",
      "0.3598068356513977\n",
      "0.3565104007720947\n",
      "0.41497719287872314\n",
      "0.3393287658691406\n",
      "0.36763787269592285\n",
      "0.4511258602142334\n",
      "0.3866228759288788\n",
      "0.42764559388160706\n",
      "0.3503778576850891\n",
      "0.39934027194976807\n",
      "0.4025959074497223\n",
      "0.38546061515808105\n",
      "0.36539414525032043\n",
      "0.3539111018180847\n",
      "0.4503212571144104\n",
      "0.3955608308315277\n",
      "0.48285120725631714\n",
      "0.4156036376953125\n",
      "0.3847964107990265\n",
      "0.34619849920272827\n",
      "0.37239545583724976\n",
      "0.38234463334083557\n",
      "0.42293664813041687\n",
      "0.3815871477127075\n",
      "0.5073213577270508\n",
      "0.36783909797668457\n",
      "0.4157482385635376\n",
      "0.4033743739128113\n",
      "0.36464816331863403\n",
      "0.4028293788433075\n",
      "0.36342543363571167\n",
      "0.35363203287124634\n",
      "0.4089469909667969\n",
      "0.3983857035636902\n",
      "0.3791070580482483\n",
      "0.3691907525062561\n",
      "0.4356134831905365\n",
      "0.48810648918151855\n",
      "0.46842271089553833\n",
      "0.4266303777694702\n",
      "0.38725966215133667\n",
      "0.47577032446861267\n",
      "0.4175339937210083\n",
      "0.42744874954223633\n",
      "0.4109388589859009\n",
      "0.3924863934516907\n",
      "0.4030396342277527\n",
      "0.4925249218940735\n",
      "0.376321941614151\n",
      "0.35598862171173096\n",
      "0.3692799210548401\n",
      "0.36567771434783936\n",
      "0.4374663531780243\n",
      "0.39460253715515137\n",
      "0.4038752317428589\n",
      "0.334043025970459\n",
      "0.3861220180988312\n",
      "0.41287899017333984\n",
      "0.34602898359298706\n",
      "0.4198932945728302\n",
      "0.4492409825325012\n",
      "0.41829991340637207\n",
      "0.44203510880470276\n",
      "0.4234349727630615\n",
      "0.4409010708332062\n",
      "0.3641285300254822\n",
      "0.37737923860549927\n",
      "0.37475281953811646\n",
      "0.3869476616382599\n",
      "0.3610121011734009\n",
      "0.4180906414985657\n",
      "0.4142129719257355\n",
      "0.46816951036453247\n",
      "0.35444509983062744\n",
      "0.4153293967247009\n",
      "0.36421704292297363\n",
      "0.39798760414123535\n",
      "0.36645716428756714\n"
     ]
    }
   ],
   "source": [
    "train_data_pred = predictor.predict(train_data, model='WeightedEnsemble_L2')\n",
    "for item in train_data_pred:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading: ./agModels-spvae/models/KNeighborsDist_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/LightGBM_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/NeuralNetFastAI_BAG_L1/model.pkl\n",
      "Loading: ./agModels-spvae/models/WeightedEnsemble_L2/model.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3715846538543701\n",
      "0.3892876207828522\n",
      "0.3662589490413666\n",
      "0.4449158012866974\n",
      "0.4008152484893799\n",
      "0.4123873710632324\n",
      "0.4056609272956848\n",
      "0.40893423557281494\n",
      "0.40943390130996704\n",
      "0.39007431268692017\n",
      "0.41601961851119995\n",
      "0.40324831008911133\n",
      "0.3807868957519531\n",
      "0.4320763945579529\n",
      "0.39484596252441406\n",
      "0.3994584083557129\n",
      "0.37342697381973267\n",
      "0.41242337226867676\n",
      "0.4068812429904938\n",
      "0.36535704135894775\n",
      "0.4233607351779938\n",
      "0.4209880232810974\n",
      "0.3790907859802246\n",
      "0.3989671766757965\n",
      "0.4112382233142853\n",
      "0.39417600631713867\n",
      "0.41431230306625366\n",
      "0.389351487159729\n",
      "0.3853309750556946\n",
      "0.3866821527481079\n",
      "0.4274556636810303\n",
      "0.3762912154197693\n",
      "0.3949410319328308\n",
      "0.41964006423950195\n",
      "0.403073251247406\n",
      "0.3803277909755707\n",
      "0.3869140148162842\n",
      "0.40557241439819336\n",
      "0.3959423005580902\n",
      "0.39824503660202026\n",
      "0.4232049286365509\n",
      "0.3929121494293213\n",
      "0.42545002698898315\n",
      "0.43621018528938293\n",
      "0.4298994839191437\n",
      "0.4001341164112091\n",
      "0.37912899255752563\n",
      "0.3720305263996124\n",
      "0.44284701347351074\n",
      "0.4230244755744934\n",
      "0.3976234197616577\n",
      "0.37220463156700134\n",
      "0.4164963364601135\n",
      "0.39883995056152344\n",
      "0.3852258622646332\n",
      "0.40488874912261963\n",
      "0.3917756676673889\n",
      "0.38697031140327454\n",
      "0.4011680483818054\n",
      "0.388541579246521\n",
      "0.3934049904346466\n",
      "0.4102158546447754\n",
      "0.37892472743988037\n",
      "0.39036574959754944\n",
      "0.3943731188774109\n",
      "0.4202759861946106\n",
      "0.4110748767852783\n",
      "0.3968810737133026\n",
      "0.37818896770477295\n",
      "0.38821107149124146\n",
      "0.3733406662940979\n",
      "0.37425196170806885\n",
      "0.37803328037261963\n",
      "0.37078338861465454\n",
      "0.37404686212539673\n",
      "0.43086665868759155\n",
      "0.4079527258872986\n",
      "0.3894023597240448\n",
      "0.4319610595703125\n",
      "0.4301909804344177\n",
      "0.4011366367340088\n",
      "0.4139380156993866\n",
      "0.38788196444511414\n",
      "0.40883398056030273\n",
      "0.3941790461540222\n",
      "0.4183719754219055\n",
      "0.384170264005661\n",
      "0.41761502623558044\n"
     ]
    }
   ],
   "source": [
    "test_data_pred = predictor.predict(test_data, model='WeightedEnsemble_L2')\n",
    "for item in test_data_pred:\n",
    "    print(item)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "surrogate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
